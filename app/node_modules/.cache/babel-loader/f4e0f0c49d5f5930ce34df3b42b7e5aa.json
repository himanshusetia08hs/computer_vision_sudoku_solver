{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape';\nexport function concat(args) {\n  const {\n    inputs,\n    backend\n  } = args;\n  const axis = util.parseAxisParam(args.attrs.axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({\n      inputs: {\n        x: $inputs[0]\n      },\n      backend\n    });\n  }\n  const out = backend.makeOutput(outShape, inputs[0].dtype);\n  if (util.sizeFromShape(outShape) === 0) {\n    return out;\n  }\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, axis);\n  if ($inputs[0].dtype === 'string') {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const inputs2D = $inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({\n        inputs: {\n          x: t\n        },\n        backend,\n        attrs: {\n          shape\n        }\n      });\n    });\n    const inputsValShapes = inputs2D.map(t => {\n      return {\n        vals: backend.readSync(t.dataId),\n        shape: t.shape\n      };\n    });\n    // Concats 2d tensors along axis=1.\n    outShape = backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = inputs2D[0].shape[0] === 1;\n    const outVals = concatImplCPU(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n    const finalOutShape = backend_util.computeOutShape($inputs.map(t => t.shape), axis);\n    out.shape = finalOutShape;\n    const outData = backend.dataIdMap.get(out.dataId);\n    outData.stringBytes = backend_util.fromStringArrayToUint8(outVals);\n    return out;\n  }\n  const batchDim = util.sizeFromShape($inputs[0].shape.slice(0, axis));\n  let sumInnerDims = 0;\n  const innerDims = $inputs.map(input => {\n    const innerDim = util.sizeFromShape(input.shape.slice(axis));\n    sumInnerDims += innerDim;\n    return innerDim;\n  });\n  const inVals = $inputs.map(input => backend.typedArrayFromHeap(input));\n  const outVals = backend.typedArrayFromHeap(out);\n  for (let b = 0; b < batchDim; b++) {\n    let outOffset = b * sumInnerDims;\n    for (let i = 0; i < inVals.length; i++) {\n      const innerDim = innerDims[i];\n      const inOffset = b * innerDim;\n      const vals = inVals[i].subarray(inOffset, inOffset + innerDim);\n      outVals.set(vals, outOffset);\n      outOffset += innerDim;\n    }\n  }\n  return out;\n}\nexport const concatConfig = {\n  kernelName: Concat,\n  backendName: 'wasm',\n  kernelFunc: concat\n};","map":{"version":3,"sources":["../../src/kernels/Concat.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAE,MAAM,EAAuD,IAAI,QAAO,uBAAuB;AAGrH,SAAQ,aAAa,QAAO,wBAAwB;AACpD,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAU,MAAM,CAClB,IAAsE,EAAA;EACxE,MAAM;IAAC,MAAM;IAAE;EAAO,CAAC,GAAG,IAAI;EAE9B,MAAM,IAAI,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;EAErE,IAAI,QAAQ,GAAG,YAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC;EAE3E;EACA,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;EACnE,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;IACxB,OAAO,QAAQ,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE,OAAO,CAAC,CAAC;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC;EACpD;EAED,MAAM,GAAG,GAAG,OAAO,CAAC,UAAU,CAAC,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;EAEzD,IAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAE;IACtC,OAAO,GAAG;EACX;EAED,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC;EACxC,YAAY,CAAC,sBAAsB,CAAC,MAAM,EAAE,IAAI,CAAC;EAEjD,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;IACjC;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAG;MAC/B,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;MACzD,MAAM,KAAK,GAAG,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC;MAC7B,OAAO,OAAO,CAAC;QAAC,MAAM,EAAE;UAAC,CAAC,EAAE;QAAC,CAAC;QAAE,OAAO;QAAE,KAAK,EAAE;UAAC;QAAK;MAAC,CAAC,CAAC;IAC3D,CAAC,CAAC;IAEF,MAAM,eAAe,GAAG,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAG;MACvC,OAAO;QAAC,IAAI,EAAE,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC;QAAE,KAAK,EAAE,CAAC,CAAC;MAAK,CAAC;IAC3D,CAAC,CAAC;IAEF;IACA,QAAQ,GACJ,YAAY,CAAC,eAAe,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,WAAW;IAC1E,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;IAC/C,MAAM,OAAO,GAAG,aAAa,CACT,eAAe,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAC1C,YAAY,CAAa;IAE7C,MAAM,aAAa,GACf,YAAY,CAAC,eAAe,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC;IAEjE,GAAG,CAAC,KAAK,GAAG,aAAa;IACzB,MAAM,OAAO,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC;IACjD,OAAO,CAAC,WAAW,GAAG,YAAY,CAAC,sBAAsB,CAAC,OAAO,CAAC;IAElE,OAAO,GAAG;EACX;EAED,MAAM,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;EACpE,IAAI,YAAY,GAAG,CAAC;EACpB,MAAM,SAAS,GAAG,OAAO,CAAC,GAAG,CAAC,KAAK,IAAG;IACpC,MAAM,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IAC5D,YAAY,IAAI,QAAQ;IACxB,OAAO,QAAQ;EACjB,CAAC,CAAC;EACF,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,KAAK,IAAI,OAAO,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;EACtE,MAAM,OAAO,GAAG,OAAO,CAAC,kBAAkB,CAAC,GAAG,CAAC;EAC/C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,EAAE,CAAC,EAAE,EAAE;IACjC,IAAI,SAAS,GAAG,CAAC,GAAG,YAAY;IAChC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;MACtC,MAAM,QAAQ,GAAG,SAAS,CAAC,CAAC,CAAC;MAC7B,MAAM,QAAQ,GAAG,CAAC,GAAG,QAAQ;MAC7B,MAAM,IAAI,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,QAAQ,EAAE,QAAQ,GAAG,QAAQ,CAAC;MAC9D,OAAO,CAAC,GAAG,CAAC,IAAI,EAAE,SAAS,CAAC;MAC5B,SAAS,IAAI,QAAQ;IACtB;EACF;EACD,OAAO,GAAG;AACZ;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,MAAM;EACnB,UAAU,EAAE;CACb","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape';\nexport function concat(args) {\n    const { inputs, backend } = args;\n    const axis = util.parseAxisParam(args.attrs.axis, inputs[0].shape)[0];\n    let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n    if ($inputs.length === 1) {\n        return identity({ inputs: { x: $inputs[0] }, backend });\n    }\n    const out = backend.makeOutput(outShape, inputs[0].dtype);\n    if (util.sizeFromShape(outShape) === 0) {\n        return out;\n    }\n    const shapes = $inputs.map(t => t.shape);\n    backend_util.assertParamsConsistent(shapes, axis);\n    if ($inputs[0].dtype === 'string') {\n        // Any concat of n-dimensional tensors across any axis can be reduced to\n        // a concatenation of two-dimensional tensors across the axis 1 by first\n        // partitioning the axes of the original tensors into those less than the\n        // axis to be concatenated and the rest. Then reshape the tensors\n        // into a two-dimensional tensor by collapsing these two sets of axes and\n        // concatenate the resulting matrices across the axis 1, finally reshaping\n        // the result to have the proper shape.\n        const inputs2D = $inputs.map(t => {\n            const innerSize = util.sizeFromShape(t.shape.slice(axis));\n            const shape = [-1, innerSize];\n            return reshape({ inputs: { x: t }, backend, attrs: { shape } });\n        });\n        const inputsValShapes = inputs2D.map(t => {\n            return { vals: backend.readSync(t.dataId), shape: t.shape };\n        });\n        // Concats 2d tensors along axis=1.\n        outShape =\n            backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n        const simplyConcat = inputs2D[0].shape[0] === 1;\n        const outVals = concatImplCPU(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n        const finalOutShape = backend_util.computeOutShape($inputs.map(t => t.shape), axis);\n        out.shape = finalOutShape;\n        const outData = backend.dataIdMap.get(out.dataId);\n        outData.stringBytes = backend_util.fromStringArrayToUint8(outVals);\n        return out;\n    }\n    const batchDim = util.sizeFromShape($inputs[0].shape.slice(0, axis));\n    let sumInnerDims = 0;\n    const innerDims = $inputs.map(input => {\n        const innerDim = util.sizeFromShape(input.shape.slice(axis));\n        sumInnerDims += innerDim;\n        return innerDim;\n    });\n    const inVals = $inputs.map(input => backend.typedArrayFromHeap(input));\n    const outVals = backend.typedArrayFromHeap(out);\n    for (let b = 0; b < batchDim; b++) {\n        let outOffset = b * sumInnerDims;\n        for (let i = 0; i < inVals.length; i++) {\n            const innerDim = innerDims[i];\n            const inOffset = b * innerDim;\n            const vals = inVals[i].subarray(inOffset, inOffset + innerDim);\n            outVals.set(vals, outOffset);\n            outOffset += innerDim;\n        }\n    }\n    return out;\n}\nexport const concatConfig = {\n    kernelName: Concat,\n    backendName: 'wasm',\n    kernelFunc: concat,\n};\n//# sourceMappingURL=Concat.js.map"]},"metadata":{},"sourceType":"module"}