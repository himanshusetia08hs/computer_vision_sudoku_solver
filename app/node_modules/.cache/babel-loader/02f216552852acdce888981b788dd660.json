{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { _FusedMatMul, broadcast_util } from '@tensorflow/tfjs-core';\nimport { FusableActivation } from './types';\nlet wasmFusedMatMul;\nfunction setup(backend) {\n  wasmFusedMatMul = backend.wasm.cwrap(_FusedMatMul, null /* void */, ['number', 'array', 'number', 'number', 'array', 'number', 'number', 'number', 'number', 'number', 'number', 'number', 'number' // out_id\n  ]);\n}\n\nfunction fusedBatchMatMul(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    a,\n    b,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(`_FusedMatMul for non non-float32 tensors not yet supported.`);\n  }\n  const {\n    transposeA,\n    transposeB,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  const aId = backend.dataIdMap.get(a.dataId).id;\n  const bId = backend.dataIdMap.get(b.dataId).id;\n  let biasId = 0;\n  if (bias != null) {\n    const biasData = backend.dataIdMap.get(bias.dataId);\n    if (biasData.shape.length !== 1) {\n      throw new Error(`_FusedMatMul only supports rank-1 bias but got ` + `rank ${biasData.shape.length}.`);\n    }\n    biasId = biasData.id;\n  }\n  const preluActivationWeightsId = preluActivationWeights == null ? 0 : backend.dataIdMap.get(preluActivationWeights.dataId).id;\n  const fusedActivation = FusableActivation[activation];\n  if (fusedActivation == null) {\n    throw new Error(`${activation} activation not yet supported for FusedConv2D ` + `in the wasm backend.`);\n  }\n  const leftDim = transposeA ? a.shape[2] : a.shape[1];\n  const rightDim = transposeB ? b.shape[1] : b.shape[2];\n  const batchDims = broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const out = backend.makeOutput([...batchDims, leftDim, rightDim], a.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);\n  wasmFusedMatMul(aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length, transposeA, transposeB, fusedActivation, biasId, preluActivationWeightsId, leakyreluAlpha || 0, outId);\n  return out;\n}\nexport const _fusedMatMulConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedBatchMatMul\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-wasm/src/kernels/_FusedMatMul.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAyC,cAAc,QAAiC,uBAAuB;AAInI,SAAQ,iBAAiB,QAAO,SAAS;AAEzC,IAAI,eAKQ;AAEZ,SAAS,KAAK,CAAC,OAAoB,EAAA;EACjC,eAAe,GAAG,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,YAAY,EAAE,IAAI,CAAC,YAAY,CAClE,QAAQ,EACR,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,CAAG;EAAA,CACZ,CAAC;AACJ;;AAEA,SAAS,gBAAgB,CAAC,IAIzB,EAAA;EACC,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC,CAAC;IAAE,CAAC;IAAE,IAAI;IAAE;EAAsB,CAAC,GAAG,MAAM;EAEnD,IAAI,CAAC,CAAC,KAAK,KAAK,SAAS,IAAI,CAAC,CAAC,KAAK,KAAK,SAAS,EAAE;IAClD,MAAM,IAAI,KAAK,CACX,6DAA6D,CAAC;EACnE;EAED,MAAM;IAAC,UAAU;IAAE,UAAU;IAAE,UAAU;IAAE;EAAc,CAAC,GAAG,KAAK;EAClE,MAAM,GAAG,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,EAAE;EAC9C,MAAM,GAAG,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,EAAE;EAE9C,IAAI,MAAM,GAAG,CAAC;EACd,IAAI,IAAI,IAAI,IAAI,EAAE;IAChB,MAAM,QAAQ,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC;IACnD,IAAI,QAAQ,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;MAC/B,MAAM,IAAI,KAAK,CACX,iDAAiD,GACjD,QAAQ,QAAQ,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC;IACtC;IACD,MAAM,GAAG,QAAQ,CAAC,EAAE;EACrB;EACD,MAAM,wBAAwB,GAAG,sBAAsB,IAAI,IAAI,GAC3D,CAAC,GACD,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,sBAAsB,CAAC,MAAM,CAAC,CAAC,EAAE;EAC3D,MAAM,eAAe,GACjB,iBAAiB,CAAC,UAAkD,CAAC;EACzE,IAAI,eAAe,IAAI,IAAI,EAAE;IAC3B,MAAM,IAAI,KAAK,CACX,GAAG,UAAU,gDAAgD,GAC7D,sBAAsB,CAAC;EAC5B;EAED,MAAM,OAAO,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;EACpD,MAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;EACrD,MAAM,SAAS,GAAG,cAAc,CAAC,0BAA0B,CACvD,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;EAE/C,MAAM,GAAG,GAAG,OAAO,CAAC,UAAU,CAAC,CAAC,GAAG,SAAS,EAAE,OAAO,EAAE,QAAQ,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC;EAC1E,MAAM,KAAK,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,EAAE;EAElD,MAAM,WAAW,GAAG,IAAI,UAAU,CAAC,IAAI,UAAU,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC;EAClE,MAAM,WAAW,GAAG,IAAI,UAAU,CAAC,IAAI,UAAU,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC;EAElE,eAAe,CACX,GAAG,EAAE,WAAW,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,EAAE,GAAG,EAAE,WAAW,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,EAClE,UAAU,EAAE,UAAU,EAAE,eAAe,EAAE,MAAM,EAAE,wBAAwB,EACzE,cAAc,IAAI,CAAC,EAAE,KAAK,CAAC;EAE/B,OAAO,GAAG;AACZ;AAEA,OAAO,MAAM,kBAAkB,GAAiB;EAC9C,UAAU,EAAE,YAAY;EACxB,WAAW,EAAE,MAAM;EACnB,SAAS,EAAE,KAAK;EAChB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, broadcast_util, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {FusableActivation} from './types';\n\nlet wasmFusedMatMul:\n    (aId: number, aShape: Uint8Array, aShapeSize: number, bId: number,\n     bShape: Uint8Array, bShapeSize: number, transposeA: boolean,\n     transposeB: boolean, activation: number, biasId: number,\n     preluActivationWeightsId: number, leakyreluAlpha: number, outId: number) =>\n        void;\n\nfunction setup(backend: BackendWasm) {\n  wasmFusedMatMul = backend.wasm.cwrap(_FusedMatMul, null /* void */, [\n    'number',  // a_id\n    'array',   // a_shape\n    'number',  // a_shape.length\n    'number',  // b_id\n    'array',   // b_shape\n    'number',  // b_shape.length\n    'number',  // transpose_a\n    'number',  // transpose_b\n    'number',  // activation\n    'number',  // biasId\n    'number',  // preluActivationWeightsId\n    'number',  // leakyreluAlpha\n    'number'   // out_id\n  ]);\n}\n\nfunction fusedBatchMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  backend: BackendWasm,\n  attrs: _FusedMatMulAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(\n        `_FusedMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n  const aId = backend.dataIdMap.get(a.dataId).id;\n  const bId = backend.dataIdMap.get(b.dataId).id;\n\n  let biasId = 0;\n  if (bias != null) {\n    const biasData = backend.dataIdMap.get(bias.dataId);\n    if (biasData.shape.length !== 1) {\n      throw new Error(\n          `_FusedMatMul only supports rank-1 bias but got ` +\n          `rank ${biasData.shape.length}.`);\n    }\n    biasId = biasData.id;\n  }\n  const preluActivationWeightsId = preluActivationWeights == null ?\n      0 :\n      backend.dataIdMap.get(preluActivationWeights.dataId).id;\n  const fusedActivation =\n      FusableActivation[activation as {} as keyof typeof FusableActivation];\n  if (fusedActivation == null) {\n    throw new Error(\n        `${activation} activation not yet supported for FusedConv2D ` +\n        `in the wasm backend.`);\n  }\n\n  const leftDim = transposeA ? a.shape[2] : a.shape[1];\n  const rightDim = transposeB ? b.shape[1] : b.shape[2];\n  const batchDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n\n  const out = backend.makeOutput([...batchDims, leftDim, rightDim], a.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);\n\n  wasmFusedMatMul(\n      aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length,\n      transposeA, transposeB, fusedActivation, biasId, preluActivationWeightsId,\n      leakyreluAlpha || 0, outId);\n\n  return out;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: fusedBatchMatMul as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}