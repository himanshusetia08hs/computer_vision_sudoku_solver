{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer';\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems(items) {\n  return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start) {\n  let i = start;\n  return iteratorFromFunction(() => ({\n    value: i++,\n    done: false\n  }));\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction(func) {\n  return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n  return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped(iterators) {\n  let mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n  return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport class LazyIterator {\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray() {\n    const result = [];\n    let x = await this.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n    return result;\n  }\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArrayForTest() {\n    const stream = this.prefetch(100);\n    const result = [];\n    let x = await stream.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n    return result;\n  }\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveFully() {\n    let x = await this.next();\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveWhile(predicate) {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n    while (!x.done && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n  handleErrors(handler) {\n    return new ErrorHandlingLazyIterator(this, handler);\n  }\n  // TODO(soergel): Implement reduce() etc.\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n  filter(predicate) {\n    return new FilterIterator(this, predicate);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  map(transform) {\n    return new MapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  mapAsync(transform) {\n    return new AsyncMapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  serialMapAsync(transform) {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n  flatmap(transform) {\n    return new FlatmapIterator(this, transform);\n  }\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n  async forEachAsync(f) {\n    return this.map(f).resolveFully();\n  }\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n  async serialForEach(f) {\n    return this.serialMapAsync(f).resolveWhile(x => x === true);\n  }\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n  rowMajorBatch(batchSize) {\n    let smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n  columnMajorBatch(batchSize) {\n    let smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    let zipFn = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : zipToList;\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n    // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n  concatenate(iterator, baseErrorHandler) {\n    return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n  take(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new TakeIterator(this, count);\n  }\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n  skip(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new SkipIterator(this, count);\n  }\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n  prefetch(bufferSize) {\n    return new PrefetchIterator(this, bufferSize);\n  }\n  // TODO(soergel): deep sharded shuffle, where supported\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n  shuffle(windowSize, seed) {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n  serial() {\n    return new SerialIterator(this);\n  }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\nclass ArrayIterator extends LazyIterator {\n  constructor(items) {\n    super();\n    this.items = items;\n    this.trav = 0;\n  }\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n  async next() {\n    if (this.trav >= this.items.length) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n    const item = this.items[this.trav];\n    this.trav++;\n    return {\n      value: deepClone(item),\n      done: false\n    };\n  }\n}\nclass FunctionCallIterator extends LazyIterator {\n  constructor(nextFn) {\n    super();\n    this.nextFn = nextFn;\n  }\n  summary() {\n    return `Function call`;\n  }\n  async next() {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message = `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n}\nclass SerialIterator extends LazyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    return this.upstream.next();\n  }\n}\nclass SkipIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount;\n    // Local state that should not be clobbered by out-of-order execution.\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next();\n      // short-circuit if upstream is already empty\n      if (skipped.done) {\n        return skipped;\n      }\n      tf.dispose(skipped.value);\n    }\n    return this.upstream.next();\n  }\n}\nclass TakeIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount;\n    this.count = 0;\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n  async next() {\n    if (this.count++ >= this.maxCount) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n    return this.upstream.next();\n  }\n}\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator extends LazyIterator {\n  constructor(upstream, batchSize) {\n    let enableSmallLastBatch = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n    super();\n    this.upstream = upstream;\n    this.batchSize = batchSize;\n    this.enableSmallLastBatch = enableSmallLastBatch;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    const batch = [];\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {\n            value: batch,\n            done: false\n          };\n        }\n        return {\n          value: null,\n          done: true\n        };\n      }\n      batch.push(item.value);\n    }\n    return {\n      value: batch,\n      done: false\n    };\n  }\n}\nclass FilterIterator extends LazyIterator {\n  constructor(upstream, predicate) {\n    super();\n    this.upstream = upstream;\n    this.predicate = predicate;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    while (true) {\n      const item = await this.upstream.next();\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n      tf.dispose(item.value);\n    }\n  }\n}\nclass MapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n  async next() {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n}\nclass ErrorHandlingLazyIterator extends LazyIterator {\n  constructor(upstream, handler) {\n    super();\n    this.upstream = upstream;\n    this.handler = handler;\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {\n            value: null,\n            done: true\n          };\n        }\n        // If the handler returns true, loop and fetch the next upstream item.\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n      }\n    }\n  }\n}\n\nclass AsyncMapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n  async next() {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n}\n// Iterators that maintain a queue of pending items\n// ============================================================================\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport class OneToManyIterator extends LazyIterator {\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer();\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  async serialNext() {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!(await this.pump())) {\n        return {\n          value: null,\n          done: true\n        };\n      }\n    }\n    return {\n      value: this.outputQueue.shift(),\n      done: false\n    };\n  }\n}\nclass FlatmapIterator extends OneToManyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n  async pump() {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return false;\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n    // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n    const mappedArray = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n    this.outputQueue.pushAll(mappedArray);\n    // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return true;\n  }\n}\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator extends LazyIterator {\n  constructor(iterators, baseErrorHandler) {\n    super();\n    this.baseErrorHandler = baseErrorHandler;\n    // Strict Promise execution order:\n    // a next() call may not even begin until the previous one completes.\n    this.lastRead = null;\n    // Local state that should not be clobbered by out-of-order execution.\n    this.iterator = null;\n    this.moreIterators = iterators;\n  }\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n  async next() {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n  async readFromChain(lastRead) {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {\n          value: null,\n          done: true\n        };\n      }\n      this.iterator = iteratorResult.value;\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n    const itemResult = await this.iterator.next();\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n    return itemResult;\n  }\n}\nexport var ZipMismatchMode;\n(function (ZipMismatchMode) {\n  ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n  ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n  ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator extends LazyIterator {\n  constructor(iterators) {\n    let mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n    super();\n    this.iterators = iterators;\n    this.mismatchMode = mismatchMode;\n    this.count = 0;\n    this.currentPromise = null;\n  }\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n  async nextState(afterState) {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState;\n    // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n    let numIterators = 0;\n    let iteratorsDone = 0;\n    function getNext(container) {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n            if (x.done) {\n              iteratorsDone++;\n            }\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {\n          value: null,\n          recurse: true\n        };\n      }\n    }\n    const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {\n        value: null,\n        done: true\n      };\n    }\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error('Zipped streams should have the same length. ' + `Mismatched at element ${this.count}.`);\n        case ZipMismatchMode.SHORTEST:\n          return {\n            value: null,\n            done: true\n          };\n        case ZipMismatchMode.LONGEST:\n        default:\n        // Continue.  The exhausted streams already produced value: null.\n      }\n    }\n\n    this.count++;\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n  async next() {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n}\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator extends LazyIterator {\n  constructor(upstream, bufferSize) {\n    super();\n    this.upstream = upstream;\n    this.bufferSize = bufferSize;\n    this.buffer = new RingBuffer(bufferSize);\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n  refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n  next() {\n    this.refill();\n    // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n    return this.buffer.shift();\n  }\n}\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator extends PrefetchIterator {\n  constructor(upstream, windowSize, seed) {\n    super(upstream, windowSize);\n    this.upstream = upstream;\n    this.windowSize = windowSize;\n    // Local state that should not be clobbered by out-of-order execution.\n    this.upstreamExhausted = false;\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n  randomInt(max) {\n    return Math.floor(this.random() * max);\n  }\n  chooseIndex() {\n    return this.randomInt(this.buffer.length());\n  }\n  async serialNext() {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n    return {\n      value: null,\n      done: true\n    };\n  }\n}","map":{"version":3,"sources":["../../src/iterators/lazy_iterator.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBG;AAEH,OAAO,KAAK,EAAE,MAAM,uBAAuB;AAC3C,OAAO,KAAK,UAAU,MAAM,YAAY;AAGxC,SAAQ,SAAS,QAAO,oBAAoB;AAC5C,SAAQ,kBAAkB,EAAqC,OAAO,EAAE,SAAS,QAAO,kBAAkB;AAC1G,SAAQ,iBAAiB,QAAO,6BAA6B;AAC7D,SAAQ,UAAU,QAAO,qBAAqB;AAO9C;AACA;AACA;AAEA;;AAEG;AACH,OAAM,SAAU,iBAAiB,CAAI,KAAU,EAAA;EAC7C,OAAO,IAAI,aAAa,CAAC,KAAK,CAAC;AACjC;AAEA;;AAEG;AACH,OAAM,SAAU,wBAAwB,CAAC,KAAa,EAAA;EACpD,IAAI,CAAC,GAAG,KAAK;EACb,OAAO,oBAAoB,CAAC,OAAO;IAAC,KAAK,EAAE,CAAC,EAAE;IAAE,IAAI,EAAE;EAAK,CAAC,CAAC,CAAC;AAChE;AAEA;;;;;;;;;;;;AAYG;AACH,OAAM,SAAU,oBAAoB,CAChC,IACiD,EAAA;EACnD,OAAO,IAAI,oBAAoB,CAAC,IAAI,CAAC;AACvC;AAEA;;;;;;;;;;;AAWG;AACH,OAAM,SAAU,wBAAwB,CACpC,aAA4C,EAC5C,gBAAwC,EAAA;EAC1C,OAAO,IAAI,eAAe,CAAC,aAAa,EAAE,gBAAgB,CAAC;AAC7D;AAEA;;;;;;;;;;;;;;;AAeG;AACH,OAAM,SAAU,gCAAgC,CAC5C,YAAmD,EAAE,KAAa,EAClE,gBAAwC,EAAA;EAC1C,OAAO,wBAAwB,CAC3B,oBAAoB,CAAC,YAAY,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,gBAAgB,CAAC;AACvE;AAEA;;;;;;;;;;;;;;;;;;;;;;;AAuBG;AACH,OAAM,SAAU,kBAAkB,CAC9B,SAA4B,EACwB;EAAA,IAApD,YAAA,uEAAgC,eAAe,CAAC,IAAI;EACtD,OAAO,IAAI,WAAW,CAAI,SAAS,EAAE,YAAY,CAAC;AACpD;AAEA;;;;;;AAMG;AACH,OAAM,MAAgB,YAAY,CAAA;EAgBhC;;;;;;;AAOG;EACH,MAAM,OAAO,GAAA;IACX,MAAM,MAAM,GAAQ,EAAE;IACtB,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;IACzB,OAAO,CAAC,CAAC,CAAC,IAAI,EAAE;MACd,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC;MACpB,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;IACtB;IACD,OAAO,MAAM;EACf;EAEA;;;;;;;;;;AAUG;EACH,MAAM,cAAc,GAAA;IAClB,MAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC;IACjC,MAAM,MAAM,GAAQ,EAAE;IACtB,IAAI,CAAC,GAAG,MAAM,MAAM,CAAC,IAAI,EAAE;IAC3B,OAAO,CAAC,CAAC,CAAC,IAAI,EAAE;MACd,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC;MACpB,CAAC,GAAG,MAAM,MAAM,CAAC,IAAI,EAAE;IACxB;IACD,OAAO,MAAM;EACf;EAEA;;;;;;AAMG;EACH,MAAM,YAAY,GAAA;IAChB,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;IACzB,OAAO,CAAC,CAAC,CAAC,IAAI,EAAE;MACd,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;IACtB;EACH;EAEA;;;;;;AAMG;EACH,MAAM,YAAY,CAAC,SAA4B,EAAA;IAC7C,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;IACzB,IAAI,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC;IACvC,OAAQ,CAAC,CAAC,CAAC,IAAI,IAAK,cAAc,EAAE;MAClC,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE;MACrB,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC;IACpC;EACH;EAEA;;;;;;;;;;;AAWG;EACH,YAAY,CAAC,OAAkC,EAAA;IAC7C,OAAO,IAAI,yBAAyB,CAAC,IAAI,EAAE,OAAO,CAAC;EACrD;EAEA;EAEA;;;;;;;AAOG;EACH,MAAM,CAAC,SAAgC,EAAA;IACrC,OAAO,IAAI,cAAc,CAAC,IAAI,EAAE,SAAS,CAAC;EAC5C;EAEA;;;;;;;AAOG;EACH,GAAG,CAAI,SAA0B,EAAA;IAC/B,OAAO,IAAI,WAAW,CAAC,IAAI,EAAE,SAAS,CAAC;EACzC;EAEA;;;;;;;AAOG;EACH,QAAQ,CAAI,SAAmC,EAAA;IAC7C,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,SAAS,CAAC;EAC9C;EAEA;;;;;;;AAOG;EACH,cAAc,CAAI,SAAmC,EAAA;IACnD,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC,MAAM,EAAE;EACvD;EAEA;;;;;;;AAOG;EACH,OAAO,CAAI,SAA4B,EAAA;IACrC,OAAO,IAAI,eAAe,CAAC,IAAI,EAAE,SAAS,CAAC;EAC7C;EAEA;;;;AAIG;EACH,MAAM,YAAY,CAAC,CAAqB,EAAA;IACtC,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,YAAY,EAAE;EACnC;EAEA;;;;;;AAMG;EACH,MAAM,aAAa,CAAC,CAAiC,EAAA;IACnD,OAAO,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,IAAK,CAAC,KAAK,IAAK,CAAC;EAC/D;EAEA;;;;;;;;;;;;;;;;;AAiBG;EACH,aAAa,CAAC,SAAiB,EAAuB;IAAA,IAArB,cAAc,uEAAG,IAAI;IACpD,OAAO,IAAI,qBAAqB,CAAC,IAAI,EAAE,SAAS,EAAE,cAAc,CAAC;EACnE;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BG;EACH,gBAAgB,CACZ,SAAiB,EAE8B;IAAA,IAF5B,cAAc,uEAAG,IAAI;IAAA,IAExC,KAAA,uEAAsC,SAAS;IAEjD;IACA,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,SAAS,EAAE,cAAc,CAAC;IAChE;IACA;IACA,OAAO,UAAU,CAAC,GAAG,CAAC,CAAC,IAAI,OAAO,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;EAC/C;EAEA;;;;;;;;;AASG;EACH,WAAW,CACP,QAAyB,EACzB,gBAAwC,EAAA;IAC1C,OAAO,IAAI,eAAe,CACtB,iBAAiB,CAAC,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,EAAE,gBAAgB,CAAC;EAC5D;EAEA;;;;;;AAMG;EACH,IAAI,CAAC,KAAa,EAAA;IAChB,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,IAAI,EAAE;MAC9B,OAAO,IAAI;IACZ;IACD,OAAO,IAAI,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC;EACtC;EAEA;;;;;AAKG;EACH,IAAI,CAAC,KAAa,EAAA;IAChB,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,IAAI,EAAE;MAC9B,OAAO,IAAI;IACZ;IACD,OAAO,IAAI,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC;EACtC;EAEA;;;;;;;;AAQG;EACH,QAAQ,CAAC,UAAkB,EAAA;IACzB,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,UAAU,CAAC;EAC/C;EAEA;EAEA;;;;;;;AAOG;EACH,OAAO,CAAC,UAAkB,EAAE,IAAa,EAAA;IACvC,OAAO,IAAI,eAAe,CAAC,IAAI,EAAE,UAAU,EAAE,IAAI,CAAC;EACpD;EAEA;;;AAGG;EACH,MAAM,GAAA;IACJ,OAAO,IAAI,cAAc,CAAC,IAAI,CAAC;EACjC;AACD;AAED;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA,MAAM,aAAiB,SAAQ,YAAe,CAAA;EAE5C,WAAA,CAAsB,KAAU,EAAA;IAC9B,KAAK,EAAE;IADa,IAAA,CAAA,KAAK,GAAL,KAAK;IADnB,IAAA,CAAA,IAAI,GAAG,CAAC;EAGhB;EAEA,OAAO,GAAA;IACL,OAAO,YAAY,IAAI,CAAC,KAAK,CAAC,MAAM,QAAQ;EAC9C;EAEA,MAAM,IAAI,GAAA;IACR,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE;MAClC,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,IAAI,EAAE;MAAI,CAAC;IACjC;IACD,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC;IAClC,IAAI,CAAC,IAAI,EAAE;IACX,OAAO;MAAC,KAAK,EAAE,SAAS,CAAC,IAAI,CAAC;MAAE,IAAI,EAAE;IAAK,CAAC;EAC9C;AACD;AAED,MAAM,oBAAwB,SAAQ,YAAe,CAAA;EACnD,WAAA,CACc,MAA2D,EAAA;IACvE,KAAK,EAAE;IADK,IAAA,CAAA,MAAM,GAAN,MAAM;EAEpB;EAEA,OAAO,GAAA;IACL,OAAO,eAAe;EACxB;EAEA,MAAM,IAAI,GAAA;IACR,IAAI;MACF,OAAO,IAAI,CAAC,MAAM,EAAE;KACrB,CAAC,OAAO,CAAC,EAAE;MACV;MACA,CAAC,CAAC,OAAO,GACL,mDAAmD,CAAC,CAAC,OAAO,EAAE;MAClE,MAAM,CAAC;IACR;EACH;AACD;AAED,MAAM,cAAkB,SAAQ,YAAe,CAAA;EAK7C,WAAA,CAAsB,QAAyB,EAAA;IAC7C,KAAK,EAAE;IADa,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAE5B,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,YAAY;EAC/C;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,MAAM,UAAU,GAAA;IACtB,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;EAC7B;AACD;AAED,MAAM,YAAgB,SAAQ,YAAe,CAAA;EAQ3C,WAAA,CAAsB,QAAyB,EAAY,QAAgB,EAAA;IACzE,KAAK,EAAE;IADa,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAA6B,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAHnE;IACA,IAAA,CAAA,KAAK,GAAG,CAAC;IAIP,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,UAAU;EAC7C;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,MAAM,UAAU,GAAA;IACtB;IACA;IACA;IACA;IACA,OAAO,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,QAAQ,EAAE;MACnC,MAAM,OAAO,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;MAC1C;MACA,IAAI,OAAO,CAAC,IAAI,EAAE;QAChB,OAAO,OAAO;MACf;MACD,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,KAAW,CAAC;IAChC;IACD,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;EAC7B;AACD;AAED,MAAM,YAAgB,SAAQ,YAAe,CAAA;EAE3C,WAAA,CAAsB,QAAyB,EAAY,QAAgB,EAAA;IACzE,KAAK,EAAE;IADa,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAA6B,IAAA,CAAA,QAAQ,GAAR,QAAQ;IADnE,IAAA,CAAA,KAAK,GAAG,CAAC;EAGT;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,UAAU;EAC7C;EAEA,MAAM,IAAI,GAAA;IACR,IAAI,IAAI,CAAC,KAAK,EAAE,IAAI,IAAI,CAAC,QAAQ,EAAE;MACjC,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,IAAI,EAAE;MAAI,CAAC;IACjC;IACD,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;EAC7B;AACD;AAED;AACA;AACA;AACA,MAAM,qBAAyB,SAAQ,YAAiB,CAAA;EAKtD,WAAA,CACc,QAAyB,EAAY,SAAiB,EAC3B;IAAA,IAA3B,oBAAA,uEAAuB,IAAI;IACvC,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAA6B,IAAA,CAAA,SAAS,GAAT,SAAS;IAC9C,IAAA,CAAA,oBAAoB,GAApB,oBAAoB;IAEhC,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,mBAAmB;EACtD;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,MAAM,UAAU,GAAA;IACtB,MAAM,KAAK,GAAQ,EAAE;IACrB,OAAO,KAAK,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,EAAE;MACpC,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;MACvC,IAAI,IAAI,CAAC,IAAI,EAAE;QACb,IAAI,IAAI,CAAC,oBAAoB,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;UACjD,OAAO;YAAC,KAAK,EAAE,KAAK;YAAE,IAAI,EAAE;UAAK,CAAC;QACnC;QACD,OAAO;UAAC,KAAK,EAAE,IAAI;UAAE,IAAI,EAAE;QAAI,CAAC;MACjC;MACD,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;IACvB;IACD,OAAO;MAAC,KAAK,EAAE,KAAK;MAAE,IAAI,EAAE;IAAK,CAAC;EACpC;AACD;AAED,MAAM,cAAkB,SAAQ,YAAe,CAAA;EAK7C,WAAA,CACc,QAAyB,EACzB,SAAgC,EAAA;IAC5C,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IACR,IAAA,CAAA,SAAS,GAAT,SAAS;IAErB,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,YAAY;EAC/C;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,MAAM,UAAU,GAAA;IACtB,OAAO,IAAI,EAAE;MACX,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;MACvC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;QAC3C,OAAO,IAAI;MACZ;MACD,EAAE,CAAC,OAAO,CAAC,IAAI,CAAC,KAAW,CAAC;IAC7B;EACH;AACD;AAED,MAAM,WAAkB,SAAQ,YAAe,CAAA;EAC7C,WAAA,CACc,QAAyB,EACzB,SAA0B,EAAA;IACtC,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IACR,IAAA,CAAA,SAAS,GAAT,SAAS;EAEvB;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,SAAS;EAC5C;EAEA,MAAM,IAAI,GAAA;IACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;IACvC,IAAI,IAAI,CAAC,IAAI,EAAE;MACb,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,IAAI,EAAE;MAAI,CAAC;IACjC;IACD,MAAM,YAAY,GAAG,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC;IAC3E;IACA;IACA;IACA;IACA;IACA;IACA,MAAM,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC;IACzC,MAAM,aAAa,GAAG,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,MAAY,CAAC;IAExE;IACA;IACA,KAAK,MAAM,CAAC,IAAI,YAAY,EAAE;MAC5B,IAAI,CAAC,EAAE,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;QACpD,CAAC,CAAC,OAAO,EAAE;MACZ;IACF;IACD,OAAO;MAAC,KAAK,EAAE,MAAM;MAAE,IAAI,EAAE;IAAK,CAAC;EACrC;AACD;AAED,MAAM,yBAA6B,SAAQ,YAAe,CAAA;EAExD,WAAA,CACc,QAAyB,EACzB,OAAkC,EAAA;IAC9C,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IACR,IAAA,CAAA,OAAO,GAAP,OAAO;IAHrB,IAAA,CAAA,KAAK,GAAG,CAAC;IAKP,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,kBAAkB;EACrD;EAMA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEA,MAAM,UAAU,GAAA;IACd,OAAO,IAAI,EAAE;MACX,IAAI;QACF,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;OAClC,CAAC,OAAO,CAAC,EAAE;QACV,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;UACpB,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE;UAAI,CAAC;QACjC;QACD;QAEA;QACA;QACA;MACD;IACF;EACH;AACD;;AAED,MAAM,gBAAuB,SAAQ,YAAe,CAAA;EAClD,WAAA,CACc,QAAyB,EACzB,SAAmC,EAAA;IAC/C,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IACR,IAAA,CAAA,SAAS,GAAT,SAAS;EAEvB;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,cAAc;EACjD;EAEA,MAAM,IAAI,GAAA;IACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;IACvC,IAAI,IAAI,CAAC,IAAI,EAAE;MACb,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,IAAI,EAAE;MAAI,CAAC;IACjC;IACD,MAAM,YAAY,GAAG,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC;IAC3E;IACA;IACA;IACA;IACA;IACA;IACA,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC;IAC/C,MAAM,aAAa,GAAG,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,MAAY,CAAC;IAExE;IACA;IACA,KAAK,MAAM,CAAC,IAAI,YAAY,EAAE;MAC5B,IAAI,CAAC,EAAE,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;QACpD,CAAC,CAAC,OAAO,EAAE;MACZ;IACF;IACD,OAAO;MAAC,KAAK,EAAE,MAAM;MAAE,IAAI,EAAE;IAAK,CAAC;EACrC;AACD;AAED;AACA;AAEA;;;;;;;AAOG;AACH,OAAM,MAAgB,iBAAqB,SAAQ,YAAe,CAAA;EAQhE,WAAA,GAAA;IACE,KAAK,EAAE;IACP,IAAI,CAAC,WAAW,GAAG,IAAI,iBAAiB,EAAK;IAC7C,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAgBA,MAAM,UAAU,GAAA;IACd;IACA;IACA;IACA,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,KAAK,CAAC,EAAE;MACtC;MACA,IAAI,EAAC,MAAM,IAAI,CAAC,IAAI,EAAE,GAAE;QACtB,OAAO;UAAC,KAAK,EAAE,IAAI;UAAE,IAAI,EAAE;QAAI,CAAC;MACjC;IACF;IACD,OAAO;MAAC,KAAK,EAAE,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE;MAAE,IAAI,EAAE;IAAK,CAAC;EACvD;AACD;AACD,MAAM,eAAsB,SAAQ,iBAAoB,CAAA;EACtD,WAAA,CACc,QAAyB,EACzB,SAA4B,EAAA;IACxC,KAAK,EAAE;IAFK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IACR,IAAA,CAAA,SAAS,GAAT,SAAS;EAEvB;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,aAAa;EAChD;EAEA,MAAM,IAAI,GAAA;IACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;IACvC,IAAI,IAAI,CAAC,IAAI,EAAE;MACb,OAAO,KAAK;IACb;IACD,MAAM,YAAY,GAAG,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC;IAC3E;IACA;IACA;IACA;IACA;IACA,MAAM,WAAW,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC;IAC9C,MAAM,aAAa,GACf,EAAE,CAAC,WAAW,CAAC,qBAAqB,CAAC,WAAiB,CAAC;IAC3D,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,WAAW,CAAC;IAErC;IACA;IACA,KAAK,MAAM,CAAC,IAAI,YAAY,EAAE;MAC5B,IAAI,CAAC,EAAE,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;QACpD,CAAC,CAAC,OAAO,EAAE;MACZ;IACF;IAED,OAAO,IAAI;EACb;AACD;AAED;;;;;;;;AAQG;AACH,OAAM,MAAO,eAAmB,SAAQ,YAAe,CAAA;EASrD,WAAA,CACI,SAAwC,EACvB,gBAAwC,EAAA;IAC3D,KAAK,EAAE;IADY,IAAA,CAAA,gBAAgB,GAAhB,gBAAgB;IAVrC;IACA;IACQ,IAAA,CAAA,QAAQ,GAA+B,IAAI;IAEnD;IACQ,IAAA,CAAA,QAAQ,GAAoB,IAAI;IAOtC,IAAI,CAAC,aAAa,GAAG,SAAS;EAChC;EAEA,OAAO,GAAA;IACL,MAAM,iBAAiB,GAAG,6CAA6C;IACvE,OAAO,GAAG,iBAAiB,aAAa;EAC1C;EAEA,MAAM,IAAI,GAAA;IACR,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC;IACjD,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,MAAM,aAAa,CAAC,QAAoC,EAAA;IAE9D;IACA;IACA;IACA;IACA;IACA,MAAM,QAAQ;IACd,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;MACzB,MAAM,cAAc,GAAG,MAAM,IAAI,CAAC,aAAa,CAAC,IAAI,EAAE;MACtD,IAAI,cAAc,CAAC,IAAI,EAAE;QACvB;QACA,OAAO;UAAC,KAAK,EAAE,IAAI;UAAE,IAAI,EAAE;QAAI,CAAC;MACjC;MACD,IAAI,CAAC,QAAQ,GAAG,cAAc,CAAC,KAAK;MACpC,IAAI,IAAI,CAAC,gBAAgB,IAAI,IAAI,EAAE;QACjC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,YAAY,CAAC,IAAI,CAAC,gBAAgB,CAAC;MAClE;IACF;IACD,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;IAC7C,IAAI,UAAU,CAAC,IAAI,EAAE;MACnB,IAAI,CAAC,QAAQ,GAAG,IAAI;MACpB,OAAO,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC;IACpC;IACD,OAAO,UAAU;EACnB;AACD;AAED,OAAA,IAAY,eAIX;AAJD,CAAA,UAAY,eAAe,EAAA;EACzB,eAAA,CAAA,eAAA,CAAA,MAAA,CAAA,GAAA,CAAA,CAAA,GAAA,MAAI;EACJ,eAAA,CAAA,eAAA,CAAA,UAAA,CAAA,GAAA,CAAA,CAAA,GAAA,UAAQ;EACR,eAAA,CAAA,eAAA,CAAA,SAAA,CAAA,GAAA,CAAA,CAAA,GAAA,SAAO,CAAA,CAAI;AACb,CAAC,EAJW,eAAe,KAAf,eAAe,GAAA,CAAA,CAAA,CAAA,CAAA;AAM3B;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4BG;AACH,MAAM,WAA0C,SAAQ,YAAe,CAAA;EAIrE,WAAA,CACuB,SAA4B,EACwB;IAAA,IAApD,YAAA,uEAAgC,eAAe,CAAC,IAAI;IACzE,KAAK,EAAE;IAFc,IAAA,CAAA,SAAS,GAAT,SAAS;IACT,IAAA,CAAA,YAAY,GAAZ,YAAY;IAL3B,IAAA,CAAA,KAAK,GAAG,CAAC;IACT,IAAA,CAAA,cAAc,GAA+B,IAAI;EAMzD;EAEA,OAAO,GAAA;IACL,MAAM,iBAAiB,GAAG,yCAAyC;IACnE,OAAO,IAAI,iBAAiB,UAAU;EACxC;EAEQ,MAAM,SAAS,CAAC,UAAsC,EAAA;IAE5D;IACA;IACA,MAAM,UAAU;IAEhB;IACA;IACA,IAAI,YAAY,GAAG,CAAC;IACpB,IAAI,aAAa,GAAG,CAAC;IAErB,SAAS,OAAO,CAAC,SAA4B,EAAA;MAC3C,IAAI,SAAS,YAAY,YAAY,EAAE;QACrC,MAAM,MAAM,GAAG,SAAS,CAAC,IAAI,EAAE;QAC/B,OAAO;UACL,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC,CAAC,IAAG;YACrB,YAAY,EAAE;YACd,IAAI,CAAC,CAAC,IAAI,EAAE;cACV,aAAa,EAAE;YAChB;YACD,OAAO,CAAC,CAAC,KAAK;UAChB,CAAC,CAAC;UACF,OAAO,EAAE;SACV;OACF,MAAM;QACL,OAAO;UAAC,KAAK,EAAE,IAAI;UAAE,OAAO,EAAE;QAAI,CAAC;MACpC;IACH;IAEA,MAAM,MAAM,GAAM,MAAM,kBAAkB,CAAC,IAAI,CAAC,SAAS,EAAE,OAAO,CAAC;IAEnE,IAAI,YAAY,KAAK,aAAa,EAAE;MAClC;MACA,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,IAAI,EAAE;MAAI,CAAC;IACjC;IACD,IAAI,aAAa,GAAG,CAAC,EAAE;MACrB,QAAQ,IAAI,CAAC,YAAY;QACvB,KAAK,eAAe,CAAC,IAAI;UACvB,MAAM,IAAI,KAAK,CACX,8CAA8C,GAC9C,yBAAyB,IAAI,CAAC,KAAK,GAAG,CAAC;QAC7C,KAAK,eAAe,CAAC,QAAQ;UAC3B,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE;UAAI,CAAC;QAClC,KAAK,eAAe,CAAC,OAAO;QAC5B;QACE;MAAA;IAEL;;IAED,IAAI,CAAC,KAAK,EAAE;IACZ,OAAO;MAAC,KAAK,EAAE,MAAM;MAAE,IAAI,EAAE;IAAK,CAAC;EACrC;EAEA,MAAM,IAAI,GAAA;IACR,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,cAAc,CAAC;IACzD,OAAO,IAAI,CAAC,cAAc;EAC5B;AACD;AAED;AACA;AAEA;;;;;;AAMG;AACH,OAAM,MAAO,gBAAoB,SAAQ,YAAe,CAAA;EAGtD,WAAA,CACc,QAAyB,EAAY,UAAkB,EAAA;IACnE,KAAK,EAAE;IADK,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAA6B,IAAA,CAAA,UAAU,GAAV,UAAU;IAE3D,IAAI,CAAC,MAAM,GAAG,IAAI,UAAU,CAA6B,UAAU,CAAC;EACtE;EAEA,OAAO,GAAA;IACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,cAAc;EACjD;EAEA;;;AAGG;EACO,MAAM,GAAA;IACd,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,EAAE;MAC5B,MAAM,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE;MAC9B,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;IACpB;EACH;EAEA,IAAI,GAAA;IACF,IAAI,CAAC,MAAM,EAAE;IACb;IACA;IACA;IACA,OAAO,IAAI,CAAC,MAAM,CAAC,KAAK,EAAE;EAC5B;AACD;AAED;;;;;AAKG;AACH,OAAM,MAAO,eAAmB,SAAQ,gBAAmB,CAAA;EAUzD,WAAA,CACc,QAAyB,EAAY,UAAkB,EACjE,IAAa,EAAA;IACf,KAAK,CAAC,QAAQ,EAAE,UAAU,CAAC;IAFf,IAAA,CAAA,QAAQ,GAAR,QAAQ;IAA6B,IAAA,CAAA,UAAU,GAAV,UAAU;IAJ7D;IACQ,IAAA,CAAA,iBAAiB,GAAG,KAAK;IAM/B,IAAI,CAAC,MAAM,GAAG,UAAU,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,QAAQ,EAAE,CAAC;IAC/D,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAK,CAAC,CAAC;EAC7D;EAEA,MAAM,IAAI,GAAA;IACR;IACA;IACA;IACA;IACA,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;IAC3D,OAAO,IAAI,CAAC,QAAQ;EACtB;EAEQ,SAAS,CAAC,GAAW,EAAA;IAC3B,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC;EACxC;EAEU,WAAW,GAAA;IACnB,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC;EAC7C;EAEA,MAAM,UAAU,GAAA;IACd;IACA,IAAI,CAAC,IAAI,CAAC,iBAAiB,EAAE;MAC3B,IAAI,CAAC,MAAM,EAAE;IACd;IACD,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE,EAAE;MAC7B,MAAM,WAAW,GAAG,IAAI,CAAC,WAAW,EAAE;MACtC,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,WAAW,CAAC;MAC3D,IAAI,MAAM,CAAC,IAAI,EAAE;QACf,IAAI,CAAC,iBAAiB,GAAG,IAAI;OAC9B,MAAM;QACL,IAAI,CAAC,MAAM,EAAE;QACb,OAAO,MAAM;MACd;IACF;IACD,OAAO;MAAC,KAAK,EAAE,IAAI;MAAE,IAAI,EAAE;IAAI,CAAC;EAClC;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer';\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems(items) {\n    return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start) {\n    let i = start;\n    return iteratorFromFunction(() => ({ value: i++, done: false }));\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction(func) {\n    return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n    return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n    return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n    return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport class LazyIterator {\n    /**\n     * Collect all remaining elements of a bounded stream into an array.\n     * Obviously this will succeed only for small streams that fit in memory.\n     * Useful for testing.\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    async toArray() {\n        const result = [];\n        let x = await this.next();\n        while (!x.done) {\n            result.push(x.value);\n            x = await this.next();\n        }\n        return result;\n    }\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    async toArrayForTest() {\n        const stream = this.prefetch(100);\n        const result = [];\n        let x = await stream.next();\n        while (!x.done) {\n            result.push(x.value);\n            x = await stream.next();\n        }\n        return result;\n    }\n    /**\n     * Draw items from the stream until it is exhausted.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    async resolveFully() {\n        let x = await this.next();\n        while (!x.done) {\n            x = await this.next();\n        }\n    }\n    /**\n     * Draw items from the stream until it is exhausted, or a predicate fails.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    async resolveWhile(predicate) {\n        let x = await this.next();\n        let shouldContinue = predicate(x.value);\n        while ((!x.done) && shouldContinue) {\n            x = await this.next();\n            shouldContinue = predicate(x.value);\n        }\n    }\n    /**\n     * Handles errors thrown on this stream using a provided handler function.\n     *\n     * @param handler A function that handles any `Error` thrown during a `next()`\n     *   call and returns true if the stream should continue (dropping the failed\n     *   call) or false if the stream should quietly terminate.  If the handler\n     *   itself throws (or rethrows) an `Error`, that will be propagated.\n     *\n     * @returns A `LazyIterator` of elements passed through from upstream,\n     *   possibly filtering or terminating on upstream `next()` calls that\n     *   throw an `Error`.\n     */\n    handleErrors(handler) {\n        return new ErrorHandlingLazyIterator(this, handler);\n    }\n    // TODO(soergel): Implement reduce() etc.\n    /**\n     * Filters this stream according to `predicate`.\n     *\n     * @param predicate A function mapping a stream element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `LazyIterator` of elements for which the predicate was true.\n     */\n    filter(predicate) {\n        return new FilterIterator(this, predicate);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    map(transform) {\n        return new MapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through an async 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a `Promise` for a\n     *   transformed stream element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    mapAsync(transform) {\n        return new AsyncMapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform, forcing serial execution.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    serialMapAsync(transform) {\n        return new AsyncMapIterator(this, transform).serial();\n    }\n    /**\n     * Maps this stream through a 1-to-many transform.\n     *\n     * @param transform A function mapping a stream element to an array of\n     *   transformed elements.\n     *\n     * @returns A `DataStream` of transformed elements.\n     */\n    flatmap(transform) {\n        return new FlatmapIterator(this, transform);\n    }\n    /**\n     * Apply a function to every element of the stream.\n     *\n     * @param f A function to apply to each stream element.\n     */\n    async forEachAsync(f) {\n        return this.map(f).resolveFully();\n    }\n    /**\n     * Apply a function to every element of the stream, forcing serial execution.\n     *\n     * @param f A function to apply to each stream element.  Should return 'true'\n     *   to indicate that the stream should continue, or 'false' to cause it to\n     *   terminate.\n     */\n    async serialForEach(f) {\n        return this.serialMapAsync(f).resolveWhile(x => (x === true));\n    }\n    /**\n     * Groups elements into batches, represented as arrays of elements.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n     * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n     * form, which is needed for vectorized computation.\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `LazyIterator` of batches of elements, represented as arrays\n     *   of the original element type.\n     */\n    rowMajorBatch(batchSize, smallLastBatch = true) {\n        return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n    }\n    /**\n     * Groups elements into batches, represented in column-major form.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"column-major\" means that the resulting batch is a (potentially\n     * nested) structure representing the columns.  Each column entry, then,\n     * contains a collection of the values found in that column for a range of\n     * input elements.  This representation allows for vectorized computation, in\n     * contrast to the row-major form.\n     *\n     * The inputs should all have the same nested structure (i.e., of arrays and\n     * dicts).  The result is a single object with the same nested structure,\n     * where the leaves are arrays collecting the values of the inputs at that\n     * location (or, optionally, the result of a custom function applied to those\n     * arrays).\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @param zipFn: (optional) A function that expects an array of elements at a\n     *   single node of the object tree, and returns a `DeepMapResult`.  The\n     *   `DeepMapResult` either provides a result value for that node (i.e.,\n     *   representing the subtree), or indicates that the node should be processed\n     *   recursively.  The default zipFn recurses as far as possible and places\n     *   arrays at the leaves.\n     * @returns A `LazyIterator` of batches of elements, represented as an object\n     *   with collections at the leaves.\n     */\n    columnMajorBatch(batchSize, smallLastBatch = true, \n    // tslint:disable-next-line:no-any\n    zipFn = zipToList) {\n        // First collect the desired number of input elements as a row-major batch.\n        const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n        // Now 'rotate' or 'pivot' the data, collecting all values from each column\n        // in the batch (i.e., for each key within the elements) into an array.\n        return rowBatches.map(x => deepZip(x, zipFn));\n    }\n    /**\n     * Concatenate this `LazyIterator` with another.\n     *\n     * @param iterator A `LazyIterator` to be concatenated onto this one.\n     * @param baseErrorHandler An optional function that can intercept `Error`s\n     *   raised during a `next()` call on the base stream.  This function can\n     *   decide whether the error should be propagated, whether the error should\n     *   be ignored, or whether the base stream should be terminated.\n     * @returns A `LazyIterator`.\n     */\n    concatenate(iterator, baseErrorHandler) {\n        return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n    }\n    /**\n     * Limits this stream to return at most `count` items.\n     *\n     * @param count The maximum number of items to provide from the stream. If\n     * a negative or undefined value is given, the entire stream is returned\n     *   unaltered.\n     */\n    take(count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new TakeIterator(this, count);\n    }\n    /**\n     * Skips the first `count` items in this stream.\n     *\n     * @param count The number of items to skip.  If a negative or undefined\n     * value is given, the entire stream is returned unaltered.\n     */\n    skip(count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new SkipIterator(this, count);\n    }\n    /**\n     * Prefetch the first `bufferSize` items in this stream.\n     *\n     * Note this prefetches Promises, but makes no guarantees about when those\n     * Promises resolve.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     */\n    prefetch(bufferSize) {\n        return new PrefetchIterator(this, bufferSize);\n    }\n    // TODO(soergel): deep sharded shuffle, where supported\n    /**\n     * Randomly shuffles the elements of this stream.\n     *\n     * @param bufferSize: An integer specifying the number of elements from\n     * this stream from which the new stream will sample.\n     * @param seed: (Optional.) An integer specifying the random seed that\n     * will be used to create the distribution.\n     */\n    shuffle(windowSize, seed) {\n        return new ShuffleIterator(this, windowSize, seed);\n    }\n    /**\n     * Force an iterator to execute serially: each next() call will await the\n     * prior one, so that they cannot execute concurrently.\n     */\n    serial() {\n        return new SerialIterator(this);\n    }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\nclass ArrayIterator extends LazyIterator {\n    constructor(items) {\n        super();\n        this.items = items;\n        this.trav = 0;\n    }\n    summary() {\n        return `Array of ${this.items.length} items`;\n    }\n    async next() {\n        if (this.trav >= this.items.length) {\n            return { value: null, done: true };\n        }\n        const item = this.items[this.trav];\n        this.trav++;\n        return { value: deepClone(item), done: false };\n    }\n}\nclass FunctionCallIterator extends LazyIterator {\n    constructor(nextFn) {\n        super();\n        this.nextFn = nextFn;\n    }\n    summary() {\n        return `Function call`;\n    }\n    async next() {\n        try {\n            return this.nextFn();\n        }\n        catch (e) {\n            // Modify the error message but leave the stack trace intact\n            e.message =\n                `Error thrown while iterating through a dataset: ${e.message}`;\n            throw e;\n        }\n    }\n}\nclass SerialIterator extends LazyIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Serial`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        return this.upstream.next();\n    }\n}\nclass SkipIterator extends LazyIterator {\n    constructor(upstream, maxCount) {\n        super();\n        this.upstream = upstream;\n        this.maxCount = maxCount;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.count = 0;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Skip`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n        // collecting next() promises in an Array and then waiting for\n        // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n        // maybe delayed GC.\n        while (this.count++ < this.maxCount) {\n            const skipped = await this.upstream.next();\n            // short-circuit if upstream is already empty\n            if (skipped.done) {\n                return skipped;\n            }\n            tf.dispose(skipped.value);\n        }\n        return this.upstream.next();\n    }\n}\nclass TakeIterator extends LazyIterator {\n    constructor(upstream, maxCount) {\n        super();\n        this.upstream = upstream;\n        this.maxCount = maxCount;\n        this.count = 0;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Take`;\n    }\n    async next() {\n        if (this.count++ >= this.maxCount) {\n            return { value: null, done: true };\n        }\n        return this.upstream.next();\n    }\n}\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator extends LazyIterator {\n    constructor(upstream, batchSize, enableSmallLastBatch = true) {\n        super();\n        this.upstream = upstream;\n        this.batchSize = batchSize;\n        this.enableSmallLastBatch = enableSmallLastBatch;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> RowMajorBatch`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        const batch = [];\n        while (batch.length < this.batchSize) {\n            const item = await this.upstream.next();\n            if (item.done) {\n                if (this.enableSmallLastBatch && batch.length > 0) {\n                    return { value: batch, done: false };\n                }\n                return { value: null, done: true };\n            }\n            batch.push(item.value);\n        }\n        return { value: batch, done: false };\n    }\n}\nclass FilterIterator extends LazyIterator {\n    constructor(upstream, predicate) {\n        super();\n        this.upstream = upstream;\n        this.predicate = predicate;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Filter`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        while (true) {\n            const item = await this.upstream.next();\n            if (item.done || this.predicate(item.value)) {\n                return item;\n            }\n            tf.dispose(item.value);\n        }\n    }\n}\nclass MapIterator extends LazyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Map`;\n    }\n    async next() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return { value: null, done: true };\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // That's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying\n        // any intermediate Tensors.  Here we are concerned only about the\n        // inputs.\n        const mapped = this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n        // TODO(soergel) faster intersection\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return { value: mapped, done: false };\n    }\n}\nclass ErrorHandlingLazyIterator extends LazyIterator {\n    constructor(upstream, handler) {\n        super();\n        this.upstream = upstream;\n        this.handler = handler;\n        this.count = 0;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> handleErrors`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        while (true) {\n            try {\n                return await this.upstream.next();\n            }\n            catch (e) {\n                if (!this.handler(e)) {\n                    return { value: null, done: true };\n                }\n                // If the handler returns true, loop and fetch the next upstream item.\n                // If the upstream iterator throws an endless stream of errors, and if\n                // the handler says to ignore them, then we loop forever here.  That is\n                // the correct behavior-- it's up to the handler to decide when to stop.\n            }\n        }\n    }\n}\nclass AsyncMapIterator extends LazyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> AsyncMap`;\n    }\n    async next() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return { value: null, done: true };\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // That's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying\n        // any intermediate Tensors.  Here we are concerned only about the\n        // inputs.\n        const mapped = await this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n        // TODO(soergel) faster intersection\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return { value: mapped, done: false };\n    }\n}\n// Iterators that maintain a queue of pending items\n// ============================================================================\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport class OneToManyIterator extends LazyIterator {\n    constructor() {\n        super();\n        this.outputQueue = new GrowingRingBuffer();\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        // Fetch so that the queue contains at least one item if possible.\n        // If the upstream source is exhausted, AND there are no items left in\n        // the output queue, then this stream is also exhausted.\n        while (this.outputQueue.length() === 0) {\n            // TODO(soergel): consider parallel reads.\n            if (!await this.pump()) {\n                return { value: null, done: true };\n            }\n        }\n        return { value: this.outputQueue.shift(), done: false };\n    }\n}\nclass FlatmapIterator extends OneToManyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Flatmap`;\n    }\n    async pump() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return false;\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // that's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying any\n        // intermediate Tensors.  Here we are concerned only about the inputs.\n        const mappedArray = this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n        this.outputQueue.pushAll(mappedArray);\n        // TODO(soergel) faster intersection, and deduplicate outputTensors\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return true;\n    }\n}\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator extends LazyIterator {\n    constructor(iterators, baseErrorHandler) {\n        super();\n        this.baseErrorHandler = baseErrorHandler;\n        // Strict Promise execution order:\n        // a next() call may not even begin until the previous one completes.\n        this.lastRead = null;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.iterator = null;\n        this.moreIterators = iterators;\n    }\n    summary() {\n        const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n        return `${upstreamSummaries} -> Chained`;\n    }\n    async next() {\n        this.lastRead = this.readFromChain(this.lastRead);\n        return this.lastRead;\n    }\n    async readFromChain(lastRead) {\n        // Must await on the previous read since the previous read may have advanced\n        // the stream of streams, from which we need to read.\n        // This is unfortunate since we can't parallelize reads. Which means\n        // prefetching of chained streams is a no-op.\n        // One solution is to prefetch immediately upstream of this.\n        await lastRead;\n        if (this.iterator == null) {\n            const iteratorResult = await this.moreIterators.next();\n            if (iteratorResult.done) {\n                // No more streams to stream from.\n                return { value: null, done: true };\n            }\n            this.iterator = iteratorResult.value;\n            if (this.baseErrorHandler != null) {\n                this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n            }\n        }\n        const itemResult = await this.iterator.next();\n        if (itemResult.done) {\n            this.iterator = null;\n            return this.readFromChain(lastRead);\n        }\n        return itemResult;\n    }\n}\nexport var ZipMismatchMode;\n(function (ZipMismatchMode) {\n    ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n    ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n    ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator extends LazyIterator {\n    constructor(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n        super();\n        this.iterators = iterators;\n        this.mismatchMode = mismatchMode;\n        this.count = 0;\n        this.currentPromise = null;\n    }\n    summary() {\n        const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n        return `{${upstreamSummaries}} -> Zip`;\n    }\n    async nextState(afterState) {\n        // This chaining ensures that the underlying next() are not even called\n        // before the previous ones have resolved.\n        await afterState;\n        // Collect underlying iterator \"done\" signals as a side effect in\n        // getNext()\n        let numIterators = 0;\n        let iteratorsDone = 0;\n        function getNext(container) {\n            if (container instanceof LazyIterator) {\n                const result = container.next();\n                return {\n                    value: result.then(x => {\n                        numIterators++;\n                        if (x.done) {\n                            iteratorsDone++;\n                        }\n                        return x.value;\n                    }),\n                    recurse: false\n                };\n            }\n            else {\n                return { value: null, recurse: true };\n            }\n        }\n        const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n        if (numIterators === iteratorsDone) {\n            // The streams have all ended.\n            return { value: null, done: true };\n        }\n        if (iteratorsDone > 0) {\n            switch (this.mismatchMode) {\n                case ZipMismatchMode.FAIL:\n                    throw new Error('Zipped streams should have the same length. ' +\n                        `Mismatched at element ${this.count}.`);\n                case ZipMismatchMode.SHORTEST:\n                    return { value: null, done: true };\n                case ZipMismatchMode.LONGEST:\n                default:\n                // Continue.  The exhausted streams already produced value: null.\n            }\n        }\n        this.count++;\n        return { value: mapped, done: false };\n    }\n    async next() {\n        this.currentPromise = this.nextState(this.currentPromise);\n        return this.currentPromise;\n    }\n}\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator extends LazyIterator {\n    constructor(upstream, bufferSize) {\n        super();\n        this.upstream = upstream;\n        this.bufferSize = bufferSize;\n        this.buffer = new RingBuffer(bufferSize);\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Prefetch`;\n    }\n    /**\n     * Refill the prefetch buffer.  Returns only after the buffer is full, or\n     * the upstream source is exhausted.\n     */\n    refill() {\n        while (!this.buffer.isFull()) {\n            const v = this.upstream.next();\n            this.buffer.push(v);\n        }\n    }\n    next() {\n        this.refill();\n        // This shift will never throw an error because the buffer is always\n        // full after a refill. If the stream is exhausted, the buffer will be\n        // full of Promises that will resolve to the end-of-stream signal.\n        return this.buffer.shift();\n    }\n}\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator extends PrefetchIterator {\n    constructor(upstream, windowSize, seed) {\n        super(upstream, windowSize);\n        this.upstream = upstream;\n        this.windowSize = windowSize;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.upstreamExhausted = false;\n        this.random = seedrandom.alea(seed || tf.util.now().toString());\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    randomInt(max) {\n        return Math.floor(this.random() * max);\n    }\n    chooseIndex() {\n        return this.randomInt(this.buffer.length());\n    }\n    async serialNext() {\n        // TODO(soergel): consider performance\n        if (!this.upstreamExhausted) {\n            this.refill();\n        }\n        while (!this.buffer.isEmpty()) {\n            const chosenIndex = this.chooseIndex();\n            const result = await this.buffer.shuffleExcise(chosenIndex);\n            if (result.done) {\n                this.upstreamExhausted = true;\n            }\n            else {\n                this.refill();\n                return result;\n            }\n        }\n        return { value: null, done: true };\n    }\n}\n//# sourceMappingURL=lazy_iterator.js.map"]},"metadata":{},"sourceType":"module"}