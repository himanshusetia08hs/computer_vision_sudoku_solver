{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = this && this.__rest || function (s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\") for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n    if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];\n  }\n  return t;\n};\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\nclass ConvRNN2DCell extends RNNCell {}\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n  constructor(args) {\n    if (args.unroll) {\n      throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n    }\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n    }\n    super(args);\n    this.inputSpec = [new InputSpec({\n      ndim: 5\n    })];\n  }\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n        this.cell.dropoutMask = null;\n      }\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n        this.cell.recurrentDropoutMask = null;\n      }\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n      const mask = kwargs == null ? null : kwargs['mask'];\n      const training = kwargs == null ? null : kwargs['training'];\n      const initialState = kwargs == null ? null : kwargs['initialState'];\n      return super.call(inputs, {\n        mask,\n        training,\n        initialState\n      });\n    });\n  }\n  computeOutputShape(inputShape) {\n    let outShape = this.computeSingleOutputShape(inputShape);\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n    if (this.returnState) {\n      outShape = [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n    return outShape;\n  }\n  getInitialState(inputs) {\n    return tfc.tidy(() => {\n      const {\n        stateSize\n      } = this.cell;\n      const inputShape = inputs.shape;\n      const outputShape = this.computeSingleOutputShape(inputShape);\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n      const initialState = tfc.zeros(stateShape);\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n      return [initialState];\n    });\n  }\n  resetStates(states) {\n    let training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n      const inputShape = this.inputSpec[0].shape;\n      const outputShape = this.computeSingleOutputShape(inputShape);\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n      const batchSize = inputShape[0];\n      if (batchSize == null) {\n        throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n      }\n      // Initialize state if null.\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n        if (states.length !== this.states_.length) {\n          throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), ` + `but it received ${states.length} state value(s). Input ` + `received: ${states}`);\n        }\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n          const expectedShape = stateShape;\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(`State ${index} is incompatible with layer ${this.name}: ` + `expected shape=${expectedShape}, received shape=${value.shape}`);\n          }\n          this.states_[index] = value;\n        }\n      }\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n  computeSingleOutputShape(inputShape) {\n    const {\n      dataFormat,\n      filters,\n      kernelSize,\n      padding,\n      strides,\n      dilationRate\n    } = this.cell;\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n    const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n    const outShape = [...inputShape.slice(0, 2), ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])];\n    return outShape;\n  }\n}\n/** @nocollapse */\nConvRNN2D.className = 'ConvRNN2D';\nexport class ConvLSTM2DCell extends LSTMCell {\n  constructor(args) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate\n    } = args;\n    super(Object.assign(Object.assign({}, args), {\n      units: filters\n    }));\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n  build(inputShape) {\n    var _a;\n    inputShape = getExactlyOneShape(inputShape);\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(`The channel dimension of the input should be defined. ` + `Found ${inputShape[channelAxis]}`);\n    }\n    const inputDim = inputShape[channelAxis];\n    const numOfKernels = 4;\n    const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n    this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n    const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n    this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n    if (this.useBias) {\n      let biasInitializer;\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n        const filters = this.filters;\n        biasInitializer = new (_a = class CustomInit extends Initializer {\n          apply(shape, dtype) {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n        }, /** @nocollapse */\n        _a.className = 'CustomInit', _a)();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n      this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    }\n    this.built = true;\n  }\n  call(inputs, kwargs) {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` + `${inputs.length}.`);\n      }\n      const training = kwargs['training'] || false;\n      const x = inputs[0]; // Current input\n      const hTMinus1 = inputs[1]; // Previous memory state.\n      const cTMinus1 = inputs[2]; // Previous carry state.\n      const numOfKernels = 4;\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n          ones: () => tfc.onesLike(x),\n          rate: this.dropout,\n          training,\n          count: numOfKernels,\n          dropoutFunc: this.dropoutFunc\n        });\n      }\n      const dropoutMask = this.dropoutMask;\n      const applyDropout = (x, mask, index) => {\n        if (!mask || !mask[index]) {\n          return x;\n        }\n        return tfc.mul(mask[index], x);\n      };\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n          ones: () => tfc.onesLike(hTMinus1),\n          rate: this.recurrentDropout,\n          training,\n          count: numOfKernels,\n          dropoutFunc: this.dropoutFunc\n        });\n      }\n      const recDropoutMask = this.recurrentDropoutMask;\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n      const kernelChannelAxis = 3;\n      const [kernelI, kernelF, kernelC, kernelO] = tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n      const [biasI, biasF, biasC, biasO] = this.useBias ? tfc.split(this.bias.read(), numOfKernels) : [null, null, null, null];\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n      const [recKernelI, recKernelF, recKernelC, recKernelO] = tfc.split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(this.recurrentActivation.apply(tfc.add(xO, hO)), this.activation.apply(c));\n      return [h, h, c];\n    });\n  }\n  getConfig() {\n    const _a = super.getConfig(),\n      {\n        'units': _\n      } = _a,\n      baseConfig = __rest(_a, ['units']);\n    const config = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides\n    };\n    return Object.assign(Object.assign({}, baseConfig), config);\n  }\n  inputConv(x, w, b, padding) {\n    const out = tfc.conv2d(x, w, this.strides, padding || 'valid', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat);\n    }\n    return out;\n  }\n  recurrentConv(x, w) {\n    const strides = 1;\n    return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n}\n/** @nocollapse */\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport class ConvLSTM2D extends ConvRNN2D {\n  constructor(args) {\n    const cell = new ConvLSTM2DCell(args);\n    super(Object.assign(Object.assign({}, args), {\n      cell\n    }));\n  }\n  /** @nocollapse */\n  static fromConfig(cls, config) {\n    return new cls(config);\n  }\n}\n/** @nocollapse */\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);","map":{"version":3,"sources":["../../../../../../tfjs-layers/src/layers/convolutional_recurrent.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;;;;;;;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB;AAC5C,SAAgB,IAAI,QAAO,uBAAuB;AAGlD,OAAO,KAAK,CAAC,MAAM,yBAAyB;AAC5C,SAAQ,eAAe,EAAE,gBAAgB,QAAO,WAAW;AAE3D,SAAQ,SAAS,QAAO,oBAAoB;AAC5C,SAAQ,cAAc,EAAE,mBAAmB,EAAE,UAAU,QAAO,WAAW;AACzE,SAAQ,WAAW,QAAO,iBAAiB;AAI3C,SAAQ,gBAAgB,EAAE,cAAc,QAAO,qBAAqB;AACpE,SAAQ,qBAAqB,QAAO,wBAAwB;AAC5D,SAAQ,kBAAkB,QAAO,sBAAsB;AAEvD,SAA0B,mBAAmB,EAAE,QAAQ,EAAoC,GAAG,EAAE,OAAO,QAA6C,aAAa;AAsDjK,MAAe,aAAc,SAAQ,OAAO,CAAA;AA8B5C;;AAEG;AACH,MAAM,SAAU,SAAQ,GAAG,CAAA;EAMzB,WAAA,CAAY,IAAwB,EAAA;IAClC,IAAI,IAAI,CAAC,MAAM,EAAE;MACf,MAAM,IAAI,mBAAmB,CACzB,oDAAoD,CAAC;IAC1D;IAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;MAC5B,MAAM,IAAI,mBAAmB,CACzB,gEAAgE,CAAC;IACtE;IAED,KAAK,CAAC,IAAoB,CAAC;IAE3B,IAAI,CAAC,SAAS,GAAG,CAAC,IAAI,SAAS,CAAC;MAAC,IAAI,EAAE;IAAC,CAAC,CAAC,CAAC;EAC7C;EAES,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;IACnD,OAAO,GAAG,CAAC,IAAI,CAAC,MAAK;MACnB,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;QACjC,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC;QAElC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI;MAC7B;MAED,IAAI,IAAI,CAAC,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;QAC1C,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC;QAE3C,IAAI,CAAC,IAAI,CAAC,oBAAoB,GAAG,IAAI;MACtC;MAED,IAAI,MAAM,IAAI,MAAM,CAAC,WAAW,CAAC,EAAE;QACjC,MAAM,IAAI,UAAU,CAAC,2CAA2C,CAAC;MAClE;MAED,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,GAAG,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC;MAEnD,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,GAAG,IAAI,GAAG,MAAM,CAAC,UAAU,CAAC;MAE3D,MAAM,YAAY,GACd,MAAM,IAAI,IAAI,GAAG,IAAI,GAAG,MAAM,CAAC,cAAc,CAAC;MAElD,OAAO,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE;QAAC,IAAI;QAAE,QAAQ;QAAE;MAAY,CAAC,CAAC;IAC3D,CAAC,CAAC;EACJ;EAES,kBAAkB,CAAC,UAAiB,EAAA;IAC3C,IAAI,QAAQ,GAAU,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC;IAE/D,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE;MACzB,QAAQ,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IAC/C;IAED,IAAI,IAAI,CAAC,WAAW,EAAE;MACpB,QAAQ,GACJ,CAAC,QAAQ,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACzE;IAED,OAAO,QAAQ;EACjB;EAES,eAAe,CAAC,MAAkB,EAAA;IACzC,OAAO,GAAG,CAAC,IAAI,CAAC,MAAK;MACnB,MAAM;QAAC;MAAS,CAAC,GAAG,IAAI,CAAC,IAAI;MAE7B,MAAM,UAAU,GAAG,MAAM,CAAC,KAAK;MAE/B,MAAM,WAAW,GAAG,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC;MAE7D,MAAM,UAAU,GAAG,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,GAAG,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;MAE5D,MAAM,YAAY,GAAG,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC;MAE1C,IAAI,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,EAAE;QAC5B,OAAO,KAAK,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC;MAClD;MAED,OAAO,CAAC,YAAY,CAAC;IACvB,CAAC,CAAC;EACJ;EAES,WAAW,CAAC,MAAwB,EAAkB;IAAA,IAAhB,QAAQ,uEAAG,KAAK;IAC7D,GAAG,CAAC,IAAI,CAAC,MAAK;MACZ,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;QAClB,MAAM,IAAI,cAAc,CACpB,iEAAiE,CAAC;MACvE;MAED,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK;MAE1C,MAAM,WAAW,GAAG,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC;MAE7D,MAAM,UAAU,GAAG,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,GAAG,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;MAE5D,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC;MAE/B,IAAI,SAAS,IAAI,IAAI,EAAE;QACrB,MAAM,IAAI,UAAU,CAChB,kEAAkE,GAClE,0CAA0C,GAC1C,2DAA2D,GAC3D,2DAA2D,GAC3D,2DAA2D,GAC3D,oDAAoD,CAAC;MAC1D;MAED;MACA,IAAI,IAAI,CAAC,SAAS,EAAE,IAAI,IAAI,EAAE;QAC5B,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;UACtC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;SACpE,MAAM;UACL,IAAI,CAAC,OAAO,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;QACvC;OACF,MAAM,IAAI,MAAM,IAAI,IAAI,EAAE;QACzB;QACA,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC;QAEzB;QACA,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;UAC3B,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,CAAC;UAC5B,IAAI,CAAC,UAAU,GAAG,EAAE;QACrB;QAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;UACtC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;SACpE,MAAM;UACL,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC;QACxC;OACF,MAAM;QACL,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;UAC1B,MAAM,GAAG,CAAC,MAAM,CAAC;QAClB;QAED,IAAI,MAAM,CAAC,MAAM,KAAK,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;UACzC,MAAM,IAAI,UAAU,CAChB,SAAS,IAAI,CAAC,IAAI,YAAY,IAAI,CAAC,OAAO,CAAC,MAAM,aAAa,GAC9D,mBAAmB,MAAM,CAAC,MAAM,yBAAyB,GACzD,aAAa,MAAM,EAAE,CAAC;QAC3B;QAED,IAAI,QAAQ,EAAE;UACZ;UACA;UACA;UACA;UACA,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC;SAC3C,MAAM;UACL,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC;QAC1B;QAED,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,KAAK,EAAE;UACxD,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC;UAE3B,MAAM,aAAa,GAAG,UAAU;UAEhC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,KAAK,EAAE,aAAa,CAAC,EAAE;YACjD,MAAM,IAAI,UAAU,CAChB,SAAS,KAAK,+BAA+B,IAAI,CAAC,IAAI,IAAI,GAC1D,kBAAkB,aAAa,oBAC3B,KAAK,CAAC,KAAK,EAAE,CAAC;UACvB;UAED,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,KAAK;QAC5B;MACF;MAED,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,IAAI,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC;IACnE,CAAC,CAAC;EACJ;EAEU,wBAAwB,CAAC,UAAiB,EAAA;IAClD,MAAM;MAAC,UAAU;MAAE,OAAO;MAAE,UAAU;MAAE,OAAO;MAAE,OAAO;MAAE;IAAY,CAAC,GACnE,IAAI,CAAC,IAAI;IAEb,MAAM,eAAe,GAAG,UAAU,KAAK,eAAe;IAEtD,MAAM,CAAC,GAAG,UAAU,CAAC,eAAe,GAAG,CAAC,GAAG,CAAC,CAAC;IAC7C,MAAM,CAAC,GAAG,UAAU,CAAC,eAAe,GAAG,CAAC,GAAG,CAAC,CAAC;IAE7C,MAAM,IAAI,GAAG,gBAAgB,CACzB,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC;IAC3D,MAAM,IAAI,GAAG,gBAAgB,CACzB,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC;IAE3D,MAAM,QAAQ,GAAU,CACtB,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EACzB,IAAI,eAAe,GAAG,CAAC,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,OAAO,CAAC,CAAC,CACrE;IAED,OAAO,QAAQ;EACjB;;AAlMA;AACgB,SAAA,CAAA,SAAS,GAAG,WAAW;AAuMzC,OAAM,MAAO,cAAe,SAAQ,QAAQ,CAAA;EAW1C,WAAA,CAAY,IAAwB,EAAA;IAClC,MAAM;MACJ,OAAO;MACP,UAAU;MACV,OAAO;MACP,OAAO;MACP,UAAU;MACV;IAAY,CACb,GAAG,IAAI;IAER,KAAK,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAK,IAAI,CAAA,EAAA;MAAE,KAAK,EAAE;IAAO,CAAA,CAAA,CAAE;IAEhC,IAAI,CAAC,OAAO,GAAG,OAAO;IACtB,qBAAqB,CAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC;IAE9C,IAAI,CAAC,UAAU,GAAG,cAAc,CAAC,UAAU,EAAE,CAAC,EAAE,YAAY,CAAC;IAC7D,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,IAAI,qBAAqB,CAAC,IAAI,EAAE,YAAY,CAAC,CAAC;IAE1E,IAAI,CAAC,OAAO,GAAG,cAAc,CAAC,OAAO,IAAI,CAAC,EAAE,CAAC,EAAE,SAAS,CAAC;IACzD,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,IAAI,qBAAqB,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;IAExE,IAAI,CAAC,OAAO,GAAG,OAAO,IAAI,OAAO;IACjC,gBAAgB,CAAC,IAAI,CAAC,OAAO,CAAC;IAE9B,IAAI,CAAC,UAAU,GAAG,UAAU,IAAI,cAAc;IAC9C,eAAe,CAAC,IAAI,CAAC,UAAU,CAAC;IAEhC,IAAI,CAAC,YAAY,GAAG,cAAc,CAAC,YAAY,IAAI,CAAC,EAAE,CAAC,EAAE,cAAc,CAAC;IACxE,IAAI,CAAC,YAAY,CAAC,OAAO,CACrB,IAAI,IAAI,qBAAqB,CAAC,IAAI,EAAE,cAAc,CAAC,CAAC;EAC1D;EAEgB,KAAK,CAAC,UAAyB,EAAA;;IAC7C,UAAU,GAAG,kBAAkB,CAAC,UAAU,CAAC;IAE3C,MAAM,WAAW,GACb,IAAI,CAAC,UAAU,KAAK,eAAe,GAAG,CAAC,GAAG,UAAU,CAAC,MAAM,GAAG,CAAC;IAEnE,IAAI,UAAU,CAAC,WAAW,CAAC,IAAI,IAAI,EAAE;MACnC,MAAM,IAAI,UAAU,CAChB,wDAAwD,GACxD,SAAS,UAAU,CAAC,WAAW,CAAC,EAAE,CAAC;IACxC;IAED,MAAM,QAAQ,GAAG,UAAU,CAAC,WAAW,CAAC;IAExC,MAAM,YAAY,GAAG,CAAC;IAEtB,MAAM,WAAW,GACb,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC,QAAQ,EAAE,IAAI,CAAC,OAAO,GAAG,YAAY,CAAC,CAAC;IAEnE,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,WAAW,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EACnD,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC;IAExD,MAAM,oBAAoB,GACtB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,GAAG,YAAY,CAAC,CAAC;IAEvE,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,oBAAoB,EAAE,IAAI,EAC9C,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC;IAE7B,IAAI,IAAI,CAAC,OAAO,EAAE;MAChB,IAAI,eAA4B;MAEhC,IAAI,IAAI,CAAC,cAAc,EAAE;QACvB,MAAM,IAAI,GAAG,IAAI,CAAC,eAAe;QAEjC,MAAM,OAAO,GAAG,IAAI,CAAC,OAAO;QAE5B,eAAe,GAAG,KAAI,EAAA,GAAC,MAAM,UAAW,SAAQ,WAAW,CAAA;UAIzD,KAAK,CAAC,KAAY,EAAE,KAAgB,EAAA;YAClC,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC;YACnC,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,CAAC;YACjC,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,OAAO,GAAG,CAAC,CAAC,CAAC;YAC3C,OAAO,CAAC,CAAC,WAAW,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;UACjD;SACD,EATC;QACO,EAAA,CAAA,SAAS,GAAG,YAAa,E,EAQhC,GAAE;OACL,MAAM;QACL,eAAe,GAAG,IAAI,CAAC,eAAe;MACvC;MAED,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAAC,OAAO,GAAG,YAAY,CAAC,EAAE,IAAI,EAAE,eAAe,EAC5D,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC;IACrD;IAED,IAAI,CAAC,KAAK,GAAG,IAAI;EACnB;EAES,IAAI,CAAC,MAAoB,EAAE,MAAc,EAAA;IAChD,OAAO,GAAG,CAAC,IAAI,CAAC,MAAK;MACnB,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;QACvB,MAAM,IAAI,UAAU,CAChB,6DAA6D,GAC7D,GAAG,MAAM,CAAC,MAAM,GAAG,CAAC;MACzB;MAED,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK;MAE5C,MAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAS;MAC7B,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE;MAC7B,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE;MAE7B,MAAM,YAAY,GAAG,CAAC;MAItB,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;QACpE,IAAI,CAAC,WAAW,GAAG,mBAAmB,CAAC;UAClB,IAAI,EAAE,MAAM,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC;UAC3B,IAAI,EAAE,IAAI,CAAC,OAAO;UAClB,QAAQ;UACR,KAAK,EAAE,YAAY;UACnB,WAAW,EAAE,IAAI,CAAC;SACnB,CAAiB;MACtC;MAED,MAAM,WAAW,GAAG,IAAI,CAAC,WAA2B;MAEpD,MAAM,YAAY,GACd,CAAC,CAAa,EAAE,IAAkB,EAAE,KAAa,KAAI;QACnD,IAAI,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;UACzB,OAAO,CAAC;QACT;QAED,OAAO,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;MAChC,CAAC;MAEL,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC;MACxC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC;MACxC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC;MACxC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC;MAExC,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC,IACtD,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;QACrC,IAAI,CAAC,oBAAoB,GAAG,mBAAmB,CAAC;UAClB,IAAI,EAAE,MAAM,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC;UAClC,IAAI,EAAE,IAAI,CAAC,gBAAgB;UAC3B,QAAQ;UACR,KAAK,EAAE,YAAY;UACnB,WAAW,EAAE,IAAI,CAAC;SACnB,CAAiB;MAC/C;MAED,MAAM,cAAc,GAAG,IAAI,CAAC,oBAAoC;MAEhE,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC;MAClD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC;MAClD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC;MAClD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC;MAElD,MAAM,iBAAiB,GAAG,CAAC;MAE3B,MAAM,CAAC,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,CAAC,GACtC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,EAAE,YAAY,EAAE,iBAAiB,CAAC;MAElE,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,GAAiB,IAAI,CAAC,OAAO,GAC3D,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,YAAY,CAAC,GACzC,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC;MAE5B,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC;MACrD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC;MACrD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC;MACrD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC;MAErD,MAAM,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,GAClD,GAAG,CAAC,KAAK,CACL,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,EAAE,YAAY,EAAE,iBAAiB,CAAC;MAErE,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC;MACvC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC;MACvC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC;MACvC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC;MAEvC,MAAM,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC;MACzD,MAAM,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC;MACzD,MAAM,CAAC,GAAG,GAAG,CAAC,GAAG,CACb,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,EACpB,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;MACvD,MAAM,CAAC,GAAG,GAAG,CAAC,GAAG,CACb,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAC/C,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;MAE7B,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;IAClB,CAAC,CAAC;EACJ;EAES,SAAS,GAAA;IAChB,MAAM,EAAA,GAA8B,KAAK,CAAC,SAAS,EAAE;MAA/C;QAAC,OAAO,EAAE;MAAC,CAAA,GAAA,EAAoC;MAA/B,UAAU,GAAA,MAAA,CAAA,EAAA,EAA1B,CAAA,OAAA,CAA2B,CAAoB;IAErD,MAAM,MAAM,GAAiC;MAC3C,OAAO,EAAE,IAAI,CAAC,OAAO;MACrB,UAAU,EAAE,IAAI,CAAC,UAAU;MAC3B,OAAO,EAAE,IAAI,CAAC,OAAO;MACrB,UAAU,EAAE,IAAI,CAAC,UAAU;MAC3B,YAAY,EAAE,IAAI,CAAC,YAAY;MAC/B,OAAO,EAAE,IAAI,CAAC;KACf;IAED,OAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAW,UAAU,CAAA,EAAK,MAAM,CAAA;EAClC;EAEA,SAAS,CAAC,CAAS,EAAE,CAAS,EAAE,CAAU,EAAE,OAAqB,EAAA;IAC/D,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAClB,CAAiB,EAAE,CAAiB,EAAE,IAAI,CAAC,OAA2B,EACrE,OAAO,IAAI,OAAO,EACnB,IAAI,CAAC,UAAU,KAAK,eAAe,GAAG,MAAM,GAAG,MAAM,EACrD,IAAI,CAAC,YAAgC,CAAC;IAE1C,IAAI,CAAC,EAAE;MACL,OAAO,CAAC,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC,EAAE,IAAI,CAAC,UAAU,CAAiB;IAC1D;IAED,OAAO,GAAG;EACZ;EAEA,aAAa,CAAC,CAAS,EAAE,CAAS,EAAA;IAChC,MAAM,OAAO,GAAG,CAAC;IAEjB,OAAO,GAAG,CAAC,MAAM,CACb,CAAiB,EAAE,CAAiB,EAAE,OAAO,EAAE,MAAM,EACrD,IAAI,CAAC,UAAU,KAAK,eAAe,GAAG,MAAM,GAAG,MAAM,CAAC;EAC5D;;AA7OA;AACgB,cAAA,CAAA,SAAS,GAAG,gBAAgB;AA+O9C,GAAG,CAAC,aAAa,CAAC,aAAa,CAAC,cAAc,CAAC;AAK/C,OAAM,MAAO,UAAW,SAAQ,SAAS,CAAA;EAIvC,WAAA,CAAY,IAAoB,EAAA;IAC9B,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,IAAI,CAAC;IAErC,KAAK,CAAC,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAI,IAAI,CAAA,EAAA;MAAE;IAAI,CAAA,CAAuB,CAAC;EAC9C;EAEA;EACA,OAAgB,UAAU,CACtB,GAAiD,EACjD,MAAoC,EAAA;IACtC,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC;EACxB;;AAdA;AACgB,UAAA,CAAA,SAAS,GAAG,YAAY;AAgB1C,GAAG,CAAC,aAAa,CAAC,aAAa,CAAC,UAAU,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {Activation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat, checkPaddingMode} from '../common';\nimport {Constraint} from '../constraints';\nimport {InputSpec} from '../engine/topology';\nimport {AttributeError, NotImplementedError, ValueError} from '../errors';\nimport {Initializer} from '../initializers';\nimport {DataFormat, DataType, PaddingMode, Shape} from '../keras_format/common';\nimport {Regularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convOutputLength, normalizeArray} from '../utils/conv_utils';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport {getExactlyOneShape} from '../utils/types_utils';\n\nimport {BaseRNNLayerArgs, generateDropoutMask, LSTMCell, LSTMCellLayerArgs, LSTMLayerArgs, RNN, RNNCell, RNNLayerArgs, SimpleRNNCellLayerArgs} from './recurrent';\n\ndeclare interface ConvRNN2DCellArgs extends\n    Omit<SimpleRNNCellLayerArgs, 'units'> {\n  /**\n   * The dimensionality of the output space (i.e. the number of filters in the\n   * convolution).\n   */\n  filters: number;\n\n  /**\n   * The dimensions of the convolution window. If kernelSize is a number, the\n   * convolutional window will be square.\n   */\n  kernelSize: number|number[];\n\n  /**\n   * The strides of the convolution in each dimension. If strides is a number,\n   * strides in both dimensions are equal.\n   *\n   * Specifying any stride value != 1 is incompatible with specifying any\n   * `dilationRate` value != 1.\n   */\n  strides?: number|number[];\n\n  /**\n   * Padding mode.\n   */\n  padding?: PaddingMode;\n\n  /**\n   * Format of the data, which determines the ordering of the dimensions in\n   * the inputs.\n   *\n   * `channels_last` corresponds to inputs with shape\n   *   `(batch, ..., channels)`\n   *\n   *  `channels_first` corresponds to inputs with shape `(batch, channels,\n   * ...)`.\n   *\n   * Defaults to `channels_last`.\n   */\n  dataFormat?: DataFormat;\n\n  /**\n   * The dilation rate to use for the dilated convolution in each dimension.\n   * Should be an integer or array of two or three integers.\n   *\n   * Currently, specifying any `dilationRate` value != 1 is incompatible with\n   * specifying any `strides` value != 1.\n   */\n  dilationRate?: number|[number]|[number, number];\n}\n\nabstract class ConvRNN2DCell extends RNNCell {\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  readonly activation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n}\n\ndeclare interface ConvRNN2DLayerArgs extends BaseRNNLayerArgs,\n                                             ConvRNN2DCellArgs {}\n\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n  /** @nocollapse */\n  static override className = 'ConvRNN2D';\n\n  declare readonly cell: ConvRNN2DCell;\n\n  constructor(args: ConvRNN2DLayerArgs) {\n    if (args.unroll) {\n      throw new NotImplementedError(\n          'Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError(\n          'It is not possible at the moment to stack convolutional cells.');\n    }\n\n    super(args as RNNLayerArgs);\n\n    this.inputSpec = [new InputSpec({ndim: 5})];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n\n        this.cell.dropoutMask = null;\n      }\n\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n\n        this.cell.recurrentDropoutMask = null;\n      }\n\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n\n      const mask = kwargs == null ? null : kwargs['mask'];\n\n      const training = kwargs == null ? null : kwargs['training'];\n\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape|Shape[] {\n    let outShape: Shape = this.computeSingleOutputShape(inputShape);\n\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n\n    if (this.returnState) {\n      outShape =\n          [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n\n    return outShape;\n  }\n\n  override getInitialState(inputs: tfc.Tensor): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      const {stateSize} = this.cell;\n\n      const inputShape = inputs.shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const initialState = tfc.zeros(stateShape);\n\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n\n      return [initialState];\n    });\n  }\n\n  override resetStates(states?: Tensor|Tensor[], training = false): void {\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError(\n            'Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n\n      const inputShape = this.inputSpec[0].shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const batchSize = inputShape[0];\n\n      if (batchSize == null) {\n        throw new ValueError(\n            'If an RNN is stateful, it needs to know its batch size. Specify ' +\n            'the batch size of your input tensors: \\n' +\n            '- If using a Sequential model, specify the batch size by ' +\n            'passing a `batchInputShape` option to your first layer.\\n' +\n            '- If using the functional API, specify the batch size by ' +\n            'passing a `batchShape` option to your Input layer.');\n      }\n\n      // Initialize state if null.\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n\n        if (states.length !== this.states_.length) {\n          throw new ValueError(\n              `Layer ${this.name} expects ${this.states_.length} state(s), ` +\n              `but it received ${states.length} state value(s). Input ` +\n              `received: ${states}`);\n        }\n\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n\n          const expectedShape = stateShape;\n\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(\n                `State ${index} is incompatible with layer ${this.name}: ` +\n                `expected shape=${expectedShape}, received shape=${\n                    value.shape}`);\n          }\n\n          this.states_[index] = value;\n        }\n      }\n\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  protected computeSingleOutputShape(inputShape: Shape): Shape {\n    const {dataFormat, filters, kernelSize, padding, strides, dilationRate} =\n        this.cell;\n\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n\n    const hOut = convOutputLength(\n        h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(\n        w, kernelSize[1], padding, strides[1], dilationRate[1]);\n\n    const outShape: Shape = [\n      ...inputShape.slice(0, 2),\n      ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n    ];\n\n    return outShape;\n  }\n}\n\nexport declare interface ConvLSTM2DCellArgs extends\n    Omit<LSTMCellLayerArgs, 'units'>, ConvRNN2DCellArgs {}\n\nexport class ConvLSTM2DCell extends LSTMCell implements ConvRNN2DCell {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2DCell';\n\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  constructor(args: ConvLSTM2DCellArgs) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate,\n    } = args;\n\n    super({...args, units: filters});\n\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(\n        rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n\n    const channelAxis =\n        this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(\n          `The channel dimension of the input should be defined. ` +\n          `Found ${inputShape[channelAxis]}`);\n    }\n\n    const inputDim = inputShape[channelAxis];\n\n    const numOfKernels = 4;\n\n    const kernelShape =\n        this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n\n    this.kernel = this.addWeight(\n        'kernel', kernelShape, null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n\n    const recurrentKernelShape =\n        this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', recurrentKernelShape, null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n\n    if (this.useBias) {\n      let biasInitializer: Initializer;\n\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n\n        const filters = this.filters;\n\n        biasInitializer = new (class CustomInit extends Initializer {\n          /** @nocollapse */\n          static className = 'CustomInit';\n\n          apply(shape: Shape, dtype?: DataType): tfc.Tensor {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n        })();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n\n      this.bias = this.addWeight(\n          'bias', [this.filters * numOfKernels], null, biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.built = true;\n  }\n\n  override call(inputs: tfc.Tensor[], kwargs: Kwargs): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(\n            `ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] || false;\n\n      const x = inputs[0];         // Current input\n      const hTMinus1 = inputs[1];  // Previous memory state.\n      const cTMinus1 = inputs[2];  // Previous carry state.\n\n      const numOfKernels = 4;\n\n      type DropoutMasks = [tfc.Tensor, tfc.Tensor, tfc.Tensor, tfc.Tensor];\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(x),\n                             rate: this.dropout,\n                             training,\n                             count: numOfKernels,\n                             dropoutFunc: this.dropoutFunc\n                           }) as tfc.Tensor[];\n      }\n\n      const dropoutMask = this.dropoutMask as DropoutMasks;\n\n      const applyDropout =\n          (x: tfc.Tensor, mask: tfc.Tensor[], index: number) => {\n            if (!mask || !mask[index]) {\n              return x;\n            }\n\n            return tfc.mul(mask[index], x);\n          };\n\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: numOfKernels,\n                                      dropoutFunc: this.dropoutFunc\n                                    }) as tfc.Tensor[];\n      }\n\n      const recDropoutMask = this.recurrentDropoutMask as DropoutMasks;\n\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n\n      const kernelChannelAxis = 3;\n\n      const [kernelI, kernelF, kernelC, kernelO]: tfc.Tensor[] =\n          tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n\n      const [biasI, biasF, biasC, biasO]: tfc.Tensor[] = this.useBias ?\n          tfc.split(this.bias.read(), numOfKernels) :\n          [null, null, null, null];\n\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n\n      const [recKernelI, recKernelF, recKernelC, recKernelO]: tfc.Tensor[] =\n          tfc.split(\n              this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(\n          tfc.mul(f, cTMinus1),\n          tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(\n          this.recurrentActivation.apply(tfc.add(xO, hO)),\n          this.activation.apply(c));\n\n      return [h, h, c];\n    });\n  }\n\n  override getConfig(): tfc.serialization.ConfigDict {\n    const {'units': _, ...baseConfig} = super.getConfig();\n\n    const config: tfc.serialization.ConfigDict = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides,\n    };\n\n    return {...baseConfig, ...config};\n  }\n\n  inputConv(x: Tensor, w: Tensor, b?: Tensor, padding?: PaddingMode) {\n    const out = tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, this.strides as [number, number],\n        (padding || 'valid') as 'same' | 'valid',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC',\n        this.dilationRate as [number, number]);\n\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat) as tfc.Tensor3D;\n    }\n\n    return out;\n  }\n\n  recurrentConv(x: Tensor, w: Tensor) {\n    const strides = 1;\n\n    return tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, strides, 'same',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2DCell);\n\nexport declare interface ConvLSTM2DArgs extends\n    Omit<LSTMLayerArgs, 'units'|'cell'>, ConvRNN2DLayerArgs {}\n\nexport class ConvLSTM2D extends ConvRNN2D {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2D';\n\n  constructor(args: ConvLSTM2DArgs) {\n    const cell = new ConvLSTM2DCell(args);\n\n    super({...args, cell} as ConvRNN2DLayerArgs);\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends tfc.serialization.Serializable>(\n      cls: tfc.serialization.SerializableConstructor<T>,\n      config: tfc.serialization.ConfigDict): T {\n    return new cls(config);\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2D);\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}