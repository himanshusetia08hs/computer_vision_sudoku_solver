{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport { notEqual, reshape, serialization, tidy, zerosLike } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Embedding extends Layer {\n  constructor(args) {\n    super(args);\n    this.embeddings = null;\n    this.DEFAULT_EMBEDDINGS_INITIALIZER = 'randomUniform';\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape = [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n  build(inputShape) {\n    this.embeddings = this.addWeight('embeddings', [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);\n    this.built = true;\n  }\n  // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n  warnOnIncompatibleInputShape(inputShape) {}\n  computeMask(inputs, mask) {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    }\n    // inputLength can be an array if input is 3D or higher.\n    const inLens = generic_utils.toList(this.inputLength);\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` + `input shape has shape ${inputShape}`);\n    } else {\n      let i = 0;\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n        if (s1 != null && s2 != null && s1 !== s2) {\n          throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` + `input shape has shape ${inputShape}`);\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n        i++;\n      }\n    }\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Embedding layer accepts only a single input.\n      let input = getExactlyOneTensor(inputs);\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n      const output = K.gather(this.embeddings.read(), reshape(input, [input.size]));\n      return reshape(output, getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n  getConfig() {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\n/** @nocollapse */\nEmbedding.className = 'Embedding';\nserialization.registerClass(Embedding);","map":{"version":3,"sources":["../../../../../../tfjs-layers/src/layers/embeddings.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;AAEH;;;;AAIG;AACH,SAAQ,QAAQ,EAAE,OAAO,EAAE,aAAa,EAAU,IAAI,EAAE,SAAS,QAAO,uBAAuB;AAE/F,OAAO,KAAK,CAAC,MAAM,yBAAyB;AAC5C,SAA0C,aAAa,EAAE,mBAAmB,QAAO,gBAAgB;AACnG,SAAQ,KAAK,QAAkB,oBAAoB;AACnD,SAAQ,UAAU,QAAO,WAAW;AACpC,SAAQ,cAAc,EAAsC,oBAAoB,QAAO,iBAAiB;AAExG,SAAQ,cAAc,EAAsC,oBAAoB,QAAO,iBAAiB;AAExG,OAAO,KAAK,aAAa,MAAM,wBAAwB;AACvD,SAAQ,kBAAkB,EAAE,mBAAmB,QAAO,sBAAsB;AAiD5E,OAAM,MAAO,SAAU,SAAQ,KAAK,CAAA;EAgBlC,WAAA,CAAY,IAAwB,EAAA;IAClC,KAAK,CAAC,IAAI,CAAC;IARL,IAAA,CAAA,UAAU,GAAkB,IAAI;IAE/B,IAAA,CAAA,8BAA8B,GACnC,eAAe;IAMjB,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;MAC3D;MACA;MACA;MACA;MACA,IAAI,SAAS,GAAW,IAAI;MAC5B,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;QAC1B,SAAS,GAAG,IAAI,CAAC,SAAS;MAC3B;MACD,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;QAC5B;QACA;QACA,IAAI,CAAC,eAAe,GAAG,CAAC,SAAS,EAAE,IAAI,CAAC;OACzC,MAAM;QACL;QACA;QACA,IAAI,CAAC,eAAe,GAChB,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;MAC/D;IACF;IACD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ;IAC7B,aAAa,CAAC,qBAAqB,CAAC,IAAI,CAAC,QAAQ,EAAE,UAAU,CAAC;IAC9D,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS;IAC/B,aAAa,CAAC,qBAAqB,CAAC,IAAI,CAAC,SAAS,EAAE,WAAW,CAAC;IAChE,IAAI,CAAC,qBAAqB,GAAG,cAAc,CACvC,IAAI,CAAC,qBAAqB,IAAI,IAAI,CAAC,8BAA8B,CAAC;IACtE,IAAI,CAAC,qBAAqB,GAAG,cAAc,CAAC,IAAI,CAAC,qBAAqB,CAAC;IACvE,IAAI,CAAC,mBAAmB,GAAG,cAAc,CAAC,IAAI,CAAC,mBAAmB,CAAC;IACnE,IAAI,CAAC,oBAAoB,GAAG,aAAa,CAAC,IAAI,CAAC,oBAAoB,CAAC;IACpE,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ;IAC7B,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,QAAQ;IACpC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW;EACrC;EAEgB,KAAK,CAAC,UAAyB,EAAA;IAC7C,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,SAAS,CAC5B,YAAY,EAAE,CAAC,IAAI,CAAC,QAAQ,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,CAAC,KAAK,EACzD,IAAI,CAAC,qBAAqB,EAAE,IAAI,CAAC,qBAAqB,EAAE,IAAI,EAC5D,IAAI,CAAC,oBAAoB,CAAC;IAC9B,IAAI,CAAC,KAAK,GAAG,IAAI;EACnB;EAEA;EACA;EACmB,4BAA4B,CAAC,UAAiB,EAAA,CAAG;EAE3D,WAAW,CAAC,MAAuB,EAAE,IAAsB,EAAA;IAElE,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;QAClB,OAAO,IAAI;OACZ,MAAM;QACL,MAAM,GAAG,mBAAmB,CAAC,MAAM,CAAC;QACpC,OAAO,QAAQ,CAAC,MAAM,EAAE,SAAS,CAAC,MAAM,CAAC,CAAC;MAC3C;IACH,CAAC,CAAC;EACJ;EAES,kBAAkB,CAAC,UAAyB,EAAA;IACnD,UAAU,GAAG,kBAAkB,CAAC,UAAU,CAAC;IAC3C,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;MAC5B,OAAO,CAAC,GAAG,UAAU,EAAE,IAAI,CAAC,SAAS,CAAC;IACvC;IACD;IACA,MAAM,MAAM,GAAa,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC;IAC/D,IAAI,MAAM,CAAC,MAAM,KAAK,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;MAC3C,MAAM,IAAI,UAAU,CAChB,oBAAoB,IAAI,CAAC,WAAW,iBAAiB,GACrD,yBAAyB,UAAU,EAAE,CAAC;KAC3C,MAAM;MACL,IAAI,CAAC,GAAG,CAAC;MACT,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;QACtC,MAAM,EAAE,GAAG,MAAM,CAAC,CAAC,CAAC;QACpB,MAAM,EAAE,GAAG,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC;QAC5B,IAAK,EAAE,IAAI,IAAI,IAAM,EAAE,IAAI,IAAK,IAAK,EAAE,KAAK,EAAG,EAAE;UAC/C,MAAM,IAAI,UAAU,CAChB,oBAAoB,IAAI,CAAC,WAAW,iBAAiB,GACrD,yBAAyB,UAAU,EAAE,CAAC;SAC3C,MAAM,IAAI,EAAE,IAAI,IAAI,EAAE;UACrB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE;QACf;QACD,CAAC,EAAE;MACJ;IACF;IACD,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,GAAG,MAAM,EAAE,IAAI,CAAC,SAAS,CAAC;EACnD;EAES,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;IACnD,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC;MACnC;MACA,IAAI,KAAK,GAAG,mBAAmB,CAAC,MAAM,CAAC;MACvC,IAAI,KAAK,CAAC,KAAK,KAAK,OAAO,EAAE;QAC3B,KAAK,GAAG,CAAC,CAAC,IAAI,CAAC,KAAK,EAAE,OAAO,CAAC;MAC/B;MACD,MAAM,MAAM,GACR,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,EAAE,OAAO,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;MAClE,OAAO,OAAO,CACV,MAAM,EAAE,kBAAkB,CAAC,IAAI,CAAC,kBAAkB,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;IACvE,CAAC,CAAC;EACJ;EAES,SAAS,GAAA;IAChB,MAAM,MAAM,GAAG;MACb,QAAQ,EAAE,IAAI,CAAC,QAAQ;MACvB,SAAS,EAAE,IAAI,CAAC,SAAS;MACzB,qBAAqB,EAAE,oBAAoB,CAAC,IAAI,CAAC,qBAAqB,CAAC;MACvE,qBAAqB,EAAE,oBAAoB,CAAC,IAAI,CAAC,qBAAqB,CAAC;MACvE,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC,mBAAmB,CAAC;MACnE,oBAAoB,EAAE,mBAAmB,CAAC,IAAI,CAAC,oBAAoB,CAAC;MACpE,QAAQ,EAAE,IAAI,CAAC,QAAQ;MACvB,WAAW,EAAE,IAAI,CAAC;KACnB;IACD,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE;IACpC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC;IACjC,OAAO,MAAM;EACf;;AArIA;AACO,SAAA,CAAA,SAAS,GAAG,WAAW;AAsIhC,aAAa,CAAC,aAAa,CAAC,SAAS,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport {notEqual, reshape, serialization, Tensor, tidy, zerosLike} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface EmbeddingLayerArgs extends LayerArgs {\n  /**\n   * Integer > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n   */\n  inputDim: number;\n  /**\n   * Integer >= 0. Dimension of the dense embedding.\n   */\n  outputDim: number;\n  /**\n   * Initializer for the `embeddings` matrix.\n   */\n  embeddingsInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Regularizer function applied to the `embeddings` matrix.\n   */\n  embeddingsRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Constraint function applied to the `embeddings` matrix.\n   */\n  embeddingsConstraint?: ConstraintIdentifier|Constraint;\n  /**\n   * Whether the input value 0 is a special \"padding\" value that should be\n   * masked out. This is useful when using recurrent layers which may take\n   * variable length input.\n   *\n   * If this is `True` then all subsequent layers in the model need to support\n   * masking or an exception will be raised. If maskZero is set to `True`, as a\n   * consequence, index 0 cannot be used in the vocabulary (inputDim should\n   * equal size of vocabulary + 1).\n   */\n  maskZero?: boolean;\n  /**\n   * Length of input sequences, when it is constant.\n   *\n   * This argument is required if you are going to connect `flatten` then\n   * `dense` layers upstream (without it, the shape of the dense outputs cannot\n   * be computed).\n   */\n  inputLength?: number|number[];\n}\n\nexport class Embedding extends Layer {\n  /** @nocollapse */\n  static className = 'Embedding';\n  private inputDim: number;\n  private outputDim: number;\n  private embeddingsInitializer: Initializer;\n  private maskZero: boolean;\n  private inputLength: number|number[];\n\n  private embeddings: LayerVariable = null;\n\n  readonly DEFAULT_EMBEDDINGS_INITIALIZER: InitializerIdentifier =\n      'randomUniform';\n  private readonly embeddingsRegularizer?: Regularizer;\n  private readonly embeddingsConstraint?: Constraint;\n\n  constructor(args: EmbeddingLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape =\n            [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(\n        args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    this.embeddings = this.addWeight(\n        'embeddings', [this.inputDim, this.outputDim], this.dtype,\n        this.embeddingsInitializer, this.embeddingsRegularizer, true,\n        this.embeddingsConstraint);\n    this.built = true;\n  }\n\n  // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n  protected override warnOnIncompatibleInputShape(inputShape: Shape) {}\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]):\n      Tensor {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    }\n    // inputLength can be an array if input is 3D or higher.\n    const inLens: number[] = generic_utils.toList(this.inputLength);\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(\n          `\"inputLength\" is ${this.inputLength}, but received ` +\n          `input shape has shape ${inputShape}`);\n    } else {\n      let i = 0;\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n        if ((s1 != null) && (s2 != null) && (s1 !== s2)) {\n          throw new ValueError(\n              `\"inputLength\" is ${this.inputLength}, but received ` +\n              `input shape has shape ${inputShape}`);\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n        i++;\n      }\n    }\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Embedding layer accepts only a single input.\n      let input = getExactlyOneTensor(inputs);\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n      const output =\n          K.gather(this.embeddings.read(), reshape(input, [input.size]));\n      return reshape(\n          output, getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Embedding);\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}