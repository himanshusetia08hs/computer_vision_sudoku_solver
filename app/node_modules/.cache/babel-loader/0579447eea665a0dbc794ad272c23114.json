{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n  if (batchSize == null) {\n    batchSize = 32;\n  }\n  if (epochs == null) {\n    epochs = 1;\n  }\n  if (shuffle == null) {\n    shuffle = true;\n  }\n  if (initialEpoch == null) {\n    initialEpoch = 0;\n  }\n  // TODO(cais): Change const to let below when implementing validation.\n  let doValidation = false;\n  if (valF != null && valIns != null) {\n    doValidation = true;\n    // TODO(cais): verbose message.\n  }\n\n  if (validationSteps != null) {\n    doValidation = true;\n    if (stepsPerEpoch == null) {\n      throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n    }\n  }\n  const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n  let indexArray;\n  if (numTrainSamples != null) {\n    indexArray = range(0, numTrainSamples);\n  }\n  if (verbose == null) {\n    verbose = 1;\n  }\n  const {\n    callbackList,\n    history\n  } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n  callbackList.setModel(model);\n  model.history = history;\n  await callbackList.onTrainBegin();\n  model.stopTraining_ = false;\n  // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n  // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n    await callbackList.onEpochBegin(epoch);\n    const epochLogs = {};\n    if (stepsPerEpoch != null) {\n      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n    } else {\n      if (shuffle === 'batch') {\n        throw new NotImplementedError('batch shuffling is not implemneted yet');\n      } else if (shuffle) {\n        util.shuffle(indexArray);\n      }\n      // Convert the potentially shuffled indices to Tensor1D, to avoid the\n      // cost of repeated creation of Array1Ds later on.\n      const epochIndexArray1D = tensor1d(indexArray);\n      const batches = makeBatches(numTrainSamples, batchSize);\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchLogs = {};\n        await callbackList.onBatchBegin(batchIndex, batchLogs);\n        tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = batchEnd - batchStart;\n          // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const outs = f(insBatch);\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out);\n            // TODO(cais): Use scope() to avoid ownership.\n          }\n\n          if (batchIndex === batches.length - 1) {\n            // Last batch.\n            if (doValidation) {\n              const valOuts = model.testLoop(valF, valIns, batchSize);\n              // Porting Notes: In tfjs-layers, valOuts is always an Array.\n              for (let i = 0; i < outLabels.length; ++i) {\n                const label = outLabels[i];\n                const out = valOuts[i];\n                tfc.keep(out);\n                // TODO(cais): Use scope() to avoid ownership.\n                epochLogs['val_' + label] = out;\n              }\n            }\n          }\n        });\n        await callbackList.onBatchEnd(batchIndex, batchLogs);\n        disposeTensorsInLogs(batchLogs);\n        if (model.stopTraining_) {\n          break;\n        }\n        // TODO(cais): return outs as list of Tensor.\n      }\n\n      epochIndexArray1D.dispose();\n    }\n    // TODO(cais): Run validation at the end of the epoch.\n    await callbackList.onEpochEnd(epoch, epochLogs);\n    if (model.stopTraining_) {\n      break;\n    }\n  }\n  await callbackList.onTrainEnd();\n  await model.history.syncData();\n  return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y) {\n  let args = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  if (model.isTraining) {\n    throw new Error('Cannot start training because another fit() call is ongoing.');\n  }\n  model.isTraining = true;\n  let inputs;\n  let targets;\n  let inputValX;\n  let inputValY;\n  let valX;\n  let valY;\n  let sampleWeights;\n  try {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize);\n    // Validate user data.\n    // TODO(cais): Support sampleWeight.\n    const checkBatchAxis = false;\n    const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n    inputs = standardizedOuts[0];\n    targets = standardizedOuts[1];\n    sampleWeights = standardizedOuts[2];\n    // Prepare validation data.\n    let doValidation = false;\n    let valIns;\n    if (args.validationData != null && args.validationData.length > 0) {\n      doValidation = true;\n      if (args.validationData.length === 2) {\n        // config.validationData consists of valX and valY.\n        inputValX = args.validationData[0];\n        inputValY = args.validationData[1];\n      } else if (args.validationData.length === 3) {\n        throw new NotImplementedError('validationData including sample weights is not supported yet.');\n      } else {\n        throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` + `or 3 (valX, valY, valSampleWeight) items; ` + `${args.validationData} is invalid.`);\n      }\n      const checkBatchAxis = true;\n      const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */null, /** Unused class weights. */checkBatchAxis, batchSize);\n      valX = valStandardized[0];\n      valY = valStandardized[1];\n      valIns = valX.concat(valY);\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n      doValidation = true;\n      // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n      const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n      const originalBatchSize = inputs[0].shape[0];\n      valX = sliceArrays(inputs, splitAt, originalBatchSize);\n      inputs = sliceArrays(inputs, 0, splitAt);\n      valY = sliceArrays(targets, splitAt, originalBatchSize);\n      targets = sliceArrays(targets, 0, splitAt);\n      // TODO(cais): Once sampleWeights becomes available, slice it to get\n      //   valSampleWeights.\n      valIns = valX.concat(valY);\n      // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSteps != null) {\n      doValidation = true;\n      // TODO(cais): Add useLearningPhase.\n    }\n\n    const ins = inputs.concat(targets).concat(sampleWeights);\n    model.checkTrainableWeightsConsistency();\n    // TODO(cais): Handle use_learning_phase and learning_phase?\n    // Porting Note: Here we see a key deviation of tfjs-layers from\n    // Keras.\n    //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n    //  we do not construct symbolic computation graphs to embody the\n    //  training process. Instead, we define a function that performs the\n    //  training action. In PyKeras, the data (inputs and targets) are fed\n    //  through graph placeholders. In tfjs-layers, the data are fed as\n    //  function arguments. Since the function are defined below in the\n    //  scope, we don't have equivalents of PyKeras's\n    //  `_make_train_funciton`.\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames();\n    let valFunction;\n    let callbackMetrics;\n    if (doValidation) {\n      model.makeTestFunction();\n      valFunction = model.testFunction;\n      callbackMetrics = outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      valFunction = null;\n      valIns = [];\n      callbackMetrics = outLabels.slice();\n    }\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n    return out;\n  } finally {\n    model.isTraining = false;\n    // Memory clean up.\n    disposeNewTensors(inputs, x);\n    disposeNewTensors(targets, y);\n    disposeNewTensors(valX, inputValX);\n    disposeNewTensors(valY, inputValY);\n    if (sampleWeights != null) {\n      tfc.dispose(sampleWeights);\n    }\n  }\n  // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n  // Make Tensors at least 2D.\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n  const oldTensorIds = [];\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n  const tensorsToDispose = [];\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"sources":["../../src/engine/training_tensors.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;AAEH;;AAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB;AAC5C,SAAgB,MAAM,EAAY,QAAQ,EAAE,IAAI,QAAO,uBAAuB;AAE9E,SAAQ,UAAU,EAAE,MAAM,EAAE,mBAAmB,QAAO,yBAAyB;AAC/E,SAAsB,kBAAkB,EAAsD,oBAAoB,QAA0B,mBAAmB;AAC/J,SAAQ,mBAAmB,EAAE,UAAU,QAAO,WAAW;AACzD,SAAQ,oBAAoB,QAAuB,SAAS;AAC5D,SAAQ,KAAK,QAAO,qBAAqB;AA4IzC,OAAM,SAAU,cAAc,CAAC,SAAiB,EAAA;EAC9C,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,SAAS,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,SAAS,CAAC,EAC5C,MAAM,2DACF,SAAS,EAAE,CAAC;AACtB;AAEA;;;;;;;;;;;;AAYG;AACH,OAAM,SAAU,WAAW,CACvB,MAAuB,EAAE,KAAa,EAAE,IAAY,EAAA;EACtD,IAAI,MAAM,IAAI,IAAI,EAAE;IAClB,OAAO,CAAC,IAAI,CAAC;GACd,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;IAChC,OAAO,MAAM,CAAC,GAAG,CAAC,KAAK,IAAI,mBAAmB,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,GAAG,KAAK,CAAC,CAAC;GAC5E,MAAM;IAAG;IACR,OAAO,mBAAmB,CAAC,MAAM,EAAE,KAAK,EAAE,IAAI,GAAG,KAAK,CAAC;EACxD;AACH;AAEA;;;;;;;;;;;;AAYG;AACH,OAAM,SAAU,oBAAoB,CAChC,MAAuB,EAAE,OAAiB,EAAA;EAC5C,OAAO,GAAG,CAAC,IAAI,CAAC,MAAK;IACnB,IAAI,MAAM,IAAI,IAAI,EAAE;MAClB,OAAO,IAAI;KACZ,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;MAChC,OAAO,MAAM,CAAC,GAAG,CACb,KAAK,IAAK,oBAAoB,CAAC,KAAK,EAAE,OAAO,CAAY,CAAC;KAC/D,MAAM;MACL;MACA;MACA,OAAO,MAAM,CACT,MAAM,EAAE,OAAO,CAAC,KAAK,KAAK,OAAO,GAAG,OAAO,GAAG,OAAO,CAAC,KAAK,EAAE,CAAC;IACnE;EACH,CAAC,CAAC;AACJ;AAEA;;;;;;;AAOG;AACH,OAAM,SAAU,WAAW,CACvB,IAAY,EAAE,SAAiB,EAAA;EACjC,MAAM,MAAM,GAA4B,EAAE;EAC1C,IAAI,UAAU,GAAG,CAAC;EAClB,IAAI,QAAQ,GAAW,IAAI;EAC3B,OAAO,UAAU,GAAG,IAAI,EAAE;IACxB,QAAQ,GAAG,UAAU,GAAG,SAAS;IACjC,IAAI,QAAQ,IAAI,IAAI,EAAE;MACpB,QAAQ,GAAG,IAAI;IAChB;IACD,MAAM,CAAC,IAAI,CAAC,CAAC,UAAU,EAAE,QAAQ,CAAC,CAAC;IACnC,UAAU,GAAG,QAAQ;EACtB;EACD,OAAO,MAAM;AACf;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BG;AACH,eAAe,OAAO;AAClB;AACA;AACA,KAAU,EAAE,CAA+B,EAAE,GAAa,EAC1D,SAAoB,EAAE,SAAkB,EAAE,MAAe,EAAE,OAAgB,EAC3E,SAA0B,EAAE,IAAmC,EAC/D,MAAiB,EAAE,OAAwB,EAAE,eAA0B,EACvE,YAAqB,EAAE,aAAsB,EAC7C,eAAwB,EAAA;EAC1B,IAAI,SAAS,IAAI,IAAI,EAAE;IACrB,SAAS,GAAG,EAAE;EACf;EACD,IAAI,MAAM,IAAI,IAAI,EAAE;IAClB,MAAM,GAAG,CAAC;EACX;EACD,IAAI,OAAO,IAAI,IAAI,EAAE;IACnB,OAAO,GAAG,IAAI;EACf;EACD,IAAI,YAAY,IAAI,IAAI,EAAE;IACxB,YAAY,GAAG,CAAC;EACjB;EAED;EACA,IAAI,YAAY,GAAG,KAAK;EACxB,IAAI,IAAI,IAAI,IAAI,IAAI,MAAM,IAAI,IAAI,EAAE;IAClC,YAAY,GAAG,IAAI;IACnB;EACD;;EACD,IAAI,eAAe,IAAI,IAAI,EAAE;IAC3B,YAAY,GAAG,IAAI;IACnB,IAAI,aAAa,IAAI,IAAI,EAAE;MACzB,MAAM,IAAI,UAAU,CAChB,gEAAgE,GAChE,oCAAoC,CAAC;IAC1C;EACF;EAED,MAAM,eAAe,GACjB,KAAK,CAAC,eAAe,CAAC,GAAG,EAAE,SAAS,EAAE,aAAa,EAAE,iBAAiB,CAAC;EAC3E,IAAI,UAAoB;EACxB,IAAI,eAAe,IAAI,IAAI,EAAE;IAC3B,UAAU,GAAG,KAAK,CAAC,CAAC,EAAE,eAAe,CAAC;EACvC;EAED,IAAI,OAAO,IAAI,IAAI,EAAE;IACnB,OAAO,GAAG,CAAC;EACZ;EAED,MAAM;IAAC,YAAY;IAAE;EAAO,CAAC,GAAG,kBAAkB,CAC9C,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,YAAY,EAAE,eAAe,EAAE,aAAa,EACxE,SAAS,EAAE,YAAY,EAAE,eAAe,CAAC;EAC7C,YAAY,CAAC,QAAQ,CAAC,KAAK,CAAC;EAC5B,KAAK,CAAC,OAAO,GAAG,OAAO;EACvB,MAAM,YAAY,CAAC,YAAY,EAAE;EACjC,KAAK,CAAC,aAAa,GAAG,KAAK;EAC3B;EACA;EAEA,KAAK,IAAI,KAAK,GAAG,YAAY,EAAE,KAAK,GAAG,MAAM,EAAE,EAAE,KAAK,EAAE;IACtD,MAAM,YAAY,CAAC,YAAY,CAAC,KAAK,CAAC;IACtC,MAAM,SAAS,GAAmB,CAAA,CAAE;IACpC,IAAI,aAAa,IAAI,IAAI,EAAE;MACzB,MAAM,IAAI,mBAAmB,CACzB,4CAA4C,CAAC;KAClD,MAAM;MACL,IAAI,OAAO,KAAK,OAAO,EAAE;QACvB,MAAM,IAAI,mBAAmB,CAAC,wCAAwC,CAAC;OACxE,MAAM,IAAI,OAAO,EAAE;QAClB,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC;MACzB;MACD;MACA;MACA,MAAM,iBAAiB,GAAG,QAAQ,CAAC,UAAU,CAAC;MAE9C,MAAM,OAAO,GAAG,WAAW,CAAC,eAAe,EAAE,SAAS,CAAC;MACvD,KAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,UAAU,EAAE;QAClE,MAAM,SAAS,GAAmB,CAAA,CAAE;QACpC,MAAM,YAAY,CAAC,YAAY,CAAC,UAAU,EAAE,SAAS,CAAC;QAEtD,GAAG,CAAC,IAAI,CAAC,MAAK;UACZ,MAAM,UAAU,GAAG,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;UACzC,MAAM,QAAQ,GAAG,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;UACvC,MAAM,QAAQ,GAAG,mBAAmB,CACf,iBAAiB,EAAE,UAAU,EAC7B,QAAQ,GAAG,UAAU,CAAa;UACvD,SAAS,CAAC,OAAO,CAAC,GAAG,UAAU;UAC/B,SAAS,CAAC,MAAM,CAAC,GAAG,QAAQ,GAAG,UAAU;UAEzC;UACA;UACA,MAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAG,EAAE,QAAQ,CAAa;UAChE,MAAM,IAAI,GAAG,CAAC,CAAC,QAAQ,CAAC;UACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;YACzC,MAAM,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC;YAC1B,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC;YACnB,SAAS,CAAC,KAAK,CAAC,GAAG,GAAG;YACtB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC;YACb;UACD;;UAED,IAAI,UAAU,KAAK,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;YAAG;YACxC,IAAI,YAAY,EAAE;cAChB,MAAM,OAAO,GAAG,KAAK,CAAC,QAAQ,CAAC,IAAI,EAAE,MAAM,EAAE,SAAS,CAAC;cACvD;cACA,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBACzC,MAAM,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC;gBAC1B,MAAM,GAAG,GAAG,OAAO,CAAC,CAAC,CAAC;gBACtB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC;gBACb;gBACA,SAAS,CAAC,MAAM,GAAG,KAAK,CAAC,GAAG,GAAG;cAChC;YACF;UACF;QACH,CAAC,CAAC;QAEF,MAAM,YAAY,CAAC,UAAU,CAAC,UAAU,EAAE,SAAS,CAAC;QACpD,oBAAoB,CAAC,SAAS,CAAC;QAE/B,IAAI,KAAK,CAAC,aAAa,EAAE;UACvB;QACD;QACD;MACD;;MAED,iBAAiB,CAAC,OAAO,EAAE;IAC5B;IACD;IACA,MAAM,YAAY,CAAC,UAAU,CAAC,KAAK,EAAE,SAAS,CAAC;IAC/C,IAAI,KAAK,CAAC,aAAa,EAAE;MACvB;IACD;EACF;EACD,MAAM,YAAY,CAAC,UAAU,EAAE;EAE/B,MAAM,KAAK,CAAC,OAAO,CAAC,QAAQ,EAAE;EAC9B,OAAO,KAAK,CAAC,OAAO;AACtB;AAEA,OAAO,eAAe,UAAU;AAC5B;AACA;AACA,KAAU,EAAE,CAAgD,EAC5D,CAAgD,EACzB;EAAA,IAAvB,IAAA,uEAAqB,CAAA,CAAE;EACzB,IAAI,KAAK,CAAC,UAAU,EAAE;IACpB,MAAM,IAAI,KAAK,CACX,8DAA8D,CAAC;EACpE;EACD,KAAK,CAAC,UAAU,GAAG,IAAI;EACvB,IAAI,MAAgB;EACpB,IAAI,OAAiB;EACrB,IAAI,SAA0B;EAC9B,IAAI,SAA0B;EAC9B,IAAI,IAAqB;EACzB,IAAI,IAAqB;EACzB,IAAI,aAAuB;EAC3B,IAAI;IACF,MAAM,SAAS,GAAG,IAAI,CAAC,SAAS,IAAI,IAAI,GAAG,EAAE,GAAG,IAAI,CAAC,SAAS;IAC9D,cAAc,CAAC,SAAS,CAAC;IAEzB;IACA;IACA,MAAM,cAAc,GAAG,KAAK;IAC5B,MAAM,gBAAgB,GAClB,MAAM,KAAK,CAAC,mBAAmB,CAC3B,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,WAAW,EAAE,cAAc,EACzD,SAAS,CAAmC;IACpD,MAAM,GAAG,gBAAgB,CAAC,CAAC,CAAC;IAC5B,OAAO,GAAG,gBAAgB,CAAC,CAAC,CAAC;IAC7B,aAAa,GAAG,gBAAgB,CAAC,CAAC,CAAC;IAEnC;IACA,IAAI,YAAY,GAAG,KAAK;IACxB,IAAI,MAAgB;IACpB,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,GAAG,CAAC,EAAE;MACjE,YAAY,GAAG,IAAI;MACnB,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;QACpC;QACA,SAAS,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC;QAClC,SAAS,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC;OACnC,MAAM,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;QAC3C,MAAM,IAAI,mBAAmB,CACzB,+DAA+D,CAAC;OACrE,MAAM;QACL,MAAM,IAAI,UAAU,CAChB,+DAA+D,GAC/D,4CAA4C,GAC5C,GAAG,IAAI,CAAC,cAAc,cAAc,CAAC;MAC1C;MAED,MAAM,cAAc,GAAG,IAAI;MAC3B,MAAM,eAAe,GACjB,MAAM,KAAK,CAAC,mBAAmB,CAC3B,SAAS,EAAE,SAAS,EAAE,IAAI,EAAE,6BAC5B,IAAI,EAAwB,4BAC5B,cAAc,EAAE,SAAS,CAAmC;MACpE,IAAI,GAAG,eAAe,CAAC,CAAC,CAAC;MACzB,IAAI,GAAG,eAAe,CAAC,CAAC,CAAC;MACzB,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;MAC1B;KACD,MAAM,IACH,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,eAAe,GAAG,CAAC,IACxD,IAAI,CAAC,eAAe,GAAG,CAAC,EAAE;MAC5B,YAAY,GAAG,IAAI;MACnB;MACA,MAAM,OAAO,GACT,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC;MAC/D,MAAM,iBAAiB,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;MAC5C,IAAI,GAAG,WAAW,CAAC,MAAM,EAAE,OAAO,EAAE,iBAAiB,CAAa;MAClE,MAAM,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,OAAO,CAAa;MACpD,IAAI,GAAG,WAAW,CAAC,OAAO,EAAE,OAAO,EAAE,iBAAiB,CAAa;MACnE,OAAO,GAAG,WAAW,CAAC,OAAO,EAAE,CAAC,EAAE,OAAO,CAAa;MACtD;MACA;MACA,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;MAE1B;KACD,MAAM,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;MACvC,YAAY,GAAG,IAAI;MACnB;IACD;;IAED,MAAM,GAAG,GAAG,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,aAAa,CAAC;IAExD,KAAK,CAAC,gCAAgC,EAAE;IAExC;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAM,aAAa,GAAG,KAAK,CAAC,iBAAiB,EAAE;IAC/C,MAAM,SAAS,GAAG,KAAK,CAAC,sBAAsB,EAAc;IAE5D,IAAI,WAAyC;IAC7C,IAAI,eAAyB;IAC7B,IAAI,YAAY,EAAE;MAChB,KAAK,CAAC,gBAAgB,EAAE;MACxB,WAAW,GAAG,KAAK,CAAC,YAAY;MAChC,eAAe,GACX,SAAS,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,IAAI,MAAM,GAAG,CAAC,CAAC,CAAC;KAC7D,MAAM;MACL,WAAW,GAAG,IAAI;MAClB,MAAM,GAAG,EAAE;MACX,eAAe,GAAG,SAAS,CAAC,KAAK,EAAE;IACpC;IAED,MAAM,SAAS,GAAG,oBAAoB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC;IACvE,MAAM,GAAG,GAAG,MAAM,OAAO,CACrB,KAAK,EAAE,aAAa,EAAE,GAAG,EAAE,SAAS,EAAE,SAAS,EAAE,IAAI,CAAC,MAAM,EAC5D,IAAI,CAAC,OAAO,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,IAAI,CAAC,OAAO,EAC1D,eAAe,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,EAAE,IAAI,CAAC;IACnD,OAAO,GAAG;GACX,SAAS;IACR,KAAK,CAAC,UAAU,GAAG,KAAK;IACxB;IACA,iBAAiB,CAAC,MAAM,EAAE,CAAC,CAAC;IAC5B,iBAAiB,CAAC,OAAO,EAAE,CAAC,CAAC;IAC7B,iBAAiB,CAAC,IAAgB,EAAE,SAAS,CAAC;IAC9C,iBAAiB,CAAC,IAAgB,EAAE,SAAS,CAAC;IAC9C,IAAI,aAAa,IAAI,IAAI,EAAE;MACzB,GAAG,CAAC,OAAO,CAAC,aAAa,CAAC;IAC3B;EACF;EACD;AACF;AAEA;;;;;AAKG;AACH,OAAM,SAAU,0BAA0B,CAAC,OAAwB,EAAA;EACjE,MAAM,IAAI,GAAa,EAAE;EACzB,IAAI,OAAO,YAAY,MAAM,EAAE;IAC7B,OAAO,GAAG,CAAC,OAAO,CAAC;EACpB;EAED;EACA,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;IACvC,MAAM,MAAM,GAAG,OAAO,CAAC,CAAC,CAAC;IACzB,IAAI,MAAM,CAAC,IAAI,KAAK,CAAC,EAAE;MACrB,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;KACjC,MAAM,IAAI,MAAM,CAAC,IAAI,KAAK,CAAC,EAAE;MAC5B,MAAM,IAAI,KAAK,CACX,8DAA8D,GAC9D,WAAW,CAAC;KACjB,MAAM;MACL,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC;IAClB;EACF;EACD,OAAO,IAAI;AACb;AAEA;;;;;;;;;;AAUG;AACH;AACA,OAAM,SAAU,iBAAiB,CAC7B,OAAsD,EACtD,UAAyD,EAAA;EAC3D,IAAI,OAAO,IAAI,IAAI,EAAE;IACnB;EACD;EACD,MAAM,YAAY,GAAa,EAAE;EACjC,IAAI,UAAU,YAAY,MAAM,EAAE;IAChC,YAAY,CAAC,IAAI,CAAC,UAAU,CAAC,EAAE,CAAC;GACjC,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,UAAU,CAAC,EAAE;IACpC,UAAU,CAAC,OAAO,CAAC,CAAC,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;GACjD,MAAM,IAAI,UAAU,IAAI,IAAI,EAAE;IAC7B;IACA,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE;MAC7B,MAAM,SAAS,GAAG,UAAU,CAAC,IAAI,CAAC;MAClC,YAAY,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE,CAAC;IAChC;EACF;EAED,MAAM,gBAAgB,GAAa,EAAE;EACrC,IAAI,OAAO,YAAY,MAAM,EAAE;IAC7B,IAAI,YAAY,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;MAC3C,gBAAgB,CAAC,IAAI,CAAC,OAAO,CAAC;IAC/B;GACF,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;IACjC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAG;MAClB,IAAI,YAAY,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;QACrC,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC;MACzB;IACH,CAAC,CAAC;GACH,MAAM,IAAI,OAAO,IAAI,IAAI,EAAE;IAC1B;IACA,KAAK,MAAM,IAAI,IAAI,OAAO,EAAE;MAC1B,MAAM,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC;MAC5B,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;QAC1C,gBAAgB,CAAC,IAAI,CAAC,MAAM,CAAC;MAC9B;IACF;EACF;EAED,gBAAgB,CAAC,OAAO,CAAC,CAAC,IAAG;IAC3B,IAAI,CAAC,CAAC,CAAC,UAAU,EAAE;MACjB,CAAC,CAAC,OAAO,EAAE;IACZ;EACH,CAAC,CAAC;AACJ","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n    }\n    else { // Tensor.\n        return sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(() => {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(array => sliceArraysByIndices(array, indices));\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n    const output = [];\n    let batchStart = 0;\n    let batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n        batchSize = 32;\n    }\n    if (epochs == null) {\n        epochs = 1;\n    }\n    if (shuffle == null) {\n        shuffle = true;\n    }\n    if (initialEpoch == null) {\n        initialEpoch = 0;\n    }\n    // TODO(cais): Change const to let below when implementing validation.\n    let doValidation = false;\n    if (valF != null && valIns != null) {\n        doValidation = true;\n        // TODO(cais): verbose message.\n    }\n    if (validationSteps != null) {\n        doValidation = true;\n        if (stepsPerEpoch == null) {\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                'i.e., `stepsPerEpoch` must be set.');\n        }\n    }\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n    if (numTrainSamples != null) {\n        indexArray = range(0, numTrainSamples);\n    }\n    if (verbose == null) {\n        verbose = 1;\n    }\n    const { callbackList, history } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n        await callbackList.onEpochBegin(epoch);\n        const epochLogs = {};\n        if (stepsPerEpoch != null) {\n            throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n        }\n        else {\n            if (shuffle === 'batch') {\n                throw new NotImplementedError('batch shuffling is not implemneted yet');\n            }\n            else if (shuffle) {\n                util.shuffle(indexArray);\n            }\n            // Convert the potentially shuffled indices to Tensor1D, to avoid the\n            // cost of repeated creation of Array1Ds later on.\n            const epochIndexArray1D = tensor1d(indexArray);\n            const batches = makeBatches(numTrainSamples, batchSize);\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchLogs = {};\n                await callbackList.onBatchBegin(batchIndex, batchLogs);\n                tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = batchEnd - batchStart;\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const outs = f(insBatch);\n                    for (let i = 0; i < outLabels.length; ++i) {\n                        const label = outLabels[i];\n                        const out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                        // TODO(cais): Use scope() to avoid ownership.\n                    }\n                    if (batchIndex === batches.length - 1) { // Last batch.\n                        if (doValidation) {\n                            const valOuts = model.testLoop(valF, valIns, batchSize);\n                            // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                            for (let i = 0; i < outLabels.length; ++i) {\n                                const label = outLabels[i];\n                                const out = valOuts[i];\n                                tfc.keep(out);\n                                // TODO(cais): Use scope() to avoid ownership.\n                                epochLogs['val_' + label] = out;\n                            }\n                        }\n                    }\n                });\n                await callbackList.onBatchEnd(batchIndex, batchLogs);\n                disposeTensorsInLogs(batchLogs);\n                if (model.stopTraining_) {\n                    break;\n                }\n                // TODO(cais): return outs as list of Tensor.\n            }\n            epochIndexArray1D.dispose();\n        }\n        // TODO(cais): Run validation at the end of the epoch.\n        await callbackList.onEpochEnd(epoch, epochLogs);\n        if (model.stopTraining_) {\n            break;\n        }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n    if (model.isTraining) {\n        throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n    try {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // Validate user data.\n        // TODO(cais): Support sampleWeight.\n        const checkBatchAxis = false;\n        const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        sampleWeights = standardizedOuts[2];\n        // Prepare validation data.\n        let doValidation = false;\n        let valIns;\n        if (args.validationData != null && args.validationData.length > 0) {\n            doValidation = true;\n            if (args.validationData.length === 2) {\n                // config.validationData consists of valX and valY.\n                inputValX = args.validationData[0];\n                inputValY = args.validationData[1];\n            }\n            else if (args.validationData.length === 3) {\n                throw new NotImplementedError('validationData including sample weights is not supported yet.');\n            }\n            else {\n                throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` +\n                    `or 3 (valX, valY, valSampleWeight) items; ` +\n                    `${args.validationData} is invalid.`);\n            }\n            const checkBatchAxis = true;\n            const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis, batchSize);\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSplit != null && args.validationSplit > 0 &&\n            args.validationSplit < 1) {\n            doValidation = true;\n            // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            const originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            // TODO(cais): Once sampleWeights becomes available, slice it to get\n            //   valSampleWeights.\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSteps != null) {\n            doValidation = true;\n            // TODO(cais): Add useLearningPhase.\n        }\n        const ins = inputs.concat(targets).concat(sampleWeights);\n        model.checkTrainableWeightsConsistency();\n        // TODO(cais): Handle use_learning_phase and learning_phase?\n        // Porting Note: Here we see a key deviation of tfjs-layers from\n        // Keras.\n        //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n        //  we do not construct symbolic computation graphs to embody the\n        //  training process. Instead, we define a function that performs the\n        //  training action. In PyKeras, the data (inputs and targets) are fed\n        //  through graph placeholders. In tfjs-layers, the data are fed as\n        //  function arguments. Since the function are defined below in the\n        //  scope, we don't have equivalents of PyKeras's\n        //  `_make_train_funciton`.\n        const trainFunction = model.makeTrainFunction();\n        const outLabels = model.getDedupedMetricsNames();\n        let valFunction;\n        let callbackMetrics;\n        if (doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics =\n                outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n        }\n        else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n        }\n        const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n        const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n        return out;\n    }\n    finally {\n        model.isTraining = false;\n        // Memory clean up.\n        disposeNewTensors(inputs, x);\n        disposeNewTensors(targets, y);\n        disposeNewTensors(valX, inputValX);\n        disposeNewTensors(valY, inputValY);\n        if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n        }\n    }\n    // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n    const outs = [];\n    if (tensors instanceof Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (let i = 0; i < tensors.length; ++i) {\n        const tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    const oldTensorIds = [];\n    if (refTensors instanceof Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(t => oldTensorIds.push(t.id));\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in refTensors) {\n            const oldTensor = refTensors[name];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    const tensorsToDispose = [];\n    if (tensors instanceof Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(t => {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in tensors) {\n            const tensor = tensors[name];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(t => {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\n//# sourceMappingURL=training_tensors.js.map"]},"metadata":{},"sourceType":"module"}