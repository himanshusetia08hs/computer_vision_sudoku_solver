{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Relu } from '../kernel_names';\nimport { cast } from '../ops/cast';\nimport { mul } from '../ops/mul';\nimport { step } from '../ops/step';\nexport const reluGradConfig = {\n  kernelName: Relu,\n  inputsToSave: ['x'],\n  gradFunc: (dy, saved) => {\n    const [x] = saved;\n    return {\n      x: () => mul(dy, cast(step(x), 'float32'))\n    };\n  }\n};","map":{"version":3,"sources":["../../../../../../tfjs-core/src/gradients/Relu_grad.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,IAAI,QAAO,iBAAiB;AAEpC,SAAQ,IAAI,QAAO,aAAa;AAChC,SAAQ,GAAG,QAAO,YAAY;AAC9B,SAAQ,IAAI,QAAO,aAAa;AAGhC,OAAO,MAAM,cAAc,GAAe;EACxC,UAAU,EAAE,IAAI;EAChB,YAAY,EAAE,CAAC,GAAG,CAAC;EACnB,QAAQ,EAAE,CAAC,EAAU,EAAE,KAAe,KAAI;IACxC,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK;IACjB,OAAO;MAAC,CAAC,EAAE,MAAM,GAAG,CAAC,EAAE,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC;IAAC,CAAC;EACrD;CACD","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Relu} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport {cast} from '../ops/cast';\nimport {mul} from '../ops/mul';\nimport {step} from '../ops/step';\nimport {Tensor} from '../tensor';\n\nexport const reluGradConfig: GradConfig = {\n  kernelName: Relu,\n  inputsToSave: ['x'],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [x] = saved;\n    return {x: () => mul(dy, cast(step(x), 'float32'))};\n  }\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}