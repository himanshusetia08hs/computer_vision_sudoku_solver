{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { complex } from './Complex';\nimport { concatImpl } from './Concat_impl';\nimport { identity } from './Identity';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concat(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    axis\n  } = attrs;\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({\n      inputs: {\n        x: $inputs[0]\n      },\n      backend\n    });\n  }\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map(t => real({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const imags = $inputs.map(t => imag({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const realConcated = concat({\n      inputs: reals,\n      backend,\n      attrs: {\n        axis: $axis\n      }\n    });\n    const imagConcated = concat({\n      inputs: imags,\n      backend,\n      attrs: {\n        axis: $axis\n      }\n    });\n    const result = complex({\n      inputs: {\n        real: realConcated,\n        imag: imagConcated\n      },\n      backend\n    });\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n    return result;\n  }\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({\n      inputs: {\n        x: t\n      },\n      backend,\n      attrs: {\n        shape\n      }\n    });\n  });\n  const inputsValShapes = inputs2D.map(t => {\n    return {\n      vals: backend.data.get(t.dataId).values,\n      shape: t.shape\n    };\n  });\n  // Concats 2d tensors along axis=1.\n  outShape = backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n  const finalOutShape = backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n  const outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return outInfo;\n}\nexport const concatConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/Concat.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAE,MAAM,EAAmE,IAAI,QAAO,uBAAuB;AAIjI,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,UAAU,QAAO,eAAe;AACxC,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAU,MAAM,CAClB,IAAyE,EAAA;EAE3E,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAI,CAAC,GAAG,KAAK;EAEpB,MAAM,KAAK,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;EAE3D,MAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC;EACvC,YAAY,CAAC,sBAAsB,CAAC,MAAM,EAAE,KAAK,CAAC;EAElD,IAAI,QAAQ,GAAG,YAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC;EAE5E,IAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAE;IACtC,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC;EAC7D;EAED;EACA,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;EACnE,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;IACxB,OAAO,QAAQ,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE,OAAO,CAAC,CAAC;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC;EACpD;EAED,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;IACpC,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IACrE,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IAErE,MAAM,YAAY,GAAG,MAAM,CAAC;MAAC,MAAM,EAAE,KAAK;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAK;IAAC,CAAC,CAAC;IAC3E,MAAM,YAAY,GAAG,MAAM,CAAC;MAAC,MAAM,EAAE,KAAK;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAK;IAAC,CAAC,CAAC;IAE3E,MAAM,MAAM,GACR,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,IAAI,EAAE,YAAY;QAAE,IAAI,EAAE;MAAY,CAAC;MAAE;IAAO,CAAC,CAAC;IAExE,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IACnD,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IAEnD,OAAO,MAAM;EACd;EAED;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAG;IAC/B,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;IAC1D,MAAM,KAAK,GAAG,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC;IAC7B,OAAO,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC;MAAK;IAAC,CAAC,CAAC;EAC3D,CAAC,CAAC;EAEF,MAAM,eAAe,GAAG,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAG;IACvC,OAAO;MAAC,IAAI,EAAE,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM;MAAE,KAAK,EAAE,CAAC,CAAC;IAAK,CAAC;EAClE,CAAC,CAAC;EAEF;EACA,QAAQ,GACJ,YAAY,CAAC,eAAe,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,WAAW;EAC1E,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;EAC/C,MAAM,OAAO,GACT,UAAU,CAAC,eAAe,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,YAAY,CAAC;EAExE,MAAM,aAAa,GACf,YAAY,CAAC,eAAe,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC;EAElE,MAAM,OAAO,GACT,OAAO,CAAC,cAAc,CAAC,aAAa,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,OAAO,CAAC;EAEnE,QAAQ,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;EAE/D,OAAO,OAAO;AAChB;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis: $axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis: $axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  const inputsValShapes = inputs2D.map(t => {\n    return {vals: backend.data.get(t.dataId).values, shape: t.shape};\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals =\n      concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}