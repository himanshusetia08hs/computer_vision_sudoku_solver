{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Cumsum, util } from '@tensorflow/tfjs-core';\nimport { CppDType } from './types';\nimport { transpose } from './Transpose';\nlet wasmCumsum;\nfunction setup(backend) {\n  wasmCumsum = backend.wasm.cwrap(Cumsum, null /* void */, ['number', 'number', 'number', 'number', 'number', 'number' // dtype\n  ]);\n}\n\nexport function cumsum(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    axis,\n    exclusive,\n    reverse\n  } = attrs;\n  const xRank = x.shape.length;\n  util.assert(x.dtype === 'float32' || x.dtype === 'int32', () => `cumsum does not support ${x.dtype} tensors in the WASM backend`);\n  // permute required axis to inner most axis\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation !== null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      attrs: {\n        perm: permutation\n      },\n      backend\n    });\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  backend_util.assertAxesAreInnerMostDims('cumsum', [permutedAxis], xRank);\n  const permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);\n  const finalDim = permutedX.shape[permutedAxis];\n  const permutedXId = backend.dataIdMap.get(permutedX.dataId).id;\n  const permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;\n  wasmCumsum(permutedXId, exclusive ? 1 : 0, reverse ? 1 : 0, finalDim, permutedOutId, CppDType[x.dtype]);\n  // transpose data back if permuted\n  let out = permutedOut;\n  if (permutation !== null) {\n    const undoPermutation = backend_util.getUndoAxesPermutation(permutation);\n    out = transpose({\n      inputs: {\n        x: permutedOut\n      },\n      attrs: {\n        perm: undoPermutation\n      },\n      backend\n    });\n    backend.disposeData(permutedX.dataId);\n    backend.disposeData(permutedOut.dataId);\n  }\n  return out;\n}\nexport const cumsumConfig = {\n  kernelName: Cumsum,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: cumsum\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-wasm/src/kernels/Cumsum.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAA4B,MAAM,EAAyC,IAAI,QAAO,uBAAuB;AAIjI,SAAQ,QAAQ,QAAO,SAAS;AAEhC,SAAQ,SAAS,QAAO,aAAa;AAErC,IAAI,UACsE;AAE1E,SAAS,KAAK,CAAC,OAAoB,EAAA;EACjC,UAAU,GAAG,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE,IAAI,CAAC,YAAY,CACvD,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,CAAE;EAAA,CACX,CAAC;AACJ;;AAEA,OAAM,SAAU,MAAM,CACpB,IAAsE,EAAA;EAEtE,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC,IAAI;IAAE,SAAS;IAAE;EAAO,CAAC,GAAG,KAAK;EACxC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAE5B,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,KAAK,SAAS,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,EACtD,MAAM,2BAA2B,CAAC,CAAC,KAAK,8BAA8B,CAAC;EACzE;EACA,MAAM,WAAW,GAAG,YAAY,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,CAAC;EAClE,IAAI,SAAS,GAAG,CAAC;EACjB,IAAI,WAAW,KAAK,IAAI,EAAE;IACxB,SAAS,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAW,CAAC;MAAE;IAAO,CAAC,CAAC;EAC1E;EACD,MAAM,YAAY,GAAG,YAAY,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;EAC/D,YAAY,CAAC,0BAA0B,CAAC,QAAQ,EAAE,CAAC,YAAY,CAAC,EAAE,KAAK,CAAC;EAExE,MAAM,WAAW,GAAG,OAAO,CAAC,UAAU,CAAC,SAAS,CAAC,KAAK,EAAE,SAAS,CAAC,KAAK,CAAC;EACxE,MAAM,QAAQ,GAAG,SAAS,CAAC,KAAK,CAAC,YAAY,CAAC;EAC9C,MAAM,WAAW,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,EAAE;EAC9D,MAAM,aAAa,GAAG,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC,EAAE;EAClE,UAAU,CAAC,WAAW,EAAE,SAAS,GAAG,CAAC,GAAG,CAAC,EAAE,OAAO,GAAG,CAAC,GAAG,CAAC,EAAE,QAAQ,EACzD,aAAa,EAAE,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;EAE5C;EACA,IAAI,GAAG,GAAG,WAAW;EACrB,IAAI,WAAW,KAAK,IAAI,EAAE;IACxB,MAAM,eAAe,GAAG,YAAY,CAAC,sBAAsB,CAAC,WAAW,CAAC;IACxE,GAAG,GAAG,SAAS,CACb;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAW,CAAC;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAe,CAAC;MAAE;IAAO,CAAC,CAAC;IACtE,OAAO,CAAC,WAAW,CAAC,SAAS,CAAC,MAAM,CAAC;IACrC,OAAO,CAAC,WAAW,CAAC,WAAW,CAAC,MAAM,CAAC;EACxC;EACD,OAAO,GAAG;AACZ;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,MAAM;EACnB,SAAS,EAAE,KAAK;EAChB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Cumsum, CumsumAttrs, CumsumInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {CppDType} from './types';\n\nimport {transpose} from './Transpose';\n\nlet wasmCumsum: (xId: number, exclusive: number, reverse: number,\n                 finalDim: number, outId: number, dtype: CppDType) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmCumsum = backend.wasm.cwrap(Cumsum, null /* void */, [\n    'number', // x_id\n    'number', // exclusive\n    'number', // reverse\n    'number', // final_dim\n    'number', // out_id\n    'number'  // dtype\n  ]);\n}\n\nexport function cumsum(\n  args: {inputs: CumsumInputs, backend: BackendWasm, attrs: CumsumAttrs}):\nTensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  const xRank = x.shape.length;\n\n  util.assert(x.dtype === 'float32' || x.dtype === 'int32',\n    () => `cumsum does not support ${x.dtype} tensors in the WASM backend`);\n  // permute required axis to inner most axis\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation !== null) {\n    permutedX = transpose({inputs: {x}, attrs: {perm: permutation}, backend});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  backend_util.assertAxesAreInnerMostDims('cumsum', [permutedAxis], xRank);\n\n  const permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);\n  const finalDim = permutedX.shape[permutedAxis];\n  const permutedXId = backend.dataIdMap.get(permutedX.dataId).id;\n  const permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;\n  wasmCumsum(permutedXId, exclusive ? 1 : 0, reverse ? 1 : 0, finalDim,\n             permutedOutId, CppDType[x.dtype]);\n\n  // transpose data back if permuted\n  let out = permutedOut;\n  if (permutation !== null) {\n    const undoPermutation = backend_util.getUndoAxesPermutation(permutation);\n    out = transpose(\n      {inputs: {x: permutedOut}, attrs: {perm: undoPermutation}, backend});\n    backend.disposeData(permutedX.dataId);\n    backend.disposeData(permutedOut.dataId);\n  }\n  return out;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: cumsum as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}