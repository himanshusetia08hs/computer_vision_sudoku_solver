{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(graph, parent) {\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n  get weightIds() {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n  get functionExecutorMap() {\n    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n  }\n  get weightMap() {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n  set weightMap(weightMap) {\n    const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager) {\n    this._resourceManager = resourceManager;\n  }\n  get inputs() {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n  get outputs() {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n  get inputNodes() {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n  get outputNodes() {\n    return this._outputs.map(node => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;\n    });\n  }\n  get functions() {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {});\n  }\n  getCompilationKey(inputs, outputs) {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n  }\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  compile(inputs, outputs) {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` + `the dynamic op '${dynamicNode.op}'. Please use ` + `model.executeAsync() instead. Alternatively, to avoid the ` + `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` + `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs, outputs) {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n    const tensorArrayMap = {};\n    const tensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n      const tensorsMap = Object.assign({}, this.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n          if (util.isPromise(tensors)) {\n            throw new Error(`The execution of the op '${node.op}' returned a promise. ` + `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n  getFrozenTensorIds(tensorMap) {\n    const ids = [].concat.apply([], Object.keys(tensorMap).map(key => tensorMap[key]).map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs, outputs) {\n    return this._executeAsync(inputs, outputs);\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  async _executeAsync(inputs, outputs) {\n    let isFunctionExecution = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    let tensorArrayMap = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n    let tensorListMap = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n    const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n    return results;\n  }\n  async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {});\n    return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n    const names = Object.keys(inputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n    const {\n      usedNodes,\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack = [...inputNodes, ...this.graph.weights, ...(this._initNodes || [])].map(node => {\n      return {\n        node,\n        contexts: context.currentContext\n      };\n    });\n    const tensorsMap = Object.assign({}, this.weightMap);\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(`This model execution did not contain any nodes with control flow ` + `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs = outputNodes.filter(node => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() ` + `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` + `inputs [${names}]. Consider providing the following inputs: ` + `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n  processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n    const promises = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n  processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n    node.children.forEach(childNode => {\n      const [nodeName] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n      } else\n        // Otherwise all inputs must to have value.\n        if (childNode.inputNames.every(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n    });\n  }\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap).forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n  checkInputShapeAndType(inputs) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value;\n        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(match, () => `The shape of dict['${node.name}'] provided in ` + `model.execute(dict) must be [${shape}], but was ` + `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` + `model.execute(dict) must be ` + `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n  mapInputs(inputs) {\n    const result = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n  checkInputs(inputs) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(`The dict provided in model.execute(dict) has ` + `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n  mapOutputs(outputs) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n  checkOutputs(outputs) {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}","map":{"version":3,"sources":["../../src/executor/graph_executor.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAA0C,IAAI,EAAE,IAAI,QAAO,uBAAuB;AAIlF,SAAQ,mBAAmB,EAAE,aAAa,EAAE,SAAS,EAAE,4BAA4B,EAAE,aAAa,QAAO,+BAA+B;AACxI,SAAQ,SAAS,QAAO,kCAAkC;AAG1D,SAAQ,gBAAgB,QAA6B,qBAAqB;AAC1E,SAAQ,oBAAoB,EAAE,0BAA0B,EAAE,aAAa,QAAO,kBAAkB;AAShG,OAAM,MAAO,aAAa,CAAA;EAuFxB;;;;;;;AAOG;EACH,WAAA,CAAoB,KAAY,EAAU,MAAsB,EAAA;IAA5C,IAAA,CAAA,KAAK,GAAL,KAAK;IAAiB,IAAA,CAAA,MAAM,GAAN,MAAM;IA9FxC,IAAA,CAAA,WAAW,GAAwB,IAAI,GAAG,EAAE;IAC5C,IAAA,CAAA,UAAU,GAAoB,CAAA,CAAE;IAMhC,IAAA,CAAA,SAAS,GAAG,GAAG;IACf,IAAA,CAAA,UAAU,GAA2B,CAAA,CAAE;IACvC,IAAA,CAAA,oBAAoB,GAAsC,CAAA,CAAE;IAsFlE,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,OAAO;IAC7B,IAAI,CAAC,OAAO,GAAG,KAAK,CAAC,MAAM;IAC3B,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS;IACjC,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS;IACjC,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS;IACjC;IACA,IAAI,KAAK,CAAC,SAAS,IAAI,IAAI,EAAE;MAC3B,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,IAAG;QAC1C,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,GAC3B,IAAI,aAAa,CAAC,KAAK,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE,IAAI,CAAC;MACpD,CAAC,CAAC;IACH;EACH;EA/FA,IAAI,SAAS,GAAA;IACX,OAAO,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,GAAG,IAAI,CAAC,UAAU;EAC9D;EAEA,IAAI,mBAAmB,GAAA;IACrB,OAAO,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,mBAAmB,GAC/B,IAAI,CAAC,oBAAoB;EAChD;EAEA,IAAI,SAAS,GAAA;IACX,OAAO,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,GAAG,IAAI,CAAC,UAAU;EAC9D;EAEA,IAAI,SAAS,CAAC,SAA0B,EAAA;IACtC,MAAM,SAAS,GAAG,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,GAAG,CACxC,GAAG,IAAI,SAAS,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,IAAI,MAAM,CAAC,EAAE,CAAC,CAAC;IACnD,IAAI,CAAC,UAAU,GAAG,EAAE,CAAC,MAAM,CAAC,GAAG,SAAS,CAAC;IACzC,IAAI,CAAC,UAAU,GAAG,SAAS;EAC7B;EAEA;;;AAGG;EACH,IAAI,eAAe,CAAC,eAAgC,EAAA;IAClD,IAAI,CAAC,gBAAgB,GAAG,eAAe;EACzC;EAEA,IAAI,MAAM,GAAA;IACR,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,IAAI,IAAG;MAC7B,OAAO;QACL,IAAI,EAAE,IAAI,CAAC,IAAI;QACf,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,GAC3B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,GAC1C,SAAS;QACb,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,GAC3B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,GAC1C;OACL;IACH,CAAC,CAAC;EACJ;EAEA,IAAI,OAAO,GAAA;IACT,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,IAAI,IAAG;MAC9B,OAAO;QACL,IAAI,EAAE,IAAI,CAAC,IAAI;QACf,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,GAC3B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,GAC1C,SAAS;QACb,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,GAC3B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,GAC1C;OACL;IACH,CAAC,CAAC;EACJ;EAEA,IAAI,UAAU,GAAA;IACZ,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,IAAI,CAAC;EACjE;EAEA,IAAI,WAAW,GAAA;IACb,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAE,IAAI,IAAI;MAChC,MAAM,IAAI,GAAG,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,IAAI;MAC3C,OAAO,IAAI,CAAC,aAAa,GAAI,GAAG,IAAI,IAAI,IAAI,CAAC,aAAa,EAAE,GAAI,IAAI;IACtE,CAAC,CAAC;EACJ;EAEA,IAAI,SAAS,GAAA;IACX,OAAO,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,KAAI;MACtD,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,SAAS;MACzC,OAAO,GAAG;IACZ,CAAC,EAAE,CAAA,CAAoC,CAAC;EAC1C;EAyBQ,iBAAiB,CAAC,MAAc,EAAE,OAAe,EAAA;IACvD,MAAM,YAAY,GAAG,MAAM,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,EAAE;IACzD,MAAM,aAAa,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,EAAE;IAC3D,OAAO,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,IAAI,GAC3C,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC;EACxC;EAEA;;;AAGG;EACK,OAAO,CAAC,MAAsB,EAAE,OAAe,EAAA;IACrD,MAAM,aAAa,GACf,oBAAoB,CAAC,MAAM,EAAE,OAAO,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC;IAC1E,MAAM;MAAC,aAAa;MAAE,WAAW;MAAE;IAAU,CAAC,GAAG,aAAa;IAC9D,IAAI,WAAW,IAAI,IAAI,EAAE;MACvB,MAAM,IAAI,KAAK,CACX,qCAAqC,WAAW,CAAC,IAAI,eAAe,GACpE,mBAAmB,WAAW,CAAC,EAAE,gBAAgB,GACjD,4DAA4D,GAC5D,oCAAoC,UAAU,GAAG,CAAC;IACvD;IAED,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE;MAC5B,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC;MACzC,MAAM,OAAO,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC;MACnC,MAAM,IAAI,KAAK,CACX,+BAA+B,QAAQ,6BAA6B,GACpE,IAAI,OAAO,qCAAqC,aAAa,GAAG,CAAC;IACtE;IAED,OAAO,0BAA0B,CAC7B,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,SAAS,EAAE,aAAa,CAAC;EAChD;EAEA;;;;;;;;AAQG;EACH,OAAO,CAAC,MAAsB,EAAE,OAAkB,EAAA;IAChD,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC;IAC/B,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE;IACxC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;IACxB,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC;IACnC,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC;IAClC,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC;IAC1B,MAAM,UAAU,GACZ,KAAK,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/D,MAAM,eAAe,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;IACnE,IAAI,WAAW,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IAErE;IACA,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;MAC5B,WAAW,GAAG,IAAI,CAAC,QAAQ;IAC5B;IAED,MAAM,cAAc,GAAG,IAAI,CAAC,iBAAiB,CAAC,UAAU,EAAE,WAAW,CAAC;IAEtE;IACA,IAAI,YAAY,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,cAAc,CAAC;IACvD,IAAI,YAAY,IAAI,IAAI,EAAE;MACxB,YAAY,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC;MAChD,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,cAAc,EAAE,YAAY,CAAC;IACnD;IAED,MAAM,cAAc,GAAmB,CAAA,CAAE;IACzC,MAAM,aAAa,GAAkB,CAAA,CAAE;IAEvC,OAAO,IAAI,CAAC,MAAK;MACf,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAChC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,aAAa,EAC7C,IAAI,CAAC,mBAAmB,CAAC;MAC7B,MAAM,UAAU,GAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAwB,IAAI,CAAC,SAAS,CAAC;MAEvD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,IAAI,IAAG;QACjC,MAAM,CAAC,QAAQ,EAAE,KAAK,CAAC,GAAG,aAAa,CAAC,IAAI,CAAC;QAC7C,MAAM,OAAO,GAAa,EAAE;QAC5B,OAAO,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,IAAI,CAAC;QAC7B,UAAU,CAAC,QAAQ,CAAC,GAAG,OAAO;MAChC,CAAC,CAAC;MAEF,MAAM,aAAa,GAAG,IAAI,CAAC,kBAAkB,CAAC,UAAU,CAAC;MACzD,MAAM,+BAA+B,GAA4B,CAAA,CAAE;MACnE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QAC5C,MAAM,IAAI,GAAG,YAAY,CAAC,CAAC,CAAC;QAC5B,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;UAC1B,MAAM,OAAO,GACT,SAAS,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAClD;UACZ,IAAI,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE;YAC3B,MAAM,IAAI,KAAK,CACX,4BAA4B,IAAI,CAAC,EAAE,wBAAwB,GAC3D,0CAA0C,CAAC;UAChD;UACD,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,OAAO;UAC/B,IAAI,CAAC,sBAAsB,CACvB,IAAI,CAAC,IAAI,EAAE,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,aAAa,EACnD,eAAe,EAAE,+BAA+B,CAAC;QACtD;MACF;MACD;MACA,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;QACvB,OAAO,CAAC,OAAO,CAAC,aAAa,CAAC;MAC/B;MACD,OAAO,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,SAAS,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;IAClE,CAAC,CAAC;EACJ;EAEQ,kBAAkB,CAAC,SAA0B,EAAA;IACnD,MAAM,GAAG,GAAG,EAAE,CAAC,MAAM,CAAC,KAAK,CACvB,EAAE,EACF,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CACjB,GAAG,CAAC,GAAG,IAAI,SAAS,CAAC,GAAG,CAAC,CAAC,CAC1B,GAAG,CAAC,OAAO,IAAI,OAAO,CAAC,GAAG,CAAC,MAAM,IAAI,MAAM,CAAC,EAAE,CAAC,CAAC,CAAC;IAC1D,OAAO,IAAI,GAAG,CAAC,GAAG,CAAC;EACrB;EACQ,sBAAsB,CAC1B,QAAgB,EAAE,IAAU,EAAE,SAA0B,EACxD,OAAyB,EAAE,aAA0B,EACrD,WAAqB,EACrB,+BAAwD,EAAA;IAC1D;IACA;IACA,IAAI,IAAI,CAAC,QAAQ,KAAK,SAAS,IAAI,WAAW,CAAC,OAAO,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE;MACvE;IACD;IAED,SAAS,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC,MAAM,IAAG;MACnC,IAAI,MAAM,IAAI,IAAI,EAAE;QAClB,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,GACtC,CAAC,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,IAChD,IAAI,CAAC,QAAQ,CAAC,MAAM;MACzB;IACH,CAAC,CAAC;IACF,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,KAAK,IAAG;MAC1B;MACA;MACA,IAAI,KAAK,CAAC,QAAQ,KAAK,SAAS,EAAE;QAChC,MAAM,OAAO,GACT,4BAA4B,CAAC,KAAK,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC;QAChE,IAAI,OAAO,IAAI,IAAI,EAAE;UACnB,OAAO,CAAC,OAAO,CAAC,MAAM,IAAG;YACvB,IAAI,MAAM,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;cAC3C,MAAM,KAAK,GAAG,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC;cACxD,IAAI,KAAK,KAAK,CAAC,EAAE;gBACf,MAAM,CAAC,OAAO,EAAE;gBAChB,OAAO,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC;eAClD,MAAM,IAAI,KAAK,IAAI,IAAI,EAAE;gBACxB;gBACA;gBACA,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;cAC7C;YACF;UACH,CAAC,CAAC;QACH;MACF;IACH,CAAC,CAAC;EACJ;EAEA;;;;;;;;AAQG;EACH,MAAM,YAAY,CAAC,MAAsB,EAAE,OAAkB,EAAA;IAE3D,OAAO,IAAI,CAAC,aAAa,CAAC,MAAM,EAAE,OAAO,CAAC;EAC5C;EAEA;;;;;;;;;;;;;AAaG;EACK,MAAM,aAAa,CACvB,MAAsB,EAAE,OAAkB,EAET;IAAA,IAFW,mBAAmB,uEAAG,KAAK;IAAA,IACvE,cAAA,uEAAiC,CAAA,CAAE;IAAA,IACnC,aAAA,uEAA+B,CAAA,CAAE;IACnC,IAAI,CAAC,mBAAmB,EAAE;MACxB,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC;MAC/B,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;MACxB,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC;MACnC,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC;MAClC,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC;IAC3B;IAED,MAAM,OAAO,GAAG,IAAI,gBAAgB,CAChC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,aAAa,EAC7C,IAAI,CAAC,mBAAmB,CAAC;IAE7B;IACA;IACA;IACA,MAAM,SAAS,GAAG,MAAM,IAAI,CAAC,sBAAsB,CAC/C,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,mBAAmB,CAAC;IAClD,MAAM,OAAO,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,SAAS,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;IAExE;IACA,MAAM,SAAS,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC;IACxC,MAAM,QAAQ,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,IAAI,IAAI,MAAM,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC;IACjE,MAAM,OAAO,GACT,IAAI,GAAG,CAAS,CAAC,GAAG,SAAS,EAAE,GAAG,QAAQ,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC;IACnE,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,GAAG,IAAG;MACnC,MAAM,WAAW,GAAG,SAAS,CAAC,GAAG,CAAC;MAClC,WAAW,CAAC,OAAO,CAAC,MAAM,IAAG;QAC3B,IAAI,MAAM,IAAI,CAAC,MAAM,CAAC,UAAU,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;UAC3D,MAAM,CAAC,OAAO,EAAE;QACjB;MACH,CAAC,CAAC;IACJ,CAAC,CAAC;IACF;IACA,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;MACvB,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC;IACzB;IAED,OAAO,OAAO;EAChB;EAEA,MAAM,oBAAoB,CACtB,MAAgB,EAAE,cAA8B,EAChD,aAA4B,EAAA;IAC9B,MAAM,YAAY,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,MAAM,EAAE,KAAK,KAAI;MACxD,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,MAAM;MACrC,OAAO,GAAG;IACZ,CAAC,EAAE,CAAA,CAAoB,CAAC;IAExB,OAAO,IAAI,CAAC,aAAa,CACrB,YAAY,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,EAAE,cAAc,EAAE,aAAa,CAAC;EAC1E;EACA;;;;;;;;;;AAUG;EACK,MAAM,sBAAsB,CAChC,MAAsB,EAAE,OAAyB,EAAE,WAAsB,EACzE,mBAA6B,EAAA;IAC/B,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC;IACjC,MAAM,UAAU,GACZ,KAAK,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/D,MAAM,eAAe,GAAG,WAAW,CAAC,GAAG,CAAC,IAAI,IAAI,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;IACvE,IAAI,WAAW,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IAErE;IACA,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;MAC5B,WAAW,GAAG,IAAI,CAAC,QAAQ;IAC5B;IAED,MAAM;MAAC,SAAS;MAAE,aAAa;MAAE,WAAW;MAAE;IAAU,CAAC,GACrD,oBAAoB,CAChB,MAAM,EAAE,WAAW,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC;IAE7D;IACA,MAAM,KAAK,GAAuB,CAChC,GAAG,UAAU,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,IAAI,IAAI,CAAC,UAAU,IAAI,EAAE,CAAC,CACjE,CAAC,GAAG,CAAC,IAAI,IAAG;MACX,OAAO;QAAC,IAAI;QAAE,QAAQ,EAAE,OAAO,CAAC;MAAc,CAAC;IACjD,CAAC,CAAC;IACF,MAAM,UAAU,GAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAwB,IAAI,CAAC,SAAS,CAAC;IACvD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,IAAI,IAAG;MACjC,MAAM,CAAC,QAAQ,EAAE,KAAK,CAAC,GAAG,aAAa,CAAC,IAAI,CAAC;MAC7C,MAAM,OAAO,GAAa,EAAE;MAC5B,OAAO,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,IAAI,CAAC;MAC7B,UAAU,CAAC,QAAQ,CAAC,GAAG,OAAO;IAChC,CAAC,CAAC;IACF,MAAM,+BAA+B,GAA4B,CAAA,CAAE;IACnE,MAAM,aAAa,GAAG,IAAI,CAAC,kBAAkB,CAAC,UAAU,CAAC;IACzD,MAAM,KAAK,GAA6B,CAAA,CAAE;IAC1C,OAAO,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;MACvB,MAAM,QAAQ,GAAG,IAAI,CAAC,YAAY,CAC9B,UAAU,EAAE,KAAK,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,EAAE,aAAa,EAC5D,eAAe,EAAE,+BAA+B,EAAE,SAAS,CAAC;MAChE,MAAM,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC;IAC5B;IACD,IAAI,WAAW,IAAI,IAAI,IAAI,CAAC,mBAAmB,EAAE;MAC/C,OAAO,CAAC,IAAI,CACR,mEAAmE,GACnE,gEAAgE,CAAC;IACtE;IACD,MAAM,cAAc,GAChB,WAAW,CACN,MAAM,CACH,IAAI,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,IACxB,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC,CAClD,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC;IAC/B,IAAI,cAAc,CAAC,MAAM,GAAG,CAAC,EAAE;MAC7B,IAAI,cAAc,GAAG,EAAE;MACvB,IAAI,WAAW,IAAI,IAAI,EAAE;QACvB,cAAc,GACV,+DAA+D,GAC/D,2BAA2B,UAAU,GAAG;MAC7C;MACD,MAAM,IAAI,KAAK,CACX,+BAA+B,cAAc,sBAAsB,GACnE,WAAW,KAAK,8CAA8C,GAC9D,IAAI,aAAa,MAAM,cAAc,EAAE,CAAC;IAC7C;IACD,OAAO,UAAU;EACnB;EAEQ,YAAY,CAChB,UAAkB,EAAE,KAAyB,EAAE,OAAyB,EACxE,SAA0B,EAAE,KAA+B,EAC3D,aAA0B,EAAE,WAAqB,EACjD,+BAAwD,EACxD,SAAsB,EAAA;IACxB,MAAM,QAAQ,GAA6B,EAAE;IAC7C,OAAO,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;MACvB,MAAM,IAAI,GAAG,KAAK,CAAC,GAAG,EAAE;MACxB,OAAO,CAAC,cAAc,GAAG,IAAI,CAAC,QAAQ;MACtC,IAAI,QAAQ,GAAG,EAAE;MACjB;MACA;MACA;MACA,IAAI,IAAI,CAAC,IAAI,CAAC,EAAE,KAAK,OAAO,IACxB,aAAa,CAAC,YAAY,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,EAAE;QAC9D,CAAC,QAAQ,CAAC,GAAG,mBAAmB,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,OAAO,CAAC;MAC1D;MAED;MACA;MACA,IAAI,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;QACrC,MAAM,OAAO,GACT,SAAS,CAAC,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAAC;QACnE,IAAI,CAAC,QAAQ,EAAE;UACb,CAAC,QAAQ,CAAC,GAAG,mBAAmB,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,OAAO,CAAC;QAC1D;QACD,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc;QAC7C,IAAI,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE;UAC3B,QAAQ,CAAC,IAAI,CAAE,OAA6B,CAAC,IAAI,CAAC,CAAC,IAAG;YACpD,SAAS,CAAC,QAAQ,CAAC,GAAG,CAAC;YACvB,OAAO,CAAC,cAAc,GAAG,cAAc;YACvC,IAAI,CAAC,sBAAsB,CACvB,QAAQ,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,aAAa,EACtD,WAAW,EAAE,+BAA+B,CAAC;YACjD,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC;YAC3D,OAAO,CAAC;UACV,CAAC,CAAC,CAAC;SACJ,MAAM;UACL,SAAS,CAAC,QAAQ,CAAC,GAAG,OAAmB;UACzC,IAAI,CAAC,sBAAsB,CACvB,QAAQ,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,aAAa,EACtD,WAAW,EAAE,+BAA+B,CAAC;UACjD,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC;QAC5D;OACF,MAAM;QACL,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC;MAC5D;IACF;IACD,OAAO,QAAQ;EACjB;EAEQ,iBAAiB,CACrB,IAAU,EAAE,KAAyB,EAAE,OAAyB,EAChE,SAA0B,EAAE,KAA+B,EAC3D,SAAsB,EAAA;IACxB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAE,SAAS,IAAI;MAClC,MAAM,CAAC,QAAQ,CAAG,GAAG,mBAAmB,CAAC,SAAS,CAAC,IAAI,EAAE,OAAO,CAAC;MACjE,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE;QACrD;MACD;MACD;MACA,IAAI,SAAS,CAAC,EAAE,KAAK,OAAO,EAAE;QAC5B,IAAI,SAAS,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,IAAG;UAC/B,OAAO,CAAC,CAAC,SAAS,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC;QAC9C,CAAC,CAAC,EAAE;UACN,KAAK,CAAC,QAAQ,CAAC,GAAG,IAAI;UACtB,KAAK,CAAC,IAAI,CAAC;YAAC,QAAQ,EAAE,OAAO,CAAC,cAAc;YAAE,IAAI,EAAE;UAAS,CAAC,CAAC;QAChE;OACF;QAAO;QACJ,IAAI,SAAS,CAAC,UAAU,CAAC,KAAK,CAAC,IAAI,IAAG;UAChC,OAAO,CAAC,CAAC,SAAS,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC;QAC9C,CAAC,CAAC,EAAE;UACV,KAAK,CAAC,QAAQ,CAAC,GAAG,IAAI;UACtB,KAAK,CAAC,IAAI,CAAC;YAAC,QAAQ,EAAE,OAAO,CAAC,cAAc;YAAE,IAAI,EAAE;UAAS,CAAC,CAAC;QAChE;IACH,CAAC,CAAC;EACJ;EAEA;;AAEG;EACH,OAAO,GAAA;IACL,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CACtB,OAAO,CACJ,GAAG,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,OAAO,CAAC,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;EACzE;EAEQ,sBAAsB,CAAC,MAAsB,EAAA;IACnD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,IAAI,IAAG;MACjC,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC;MAC1B,MAAM,CAAC,QAAQ,CAAG,GAAG,aAAa,CAAC,IAAI,CAAC;MACxC,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,QAAQ,CAAC;MACvC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE;QAC9D,MAAM,KAAK,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB;QACxD,MAAM,KAAK,GAAG,KAAK,CAAC,MAAM,KAAK,KAAK,CAAC,KAAK,CAAC,MAAM,IAC7C,KAAK,CAAC,KAAK,CAAC,KAAK,CACb,CAAC,GAAG,EAAE,KAAK,KAAK,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC;QACpE,IAAI,CAAC,MAAM,CACP,KAAK,EACL,MAAM,sBAAsB,IAAI,CAAC,IAAI,iBAAiB,GAClD,gCAAgC,KAAK,aAAa,GAClD,IAAI,KAAK,CAAC,KAAK,GAAG,CAAC;MAC5B;MACD,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE;QAC9D,IAAI,CAAC,MAAM,CACP,KAAK,CAAC,KAAK,KAAK,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAe,EACxD,MAAM,sBAAsB,IAAI,CAAC,IAAI,iBAAiB,GAClD,8BAA8B,GAC9B,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,aAAa,KAAK,CAAC,KAAK,EAAE,CAAC;MACrE;IACH,CAAC,CAAC;EACJ;EAEQ,SAAS,CAAC,MAAsB,EAAA;IACtC,MAAM,MAAM,GAAmB,CAAA,CAAE;IACjC,KAAK,MAAM,SAAS,IAAI,MAAM,EAAE;MAC9B,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,CAAC,MAAM,IAAI,IAAI,IACzD,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,IAAI,EAAE;QAC7C,MAAM,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,SAAS,CAAC;QAChD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC;OACxC,MAAM;QACL,MAAM,CAAC,SAAS,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC;MACtC;IACF;IACD,OAAO,MAAM;EACf;EAEQ,WAAW,CAAC,MAAsB,EAAA;IACxC,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,IAAI,IAAG;MACnD,MAAM,CAAC,QAAQ,CAAC,GAAG,aAAa,CAAC,IAAI,CAAC;MACtC,OAAO,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,QAAQ,CAAC,IAAI,IAAI;IAC3C,CAAC,CAAC;IACF,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;MACzB,MAAM,IAAI,KAAK,CACX,+CAA+C,GAC/C,UAAU,UAAU,8BAA8B,CAAC;IACxD;EACH;EAEQ,UAAU,CAAC,OAAiB,EAAA;IAClC,OAAO,OAAO,CAAC,GAAG,CAAC,IAAI,IAAG;MACxB,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,IAAI,IAAI,IAC1D,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;QACzC,MAAM,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC;QAC5C,OAAO,MAAM,CAAC,IAAI;MACnB;MACD,OAAO,IAAI;IACb,CAAC,EAAE,CAAA,CAAE,CAAC;EACR;EAEQ,YAAY,CAAC,OAAiB,EAAA;IACpC,OAAO,CAAC,OAAO,CAAC,IAAI,IAAG;MACrB,MAAM,CAAC,cAAc,CAAC,GAAG,aAAa,CAAC,IAAI,CAAC;MAC5C,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,cAAc,CAAC,EAAE;QACrC,MAAM,IAAI,KAAK,CAAC,eAAe,IAAI,6BAA6B,CAAC;MAClE;IACH,CAAC,CAAC;EACJ;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n    /**\n     *\n     * @param graph Graph the model or function graph to be executed.\n     * @param parent When building function exector you need to set the parent\n     * executor. Since the weights and function executor maps are set at parant\n     * level, that function executor can access the function maps and weight maps\n     * through the parent.\n     */\n    constructor(graph, parent) {\n        this.graph = graph;\n        this.parent = parent;\n        this.compiledMap = new Map();\n        this._weightMap = {};\n        this.SEPERATOR = ',';\n        this._functions = {};\n        this._functionExecutorMap = {};\n        this._outputs = graph.outputs;\n        this._inputs = graph.inputs;\n        this._initNodes = graph.initNodes;\n        this._signature = graph.signature;\n        this._functions = graph.functions;\n        // create sub-graph executors\n        if (graph.functions != null) {\n            Object.keys(graph.functions).forEach(name => {\n                this._functionExecutorMap[name] =\n                    new GraphExecutor(graph.functions[name], this);\n            });\n        }\n    }\n    get weightIds() {\n        return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n    get functionExecutorMap() {\n        return this.parent ? this.parent.functionExecutorMap :\n            this._functionExecutorMap;\n    }\n    get weightMap() {\n        return this.parent ? this.parent.weightMap : this._weightMap;\n    }\n    set weightMap(weightMap) {\n        const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n        this._weightIds = [].concat(...weightIds);\n        this._weightMap = weightMap;\n    }\n    /**\n     * Set `ResourceManager` shared by executors of a model.\n     * @param resourceManager: `ResourceManager` of the `GraphModel`.\n     */\n    set resourceManager(resourceManager) {\n        this._resourceManager = resourceManager;\n    }\n    get inputs() {\n        return this._inputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get outputs() {\n        return this._outputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get inputNodes() {\n        return this._inputs.map(node => node.signatureKey || node.name);\n    }\n    get outputNodes() {\n        return this._outputs.map((node) => {\n            const name = node.signatureKey || node.name;\n            return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n        });\n    }\n    get functions() {\n        return Object.keys(this._functions).reduce((map, key) => {\n            map[key] = this._functions[key].signature;\n            return map;\n        }, {});\n    }\n    getCompilationKey(inputs, outputs) {\n        const sortedInputs = inputs.map(node => node.name).sort();\n        const sortedOutputs = outputs.map(node => node.name).sort();\n        return sortedInputs.join(this.SEPERATOR) + '--' +\n            sortedOutputs.join(this.SEPERATOR);\n    }\n    /**\n     * Compiles the inference graph and returns the minimal set of nodes that are\n     * required for execution, in the correct execution order.\n     */\n    compile(inputs, outputs) {\n        const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n        const { missingInputs, dynamicNode, syncInputs } = executionInfo;\n        if (dynamicNode != null) {\n            throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` +\n                `the dynamic op '${dynamicNode.op}'. Please use ` +\n                `model.executeAsync() instead. Alternatively, to avoid the ` +\n                `dynamic ops, specify the inputs [${syncInputs}]`);\n        }\n        if (missingInputs.length > 0) {\n            const outNames = outputs.map(n => n.name);\n            const inNames = Object.keys(inputs);\n            throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` +\n                `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n        }\n        return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n    /**\n     * Executes the inference for given input tensors.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model, if\n     * no outputs are specified, the default outputs of the model would be used.\n     * You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     */\n    execute(inputs, outputs) {\n        inputs = this.mapInputs(inputs);\n        const names = Object.keys(inputs).sort();\n        this.checkInputs(inputs);\n        this.checkInputShapeAndType(inputs);\n        outputs = this.mapOutputs(outputs);\n        this.checkOutputs(outputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n        // Do nothing if the compiled graph cache contains the input.\n        let orderedNodes = this.compiledMap.get(compilationKey);\n        if (orderedNodes == null) {\n            orderedNodes = this.compile(inputs, outputNodes);\n            this.compiledMap.set(compilationKey, orderedNodes);\n        }\n        const tensorArrayMap = {};\n        const tensorListMap = {};\n        return tidy(() => {\n            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n            const tensorsMap = Object.assign({}, this.weightMap);\n            Object.keys(inputs).forEach(name => {\n                const [nodeName, index] = parseNodeName(name);\n                const tensors = [];\n                tensors[index] = inputs[name];\n                tensorsMap[nodeName] = tensors;\n            });\n            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n            const intermediateTensorConsumerCount = {};\n            for (let i = 0; i < orderedNodes.length; i++) {\n                const node = orderedNodes[i];\n                if (!tensorsMap[node.name]) {\n                    const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n                    if (util.isPromise(tensors)) {\n                        throw new Error(`The execution of the op '${node.op}' returned a promise. ` +\n                            `Please use model.executeAsync() instead.`);\n                    }\n                    tensorsMap[node.name] = tensors;\n                    this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n                }\n            }\n            // dispose the context for the root executor\n            if (this.parent == null) {\n                context.dispose(tensorsToKeep);\n            }\n            return outputs.map(name => getTensor(name, tensorsMap, context));\n        });\n    }\n    getFrozenTensorIds(tensorMap) {\n        const ids = [].concat.apply([], Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n        return new Set(ids);\n    }\n    checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n        // Skip output nodes and any control flow nodes, since its dependency is\n        // tricky to track correctly.\n        if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n            return;\n        }\n        tensorMap[nodeName].forEach(tensor => {\n            if (tensor != null) {\n                intermediateTensorConsumerCount[tensor.id] =\n                    (intermediateTensorConsumerCount[tensor.id] || 0) +\n                        node.children.length;\n            }\n        });\n        node.inputs.forEach(input => {\n            // Skip any control flow nodes, since its dependency is tricky to track\n            // correctly.\n            if (input.category !== 'control') {\n                const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n                if (tensors != null) {\n                    tensors.forEach(tensor => {\n                        if (tensor && !tensorsToKeep.has(tensor.id)) {\n                            const count = intermediateTensorConsumerCount[tensor.id];\n                            if (count === 1) {\n                                tensor.dispose();\n                                delete intermediateTensorConsumerCount[tensor.id];\n                            }\n                            else if (count != null) {\n                                // only intermediate nodes has count set, inputs and weights are\n                                // not.\n                                intermediateTensorConsumerCount[tensor.id]--;\n                            }\n                        }\n                    });\n                }\n            }\n        });\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs output node name from the Tensorflow model, if no outputs\n     * are specified, the default outputs of the model would be used. You can\n     * inspect intermediate nodes of the model by adding them to the outputs\n     * array.\n     */\n    async executeAsync(inputs, outputs) {\n        return this._executeAsync(inputs, outputs);\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Optional. Flag for executing a function.\n     * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n     * function execution.\n     * @param tensorArrayMap Optinal global TensorList map by id. Used for\n     * function execution.\n     */\n    async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n        if (!isFunctionExecution) {\n            inputs = this.mapInputs(inputs);\n            this.checkInputs(inputs);\n            this.checkInputShapeAndType(inputs);\n            outputs = this.mapOutputs(outputs);\n            this.checkOutputs(outputs);\n        }\n        const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n        // Graph with control flow op requires runtime evaluation of the execution\n        // order, while without control flow the execution order is pre-determined\n        // in the compile method.\n        const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n        const results = outputs.map(name => getTensor(name, tensorMap, context));\n        // dispose all the intermediate tensors\n        const outputIds = results.map(t => t.id);\n        const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n        const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);\n        Object.keys(tensorMap).forEach(key => {\n            const tensorArray = tensorMap[key];\n            tensorArray.forEach(tensor => {\n                if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n                    tensor.dispose();\n                }\n            });\n        });\n        // dispose the context for the root executor\n        if (this.parent == null) {\n            context.dispose(keepIds);\n        }\n        return results;\n    }\n    async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n        const mappedInputs = inputs.reduce((map, tensor, index) => {\n            map[this.inputs[index].name] = tensor;\n            return map;\n        }, {});\n        return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n    }\n    /**\n     * When there are control flow nodes in the graph, the graph execution use\n     * ExecutionContext to keep track of the frames and loop iterators.\n     * @param inputs placeholder tensors for the graph.\n     * @param context the execution context object for current execution.\n     * @param outputNames Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Flag for executing a function.\n     */\n    async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n        const names = Object.keys(inputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n        // First nodes to execute include inputNodes, weights, and initNodes.\n        const stack = [\n            ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n        ].map(node => {\n            return { node, contexts: context.currentContext };\n        });\n        const tensorsMap = Object.assign({}, this.weightMap);\n        Object.keys(inputs).forEach(name => {\n            const [nodeName, index] = parseNodeName(name);\n            const tensors = [];\n            tensors[index] = inputs[name];\n            tensorsMap[nodeName] = tensors;\n        });\n        const intermediateTensorConsumerCount = {};\n        const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n        const added = {};\n        while (stack.length > 0) {\n            const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n            await Promise.all(promises);\n        }\n        if (dynamicNode == null && !isFunctionExecution) {\n            console.warn(`This model execution did not contain any nodes with control flow ` +\n                `or dynamic output shapes. You can use model.execute() instead.`);\n        }\n        const missingOutputs = outputNodes\n            .filter(node => !isControlFlow(node) &&\n            !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n        if (missingOutputs.length > 0) {\n            let alternativeMsg = '';\n            if (dynamicNode != null) {\n                alternativeMsg =\n                    `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n                        `and specify the inputs [${syncInputs}]`;\n            }\n            throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` +\n                `inputs [${names}]. Consider providing the following inputs: ` +\n                `[${missingInputs}]. ${alternativeMsg}`);\n        }\n        return tensorsMap;\n    }\n    processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n        const promises = [];\n        while (stack.length > 0) {\n            const item = stack.pop();\n            context.currentContext = item.contexts;\n            let nodeName = '';\n            // The tensor of the Enter op with isConstant set should be set\n            // in the parent scope, so it will be available as constant for the\n            // whole loop.\n            if (item.node.op === 'Enter' &&\n                getParamValue('isConstant', item.node, tensorMap, context)) {\n                [nodeName] = getNodeNameAndIndex(item.node.name, context);\n            }\n            // only process nodes that are not in the tensorMap yet, this include\n            // inputNodes and internal initNodes.\n            if (tensorMap[item.node.name] == null) {\n                const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n                if (!nodeName) {\n                    [nodeName] = getNodeNameAndIndex(item.node.name, context);\n                }\n                const currentContext = context.currentContext;\n                if (util.isPromise(tensors)) {\n                    promises.push(tensors.then(t => {\n                        tensorMap[nodeName] = t;\n                        context.currentContext = currentContext;\n                        this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                        return t;\n                    }));\n                }\n                else {\n                    tensorMap[nodeName] = tensors;\n                    this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                    this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                }\n            }\n            else {\n                this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            }\n        }\n        return promises;\n    }\n    processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n        node.children.forEach((childNode) => {\n            const [nodeName,] = getNodeNameAndIndex(childNode.name, context);\n            if (added[nodeName] || !usedNodes.has(childNode.name)) {\n                return;\n            }\n            // Merge op can be pushed if any of its inputs has value.\n            if (childNode.op === 'Merge') {\n                if (childNode.inputNames.some(name => {\n                    return !!getTensor(name, tensorMap, context);\n                })) {\n                    added[nodeName] = true;\n                    stack.push({ contexts: context.currentContext, node: childNode });\n                }\n            }\n            else // Otherwise all inputs must to have value.\n             if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n            })) {\n                added[nodeName] = true;\n                stack.push({ contexts: context.currentContext, node: childNode });\n            }\n        });\n    }\n    /**\n     * Releases the memory used by the weight tensors.\n     */\n    dispose() {\n        Object.keys(this.weightMap)\n            .forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n    }\n    checkInputShapeAndType(inputs) {\n        Object.keys(inputs).forEach(name => {\n            const input = inputs[name];\n            const [nodeName,] = parseNodeName(name);\n            const node = this.graph.nodes[nodeName];\n            if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n                const shape = node.attrParams['shape'].value;\n                const match = shape.length === input.shape.length &&\n                    input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n                util.assert(match, () => `The shape of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be [${shape}], but was ` +\n                    `[${input.shape}]`);\n            }\n            if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n                util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be ` +\n                    `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n            }\n        });\n    }\n    mapInputs(inputs) {\n        const result = {};\n        for (const inputName in inputs) {\n            if (this._signature != null && this._signature.inputs != null &&\n                this._signature.inputs[inputName] != null) {\n                const tensor = this._signature.inputs[inputName];\n                result[tensor.name] = inputs[inputName];\n            }\n            else {\n                result[inputName] = inputs[inputName];\n            }\n        }\n        return result;\n    }\n    checkInputs(inputs) {\n        const notInGraph = Object.keys(inputs).filter(name => {\n            const [nodeName] = parseNodeName(name);\n            return this.graph.nodes[nodeName] == null;\n        });\n        if (notInGraph.length > 0) {\n            throw new Error(`The dict provided in model.execute(dict) has ` +\n                `keys: [${notInGraph}] that are not part of graph`);\n        }\n    }\n    mapOutputs(outputs) {\n        return outputs.map(name => {\n            if (this._signature != null && this._signature.outputs != null &&\n                this._signature.outputs[name] != null) {\n                const tensor = this._signature.outputs[name];\n                return tensor.name;\n            }\n            return name;\n        }, {});\n    }\n    checkOutputs(outputs) {\n        outputs.forEach(name => {\n            const [normalizedName] = parseNodeName(name);\n            if (!this.graph.nodes[normalizedName]) {\n                throw new Error(`The output '${name}' is not found in the graph`);\n            }\n        });\n    }\n}\n//# sourceMappingURL=graph_executor.js.map"]},"metadata":{},"sourceType":"module"}