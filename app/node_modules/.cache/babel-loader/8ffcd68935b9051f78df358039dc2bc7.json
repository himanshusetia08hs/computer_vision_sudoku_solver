{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'addStrict');\n  const $b = convertToTensor(b, 'b', 'addStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n  return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'subStrict');\n  const $b = convertToTensor(b, 'b', 'subStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n  return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n  return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'mul');\n  const $b = convertToTensor(b, 'b', 'mul');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n  return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'div');\n  const $b = convertToTensor(b, 'b', 'div');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n  return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'modStrict');\n  const $b = convertToTensor(b, 'b', 'modStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n  return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'minimumStrict');\n  const $b = convertToTensor(b, 'b', 'minimumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n  return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'maximumStrict');\n  const $b = convertToTensor(b, 'b', 'maximumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n  return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n  const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n  return squaredDifference($a, $b);\n}\nexport const addStrict = op({\n  addStrict_\n});\nexport const divStrict = op({\n  divStrict_\n});\nexport const maximumStrict = op({\n  maximumStrict_\n});\nexport const minimumStrict = op({\n  minimumStrict_\n});\nexport const modStrict = op({\n  modStrict_\n});\nexport const mulStrict = op({\n  mulStrict_\n});\nexport const powStrict = op({\n  powStrict_\n});\nexport const squaredDifferenceStrict = op({\n  squaredDifferenceStrict_\n});\nexport const subStrict = op({\n  subStrict_\n});","map":{"version":3,"sources":["../../src/ops/binary_ops.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,eAAe,QAAO,YAAY;AAE1C,SAAQ,eAAe,QAAO,oBAAoB;AAElD,OAAO,KAAK,IAAI,MAAM,SAAS;AAE/B,SAAQ,GAAG,QAAO,OAAO;AACzB,SAAQ,GAAG,QAAO,OAAO;AACzB,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,GAAG,QAAO,OAAO;AACzB,SAAQ,GAAG,QAAO,OAAO;AACzB,SAAQ,EAAE,QAAO,aAAa;AAC9B,SAAQ,GAAG,QAAO,OAAO;AACzB,SAAQ,iBAAiB,QAAO,sBAAsB;AACtD,SAAQ,GAAG,QAAO,OAAO;AAEzB;;;;;;;;AAQG;AACH,SAAS,UAAU,CAAmB,CAAe,EAAE,CAAe,EAAA;EACpE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EACpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,sBAAsB,CAAC;EAClE,OAAO,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC;AACpB;AAEA;;;;;;;;;AASG;AACH,SAAS,UAAU,CAAmB,CAAe,EAAE,CAAe,EAAA;EACpE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,sBAAsB,CAAC;EAClE,OAAO,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC;AACpB;AAEA;;;;;;;;;AASG;AACH,SAAS,UAAU,CAAmB,IAAO,EAAE,GAAW,EAAA;EACxD,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,EAAE,GAAG,CAAC,KAAK,EAAE,sBAAsB,CAAC;EACrE,OAAO,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC;AACvB;AAEA;;;;;;;;;AASG;AACH,SAAS,UAAU,CAAmB,CAAe,EAAE,CAAe,EAAA;EACpE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,KAAK,CAAC;EACzC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,KAAK,CAAC;EACzC,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,2BAA2B,CAAC;EACvE,OAAO,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC;AACpB;AAEA;;;;;;;AAOG;AACH,SAAS,UAAU,CAAmB,CAAe,EAAE,CAAe,EAAA;EACpE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,KAAK,CAAC;EACzC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,KAAK,CAAC;EACzC,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,yBAAyB,CAAC;EACrE,OAAO,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC;AACpB;AAEA;;;;;;;AAOG;AACH,SAAS,UAAU,CAAmB,CAAe,EAAE,CAAe,EAAA;EACpE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,WAAW,CAAC;EAC/C,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,sBAAsB,CAAC;EAClE,OAAO,GAAG,CAAC,EAAE,EAAE,EAAE,CAAC;AACpB;AAEA;;;;;;;AAOG;AACH,SAAS,cAAc,CAAmB,CAAe,EAAE,CAAe,EAAA;EACxE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,eAAe,CAAC;EACnD,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,eAAe,CAAC;EACnD,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,0BAA0B,CAAC;EACtE,OAAO,OAAO,CAAC,EAAE,EAAE,EAAE,CAAC;AACxB;AAEA;;;;;;;AAOG;AACH,SAAS,cAAc,CAAmB,CAAe,EAAE,CAAe,EAAA;EACxE,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EAEpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,eAAe,CAAC;EACnD,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,eAAe,CAAC;EACnD,IAAI,CAAC,iBAAiB,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,0BAA0B,CAAC;EACtE,OAAO,OAAO,CAAC,EAAE,EAAE,EAAE,CAAC;AACxB;AAEA;;;;;;;;;AASG;AACH,SAAS,wBAAwB,CAC7B,CAAe,EAAE,CAAe,EAAA;EAClC,eAAe,CACX,8CAA8C,GAC9C,+BAA+B,CAAC;EACpC,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,yBAAyB,CAAC;EAC7D,MAAM,EAAE,GAAG,eAAe,CAAC,CAAC,EAAE,GAAG,EAAE,yBAAyB,CAAC;EAC7D,IAAI,CAAC,iBAAiB,CAClB,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,EAAE,oCAAoC,CAAC;EAC7D,OAAO,iBAAiB,CAAC,EAAE,EAAE,EAAE,CAAC;AAClC;AAEA,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC;AACzC,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC;AACzC,OAAO,MAAM,aAAa,GAAG,EAAE,CAAC;EAAC;AAAc,CAAC,CAAC;AACjD,OAAO,MAAM,aAAa,GAAG,EAAE,CAAC;EAAC;AAAc,CAAC,CAAC;AACjD,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC;AACzC,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC;AACzC,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC;AACzC,OAAO,MAAM,uBAAuB,GAAG,EAAE,CAAC;EAAC;AAAwB,CAAC,CAAC;AACrE,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;EAAC;AAAU,CAAC,CAAC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'addStrict');\n    const $b = convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'subStrict');\n    const $b = convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'mul');\n    const $b = convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'div');\n    const $b = convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'modStrict');\n    const $b = convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'minimumStrict');\n    const $b = convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'maximumStrict');\n    const $b = convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return squaredDifference($a, $b);\n}\nexport const addStrict = op({ addStrict_ });\nexport const divStrict = op({ divStrict_ });\nexport const maximumStrict = op({ maximumStrict_ });\nexport const minimumStrict = op({ minimumStrict_ });\nexport const modStrict = op({ modStrict_ });\nexport const mulStrict = op({ mulStrict_ });\nexport const powStrict = op({ powStrict_ });\nexport const squaredDifferenceStrict = op({ squaredDifferenceStrict_ });\nexport const subStrict = op({ subStrict_ });\n//# sourceMappingURL=binary_ops.js.map"]},"metadata":{},"sourceType":"module"}