{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, buffer, DataStorage, engine, env, kernel_impls, KernelBackend, util } from '@tensorflow/tfjs-core';\nconst whereImpl = kernel_impls.whereImpl;\nimport { assertNotComplex } from './cpu_util';\nexport class MathBackendCPU extends KernelBackend {\n  constructor() {\n    super();\n    this.blockSize = 48;\n    this.firstUse = true;\n    this.data = new DataStorage(this, engine());\n  }\n  write(values, shape, dtype) {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn('\\n============================\\n' + 'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' + 'Node.js. To speed things up dramatically, install our node ' + 'backend, which binds to TensorFlow C++, by running ' + 'npm i @tensorflow/tfjs-node, ' + 'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' + 'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' + 'suffix for CUDA) at the start of your program. ' + 'Visit https://github.com/tensorflow/tfjs-node for more details.' + '\\n============================');\n      }\n    }\n    const dataId = {};\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n    return dataId;\n  }\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(shape, dtype, values) {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 && util.isString(values[0])) {\n      const encodedValues = values.map(d => util.encodeString(d));\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values, shape, dtype);\n    }\n    return {\n      dataId: outId,\n      shape,\n      dtype\n    };\n  }\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId) {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId) {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n  move(dataId, values, shape, dtype) {\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n  }\n  numDataIds() {\n    return this.data.numDataIds();\n  }\n  async read(dataId) {\n    return this.readSync(dataId);\n  }\n  readSync(dataId) {\n    const {\n      dtype,\n      complexTensorInfos\n    } = this.data.get(dataId);\n    if (dtype === 'complex64') {\n      const realValues = this.readSync(complexTensorInfos.real.dataId);\n      const imagValues = this.readSync(complexTensorInfos.imag.dataId);\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return this.data.get(dataId).values;\n  }\n  bufferSync(t) {\n    const data = this.readSync(t.dataId);\n    let decodedData = data;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = data.map(d => util.decodeString(d));\n      } catch (_a) {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape, t.dtype, decodedData);\n  }\n  makeOutput(values, shape, dtype) {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n  }\n  disposeData(dataId) {\n    if (this.data.has(dataId)) {\n      const {\n        complexTensorInfos\n      } = this.data.get(dataId);\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n      this.data.delete(dataId);\n    }\n  }\n  disposeIntermediateTensorInfo(tensorInfo) {\n    const dataId = tensorInfo.dataId;\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n  async time(f) {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {\n      kernelMs\n    };\n  }\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons: ['The reported memory is an upper bound. Due to automatic garbage ' + 'collection, the true allocated memory may be less.']\n    };\n  }\n  where(condition) {\n    assertNotComplex([condition], 'where');\n    const condVals = this.readSync(condition.dataId);\n    return whereImpl(condition.shape, condVals);\n  }\n  dispose() {}\n  floatPrecision() {\n    return 32;\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return super.epsilon();\n  }\n}","map":{"version":3,"sources":["../src/backend_cpu.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAqB,MAAM,EAAE,WAAW,EAAwB,MAAM,EAAE,GAAG,EAAE,YAAY,EAAE,aAAa,EAA0E,IAAI,QAAO,uBAAuB;AAExO,MAAM,SAAS,GAAG,YAAY,CAAC,SAAS;AACxC,SAAQ,gBAAgB,QAAO,YAAY;AAgB3C,OAAM,MAAO,cAAe,SAAQ,aAAa,CAAA;EAM/C,WAAA,GAAA;IACE,KAAK,EAAE;IANF,IAAA,CAAA,SAAS,GAAG,EAAE;IAGb,IAAA,CAAA,QAAQ,GAAG,IAAI;IAIrB,IAAI,CAAC,IAAI,GAAG,IAAI,WAAW,CAAC,IAAI,EAAE,MAAM,EAAE,CAAC;EAC7C;EAEA,KAAK,CAAC,MAAkC,EAAE,KAAe,EAAE,KAAe,EAAA;IAExE,IAAI,IAAI,CAAC,QAAQ,EAAE;MACjB,IAAI,CAAC,QAAQ,GAAG,KAAK;MACrB,IAAI,GAAG,EAAE,CAAC,GAAG,CAAC,SAAS,CAAC,EAAE;QACxB,YAAY,CAAC,IAAI,CACb,kCAAkC,GAClC,2DAA2D,GAC3D,6DAA6D,GAC7D,qDAAqD,GACrD,+BAA+B,GAC/B,uDAAuD,GACvD,sDAAsD,GACtD,iDAAiD,GACjD,iEAAiE,GACjE,gCAAgC,CAAC;MACtC;IACF;IACD,MAAM,MAAM,GAAG,CAAA,CAAE;IAEjB,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE;MAAC,MAAM;MAAE,KAAK;MAAE,QAAQ,EAAE;IAAC,CAAC,CAAC;IAEnD,OAAO,MAAM;EACf;EAEA;;;;;AAKG;EACH,cAAc,CACV,KAAe,EAAE,KAAe,EAChC,MAA4C,EAAA;IAC9C,IAAI,KAAK;IACT,IAAI,KAAK,KAAK,QAAQ,IAAI,MAAM,IAAI,IAAI,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,IACzD,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE;MAC5B,MAAM,aAAa,GACd,MAAyB,CAAC,GAAG,CAAC,CAAC,IAAI,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;MAE7D,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,EAAE,KAAK,EAAE,KAAK,CAAC;KAChD,MAAM;MACL,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,MAAoB,EAAE,KAAK,EAAE,KAAK,CAAC;IACvD;IAED,OAAO;MAAC,MAAM,EAAE,KAAK;MAAE,KAAK;MAAE;IAAK,CAAC;EACtC;EAEA;EACA,MAAM,CAAC,MAAc,EAAA;IACnB,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;IACxC,UAAU,CAAC,QAAQ,EAAE;EACvB;EAEA;EACA,MAAM,CAAC,MAAc,EAAA;IACnB,IAAI,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;MACzB,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;MACxC,UAAU,CAAC,QAAQ,EAAE;IACtB;EACH;EAEA,IAAI,CACA,MAAc,EAAE,MAAkC,EAAE,KAAe,EACnE,KAAe,EAAA;IACjB,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE;MAAC,MAAM;MAAE,KAAK;MAAE,QAAQ,EAAE;IAAC,CAAC,CAAC;EACrD;EAEA,UAAU,GAAA;IACR,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE;EAC/B;EAEA,MAAM,IAAI,CAAC,MAAc,EAAA;IACvB,OAAO,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;EAC9B;EACA,QAAQ,CAAC,MAAc,EAAA;IACrB,MAAM;MAAC,KAAK;MAAE;IAAkB,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;IAEzD,IAAI,KAAK,KAAK,WAAW,EAAE;MACzB,MAAM,UAAU,GACZ,IAAI,CAAC,QAAQ,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAiB;MACjE,MAAM,UAAU,GACZ,IAAI,CAAC,QAAQ,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAiB;MACjE,OAAO,YAAY,CAAC,sBAAsB,CAAC,UAAU,EAAE,UAAU,CAAC;IACnE;IAED,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,MAAM;EACrC;EAEA,UAAU,CAAiB,CAAa,EAAA;IACtC,MAAM,IAAI,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC;IACpC,IAAI,WAAW,GAAG,IAAkB;IACpC,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;MACxB,IAAI;QACF;QACA,WAAW,GAAI,IAAqB,CAAC,GAAG,CAAC,CAAC,IAAI,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;OACpE,CAAC,OAAA,EAAA,EAAM;QACN,MAAM,IAAI,KAAK,CAAC,kDAAkD,CAAC;MACpE;IACF;IACD,OAAO,MAAM,CAAC,CAAC,CAAC,KAAoB,EAAE,CAAC,CAAC,KAAK,EAAE,WAAW,CACvC;EACrB;EAEA,UAAU,CACN,MAAkC,EAAE,KAAe,EAAE,KAAe,EAAA;IACtE,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC;IAC/C,OAAO,MAAM,EAAE,CAAC,oBAAoB,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,CAAM;EACvE;EAEA,WAAW,CAAC,MAAc,EAAA;IACxB,IAAI,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;MACzB,MAAM;QAAC;MAAkB,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;MAElD,IAAI,kBAAkB,IAAI,IAAI,EAAE;QAC9B,IAAI,CAAC,WAAW,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAC;QAChD,IAAI,CAAC,WAAW,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAC;MACjD;MAED,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;IACzB;EACH;EAEA,6BAA6B,CAAC,UAAsB,EAAA;IAClD,MAAM,MAAM,GAAG,UAAU,CAAC,MAAM;IAEhC,IAAI,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE;MACzB,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC;MAExC,UAAU,CAAC,QAAQ,EAAE;MAErB,IAAI,UAAU,CAAC,QAAQ,GAAG,CAAC,EAAE;QAC3B,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;MACzB;IACF;EACH;EAEA,MAAM,IAAI,CAAC,CAAa,EAAA;IACtB,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,EAAE;IACxB,CAAC,EAAE;IACH,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,EAAE,GAAG,KAAK;IACnC,OAAO;MAAC;IAAQ,CAAC;EACnB;EAEA,MAAM,GAAA;IACJ,OAAO;MACL;MACA,UAAU,EAAE,IAAI;MAChB,OAAO,EACH,CAAC,kEAAkE,GAClE,oDAAoD;KAC1D;EACH;EAEA,KAAK,CAAC,SAAiB,EAAA;IACrB,gBAAgB,CAAC,CAAC,SAAS,CAAC,EAAE,OAAO,CAAC;IAEtC,MAAM,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,MAAM,CAAe;IAC9D,OAAO,SAAS,CAAC,SAAS,CAAC,KAAK,EAAE,QAAQ,CAAC;EAC7C;EAEA,OAAO,GAAA,CAAI;EAEX,cAAc,GAAA;IACZ,OAAO,EAAE;EACX;EAEA;EACA,OAAO,GAAA;IACL,OAAO,KAAK,CAAC,OAAO,EAAE;EACxB;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, buffer, DataStorage, engine, env, kernel_impls, KernelBackend, util } from '@tensorflow/tfjs-core';\nconst whereImpl = kernel_impls.whereImpl;\nimport { assertNotComplex } from './cpu_util';\nexport class MathBackendCPU extends KernelBackend {\n    constructor() {\n        super();\n        this.blockSize = 48;\n        this.firstUse = true;\n        this.data = new DataStorage(this, engine());\n    }\n    write(values, shape, dtype) {\n        if (this.firstUse) {\n            this.firstUse = false;\n            if (env().get('IS_NODE')) {\n                backend_util.warn('\\n============================\\n' +\n                    'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n                    'Node.js. To speed things up dramatically, install our node ' +\n                    'backend, which binds to TensorFlow C++, by running ' +\n                    'npm i @tensorflow/tfjs-node, ' +\n                    'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n                    'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n                    'suffix for CUDA) at the start of your program. ' +\n                    'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n                    '\\n============================');\n            }\n        }\n        const dataId = {};\n        this.data.set(dataId, { values, dtype, refCount: 1 });\n        return dataId;\n    }\n    /**\n     * Create a data bucket in cpu backend.\n     * @param shape Shape of the `TensorInfo`.\n     * @param dtype DType of the `TensorInfo`.\n     * @param values The value of the `TensorInfo` stored as a flattened array.\n     */\n    makeTensorInfo(shape, dtype, values) {\n        let outId;\n        if (dtype === 'string' && values != null && values.length > 0 &&\n            util.isString(values[0])) {\n            const encodedValues = values.map(d => util.encodeString(d));\n            outId = this.write(encodedValues, shape, dtype);\n        }\n        else {\n            outId = this.write(values, shape, dtype);\n        }\n        return { dataId: outId, shape, dtype };\n    }\n    /** Increase refCount of a `TensorData`. */\n    incRef(dataId) {\n        const tensorData = this.data.get(dataId);\n        tensorData.refCount++;\n    }\n    /** Decrease refCount of a `TensorData`. */\n    decRef(dataId) {\n        if (this.data.has(dataId)) {\n            const tensorData = this.data.get(dataId);\n            tensorData.refCount--;\n        }\n    }\n    move(dataId, values, shape, dtype) {\n        this.data.set(dataId, { values, dtype, refCount: 1 });\n    }\n    numDataIds() {\n        return this.data.numDataIds();\n    }\n    async read(dataId) {\n        return this.readSync(dataId);\n    }\n    readSync(dataId) {\n        const { dtype, complexTensorInfos } = this.data.get(dataId);\n        if (dtype === 'complex64') {\n            const realValues = this.readSync(complexTensorInfos.real.dataId);\n            const imagValues = this.readSync(complexTensorInfos.imag.dataId);\n            return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        return this.data.get(dataId).values;\n    }\n    bufferSync(t) {\n        const data = this.readSync(t.dataId);\n        let decodedData = data;\n        if (t.dtype === 'string') {\n            try {\n                // Decode the bytes into string.\n                decodedData = data.map(d => util.decodeString(d));\n            }\n            catch (_a) {\n                throw new Error('Failed to decode encoded string bytes into utf-8');\n            }\n        }\n        return buffer(t.shape, t.dtype, decodedData);\n    }\n    makeOutput(values, shape, dtype) {\n        const dataId = this.write(values, shape, dtype);\n        return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n    }\n    disposeData(dataId) {\n        if (this.data.has(dataId)) {\n            const { complexTensorInfos } = this.data.get(dataId);\n            if (complexTensorInfos != null) {\n                this.disposeData(complexTensorInfos.real.dataId);\n                this.disposeData(complexTensorInfos.imag.dataId);\n            }\n            this.data.delete(dataId);\n        }\n    }\n    disposeIntermediateTensorInfo(tensorInfo) {\n        const dataId = tensorInfo.dataId;\n        if (this.data.has(dataId)) {\n            const tensorData = this.data.get(dataId);\n            tensorData.refCount--;\n            if (tensorData.refCount < 1) {\n                this.disposeData(dataId);\n            }\n        }\n    }\n    async time(f) {\n        const start = util.now();\n        f();\n        const kernelMs = util.now() - start;\n        return { kernelMs };\n    }\n    memory() {\n        return {\n            // Unreliable due to automatic gc. The numbers above are cumulative.\n            unreliable: true,\n            reasons: ['The reported memory is an upper bound. Due to automatic garbage ' +\n                    'collection, the true allocated memory may be less.']\n        };\n    }\n    where(condition) {\n        assertNotComplex([condition], 'where');\n        const condVals = this.readSync(condition.dataId);\n        return whereImpl(condition.shape, condVals);\n    }\n    dispose() { }\n    floatPrecision() {\n        return 32;\n    }\n    /** Returns the smallest representable number.  */\n    epsilon() {\n        return super.epsilon();\n    }\n}\n//# sourceMappingURL=backend_cpu.js.map"]},"metadata":{},"sourceType":"module"}