{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { complex } from './Complex';\nimport { concatImpl } from './Concat_impl';\nimport { identity } from './Identity';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concat(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    axis\n  } = attrs;\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({\n      inputs: {\n        x: $inputs[0]\n      },\n      backend\n    });\n  }\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map(t => real({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const imags = $inputs.map(t => imag({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const realConcated = concat({\n      inputs: reals,\n      backend,\n      attrs: {\n        axis: $axis\n      }\n    });\n    const imagConcated = concat({\n      inputs: imags,\n      backend,\n      attrs: {\n        axis: $axis\n      }\n    });\n    const result = complex({\n      inputs: {\n        real: realConcated,\n        imag: imagConcated\n      },\n      backend\n    });\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n    return result;\n  }\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({\n      inputs: {\n        x: t\n      },\n      backend,\n      attrs: {\n        shape\n      }\n    });\n  });\n  const inputsValShapes = inputs2D.map(t => {\n    return {\n      vals: backend.data.get(t.dataId).values,\n      shape: t.shape\n    };\n  });\n  // Concats 2d tensors along axis=1.\n  outShape = backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n  const finalOutShape = backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n  const outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return outInfo;\n}\nexport const concatConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat\n};","map":{"version":3,"sources":["../../src/kernels/Concat.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAE,MAAM,EAAmE,IAAI,QAAO,uBAAuB;AAIjI,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,UAAU,QAAO,eAAe;AACxC,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAU,MAAM,CAClB,IAAyE,EAAA;EAE3E,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAI,CAAC,GAAG,KAAK;EAEpB,MAAM,KAAK,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;EAC3D,IAAI,QAAQ,GAAG,YAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC;EAE5E,IAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAE;IACtC,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC;EAC7D;EAED;EACA,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;EACnE,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;IACxB,OAAO,QAAQ,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE,OAAO,CAAC,CAAC;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC;EACpD;EAED,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC;EACxC,YAAY,CAAC,sBAAsB,CAAC,MAAM,EAAE,KAAK,CAAC;EAElD,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;IACpC,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IACrE,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IAErE,MAAM,YAAY,GAAG,MAAM,CAAC;MAAC,MAAM,EAAE,KAAK;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAK;IAAC,CAAC,CAAC;IAC3E,MAAM,YAAY,GAAG,MAAM,CAAC;MAAC,MAAM,EAAE,KAAK;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAK;IAAC,CAAC,CAAC;IAE3E,MAAM,MAAM,GACR,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,IAAI,EAAE,YAAY;QAAE,IAAI,EAAE;MAAY,CAAC;MAAE;IAAO,CAAC,CAAC;IAExE,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IACnD,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IAEnD,OAAO,MAAM;EACd;EAED;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,IAAG;IAC/B,MAAM,SAAS,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;IAC1D,MAAM,KAAK,GAAG,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC;IAC7B,OAAO,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC;MAAK;IAAC,CAAC,CAAC;EAC3D,CAAC,CAAC;EAEF,MAAM,eAAe,GAAG,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAG;IACvC,OAAO;MAAC,IAAI,EAAE,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM;MAAE,KAAK,EAAE,CAAC,CAAC;IAAK,CAAC;EAClE,CAAC,CAAC;EAEF;EACA,QAAQ,GACJ,YAAY,CAAC,eAAe,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,WAAW;EAC1E,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;EAC/C,MAAM,OAAO,GACT,UAAU,CAAC,eAAe,EAAE,QAAQ,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,YAAY,CAAC;EAExE,MAAM,aAAa,GACf,YAAY,CAAC,eAAe,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC;EAElE,MAAM,OAAO,GACT,OAAO,CAAC,cAAc,CAAC,aAAa,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,OAAO,CAAC;EAEnE,QAAQ,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;EAE/D,OAAO,OAAO;AAChB;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { complex } from './Complex';\nimport { concatImpl } from './Concat_impl';\nimport { identity } from './Identity';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concat(args) {\n    const { inputs, backend, attrs } = args;\n    const { axis } = attrs;\n    const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n    let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n    if (util.sizeFromShape(outShape) === 0) {\n        return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n    if ($inputs.length === 1) {\n        return identity({ inputs: { x: $inputs[0] }, backend });\n    }\n    const shapes = $inputs.map(t => t.shape);\n    backend_util.assertParamsConsistent(shapes, $axis);\n    if ($inputs[0].dtype === 'complex64') {\n        const reals = $inputs.map((t) => real({ inputs: { input: t }, backend }));\n        const imags = $inputs.map((t) => imag({ inputs: { input: t }, backend }));\n        const realConcated = concat({ inputs: reals, backend, attrs: { axis: $axis } });\n        const imagConcated = concat({ inputs: imags, backend, attrs: { axis: $axis } });\n        const result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });\n        reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n        imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n        backend.disposeIntermediateTensorInfo(realConcated);\n        backend.disposeIntermediateTensorInfo(imagConcated);\n        return result;\n    }\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const inputs2D = $inputs.map(t => {\n        const innerSize = util.sizeFromShape(t.shape.slice($axis));\n        const shape = [-1, innerSize];\n        return reshape({ inputs: { x: t }, backend, attrs: { shape } });\n    });\n    const inputsValShapes = inputs2D.map(t => {\n        return { vals: backend.data.get(t.dataId).values, shape: t.shape };\n    });\n    // Concats 2d tensors along axis=1.\n    outShape =\n        backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = inputs2D[0].shape[0] === 1;\n    const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n    const finalOutShape = backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n    const outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n    inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return outInfo;\n}\nexport const concatConfig = {\n    kernelName: Concat,\n    backendName: 'cpu',\n    kernelFunc: concat\n};\n//# sourceMappingURL=Concat.js.map"]},"metadata":{},"sourceType":"module"}