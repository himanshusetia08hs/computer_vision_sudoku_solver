{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { RaggedTensorToTensor } from '@tensorflow/tfjs-core';\nimport { raggedTensorToTensorImpl } from './RaggedTensorToTensor_impl';\nexport function raggedTensorToTensor(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    shape,\n    values,\n    defaultValue,\n    rowPartitionTensors\n  } = inputs;\n  const {\n    rowPartitionTypes\n  } = attrs;\n  const $shape = backend.data.get(shape.dataId).values;\n  const $values = backend.data.get(values.dataId).values;\n  const $defaultValue = backend.data.get(defaultValue.dataId).values;\n  const $rowPartitionValues = rowPartitionTensors.map(t => backend.data.get(t.dataId).values);\n  const rowPartitionValuesShapes = rowPartitionTensors.map(t => t.shape);\n  const [outputShape, output] = raggedTensorToTensorImpl($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes);\n  return backend.makeTensorInfo(outputShape, values.dtype, output);\n}\nexport const raggedTensorToTensorConfig = {\n  kernelName: RaggedTensorToTensor,\n  backendName: 'cpu',\n  kernelFunc: raggedTensorToTensor\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAkC,oBAAoB,QAAsF,uBAAuB;AAInK,SAAQ,wBAAwB,QAAO,6BAA6B;AAEpE,OAAM,SAAU,oBAAoB,CAAC,IAIpC,EAAA;EACC,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC,KAAK;IAAE,MAAM;IAAE,YAAY;IAAE;EAAmB,CAAC,GAAG,MAAM;EACjE,MAAM;IAAC;EAAiB,CAAC,GAAG,KAAK;EAEjC,MAAM,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,MAAoB;EAClE,MAAM,OAAO,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,MAAoB;EACpE,MAAM,aAAa,GACf,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,MAAoB;EAC9D,MAAM,mBAAmB,GAAG,mBAAmB,CAAC,GAAG,CAC/C,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB,CAAC;EACzD,MAAM,wBAAwB,GAAG,mBAAmB,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC;EAEtE,MAAM,CAAC,WAAW,EAAE,MAAM,CAAC,GAAG,wBAAwB,CAClD,MAAM,EAAE,KAAK,CAAC,KAAK,EAAE,OAAO,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,aAAa,EACvE,YAAY,CAAC,KAAK,EAAE,mBAAmB,EAAE,wBAAwB,EACjE,iBAAiB,CAAC;EACtB,OAAO,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC;AAClE;AAEA,OAAO,MAAM,0BAA0B,GAAiB;EACtD,UAAU,EAAE,oBAAoB;EAChC,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RaggedTensorToTensor, RaggedTensorToTensorAttrs, RaggedTensorToTensorInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {raggedTensorToTensorImpl} from './RaggedTensorToTensor_impl';\n\nexport function raggedTensorToTensor(args: {\n  inputs: RaggedTensorToTensorInputs,\n  backend: MathBackendCPU,\n  attrs: RaggedTensorToTensorAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {shape, values, defaultValue, rowPartitionTensors} = inputs;\n  const {rowPartitionTypes} = attrs;\n\n  const $shape = backend.data.get(shape.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values as TypedArray;\n  const $rowPartitionValues = rowPartitionTensors.map(\n      t => backend.data.get(t.dataId).values as TypedArray);\n  const rowPartitionValuesShapes = rowPartitionTensors.map(t => t.shape);\n\n  const [outputShape, output] = raggedTensorToTensorImpl(\n      $shape, shape.shape, $values, values.shape, values.dtype, $defaultValue,\n      defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes,\n      rowPartitionTypes);\n  return backend.makeTensorInfo(outputShape, values.dtype, output);\n}\n\nexport const raggedTensorToTensorConfig: KernelConfig = {\n  kernelName: RaggedTensorToTensor,\n  backendName: 'cpu',\n  kernelFunc: raggedTensorToTensor as {} as KernelFunc,\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}