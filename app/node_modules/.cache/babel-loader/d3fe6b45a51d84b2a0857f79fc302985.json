{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, util } from '@tensorflow/tfjs-core';\nimport { ConcatProgram } from '../concat_gpu';\nimport { ConcatPackedProgram } from '../concat_packed_gpu';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concatImpl(inputs, axis, backend) {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map(t => real({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const imags = inputs.map(t => imag({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n    const result = complex({\n      inputs: {\n        real: realConcated,\n        imag: imagConcated\n      },\n      backend\n    });\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n    return result;\n  }\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    const {\n      tensors2D,\n      outShape\n    } = computeTensors2D(inputs, axis, backend);\n    const inputsValShapes = tensors2D.map(t => {\n      return {\n        vals: backend.readSync(t.dataId),\n        shape: t.shape\n      };\n    });\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n    const finalOutShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n    tensors2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return outInfo;\n  }\n  if (inputs.length > env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n    const midIndex = Math.floor(inputs.length / 2);\n    const leftSide = concatImpl(inputs.slice(0, midIndex), axis, backend);\n    const rightSide = concatImpl(inputs.slice(midIndex), axis, backend);\n    const result = concatImpl([leftSide, rightSide], axis, backend);\n    backend.disposeIntermediateTensorInfo(leftSide);\n    backend.disposeIntermediateTensorInfo(rightSide);\n    return result;\n  }\n  if (env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') && inputs[0].shape.length > 1) {\n    const program = new ConcatPackedProgram(inputs.map(t => t.shape), axis);\n    return backend.runWebGLProgram(program, inputs, dtype);\n  }\n  const {\n    tensors2D,\n    outShape\n  } = computeTensors2D(inputs, axis, backend);\n  const program = new ConcatProgram(tensors2D.map(t => t.shape));\n  const result = backend.runWebGLProgram(program, tensors2D, dtype);\n  tensors2D.forEach(r => backend.disposeIntermediateTensorInfo(r));\n  const reshapedResult = reshape({\n    inputs: {\n      x: result\n    },\n    attrs: {\n      shape: outShape\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(result);\n  return reshapedResult;\n}\nfunction computeTensors2D(inputs, axis, backend) {\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(x => reshape({\n    inputs: {\n      x\n    },\n    attrs: {\n      shape: [-1, util.sizeFromShape(x.shape.slice(axis))]\n    },\n    backend\n  }));\n  return {\n    tensors2D,\n    outShape\n  };\n}","map":{"version":3,"sources":["../../src/kernels/Concat_impl.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAgB,GAAG,EAAc,IAAI,QAAO,uBAAuB;AAGvF,SAAQ,aAAa,QAAO,eAAe;AAC3C,SAAQ,mBAAmB,QAAO,sBAAsB;AACxD,SAAQ,aAAa,QAAO,wBAAwB;AAEpD,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,IAAI,QAAO,QAAQ;AAC3B,SAAQ,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAU,UAAU,CACtB,MAAoB,EAAE,IAAY,EAAE,OAAyB,EAAA;EAC/D,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK;EAC7B,IAAI,KAAK,KAAK,WAAW,EAAE;IACzB,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IACpE,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,CAAE,CAAC,IAAK,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC,CAAC;IAEpE,MAAM,YAAY,GAAG,UAAU,CAAC,KAAK,EAAE,IAAI,EAAE,OAAO,CAAC;IACrD,MAAM,YAAY,GAAG,UAAU,CAAC,KAAK,EAAE,IAAI,EAAE,OAAO,CAAC;IAErD,MAAM,MAAM,GACR,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,IAAI,EAAE,YAAY;QAAE,IAAI,EAAE;MAAY,CAAC;MAAE;IAAO,CAAC,CAAC;IAExE,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAC5D,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IACnD,OAAO,CAAC,6BAA6B,CAAC,YAAY,CAAC;IAEnD,OAAO,MAAM;EACd;EAED;EACA;EACA;EACA;EACA;EACA;EACA,IAAI,KAAK,KAAK,QAAQ,EAAE;IACtB,MAAM;MAAC,SAAS;MAAE;IAAQ,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,IAAI,EAAE,OAAO,CAAC;IACrE,MAAM,eAAe,GAAG,SAAS,CAAC,GAAG,CAAC,CAAC,IAAG;MACxC,OAAO;QAAC,IAAI,EAAE,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC;QAAE,KAAK,EAAE,CAAC,CAAC;MAAK,CAAC;IAC3D,CAAC,CAAC;IACF,MAAM,YAAY,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;IAChD,MAAM,OAAO,GACT,aAAa,CAAC,eAAe,EAAE,QAAQ,EAAE,KAAK,EAAE,YAAY,CAAC;IAEjE,MAAM,aAAa,GACf,YAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC;IAEhE,MAAM,OAAO,GAAG,OAAO,CAAC,cAAc,CAAC,aAAa,EAAE,KAAK,EAAE,OAAO,CAAC;IAErE,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;IAEhE,OAAO,OAAO;EACf;EAED,IAAI,MAAM,CAAC,MAAM,GAAG,GAAG,EAAE,CAAC,SAAS,CAAC,8BAA8B,CAAC,EAAE;IACnE,MAAM,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;IAC9C,MAAM,QAAQ,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE,IAAI,EAAE,OAAO,CAAC;IACrE,MAAM,SAAS,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,QAAQ,CAAC,EAAE,IAAI,EAAE,OAAO,CAAC;IAEnE,MAAM,MAAM,GAAG,UAAU,CAAC,CAAC,QAAQ,EAAE,SAAS,CAAC,EAAE,IAAI,EAAE,OAAO,CAAC;IAE/D,OAAO,CAAC,6BAA6B,CAAC,QAAQ,CAAC;IAC/C,OAAO,CAAC,6BAA6B,CAAC,SAAS,CAAC;IAEhD,OAAO,MAAM;EACd;EAED,IAAI,GAAG,EAAE,CAAC,OAAO,CAAC,6BAA6B,CAAC,IAC5C,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;IAC9B,MAAM,OAAO,GAAG,IAAI,mBAAmB,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC;IACvE,OAAO,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,MAAM,EAAE,KAAK,CAAC;EACvD;EAED,MAAM;IAAC,SAAS;IAAE;EAAQ,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,IAAI,EAAE,OAAO,CAAC;EACrE,MAAM,OAAO,GACT,IAAI,aAAa,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAyB,CAAC,CAAC;EACtE,MAAM,MAAM,GAAG,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,SAAS,EAAE,KAAK,CAAC;EAEjE,SAAS,CAAC,OAAO,CAAC,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;EAChE,MAAM,cAAc,GAChB,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAM,CAAC;IAAE,KAAK,EAAE;MAAC,KAAK,EAAE;IAAQ,CAAC;IAAE;EAAO,CAAC,CAAC;EACrE,OAAO,CAAC,6BAA6B,CAAC,MAAM,CAAC;EAE7C,OAAO,cAAc;AACvB;AAEA,SAAS,gBAAgB,CACrB,MAAoB,EAAE,IAAY,EAAE,OAAyB,EAAA;EAC/D;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM,QAAQ,GAAG,YAAY,CAAC,eAAe,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC;EAC7E,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CACxB,CAAC,IAAI,OAAO,CAAC;IACX,MAAM,EAAE;MAAC;IAAC,CAAC;IACX,KAAK,EAAE;MAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;IAAC,CAAC;IAC7D;GACD,CAAC,CAAC;EAEP,OAAO;IAAC,SAAS;IAAE;EAAQ,CAAC;AAC9B","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, util } from '@tensorflow/tfjs-core';\nimport { ConcatProgram } from '../concat_gpu';\nimport { ConcatPackedProgram } from '../concat_packed_gpu';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concatImpl(inputs, axis, backend) {\n    const dtype = inputs[0].dtype;\n    if (dtype === 'complex64') {\n        const reals = inputs.map((t) => real({ inputs: { input: t }, backend }));\n        const imags = inputs.map((t) => imag({ inputs: { input: t }, backend }));\n        const realConcated = concatImpl(reals, axis, backend);\n        const imagConcated = concatImpl(imags, axis, backend);\n        const result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });\n        reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n        imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n        backend.disposeIntermediateTensorInfo(realConcated);\n        backend.disposeIntermediateTensorInfo(imagConcated);\n        return result;\n    }\n    // Run on cpu if dtype is string. For string, the backend represents it\n    // as Uint8Array[], where each Uint8Array is a character. Given that the\n    // computation is only on the outer array, uploading the whole data onto\n    // gpu is wasteful. Also, currently webgl doesn't have a design to\n    // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n    // just run the kernel on cpu if dtype is string.\n    if (dtype === 'string') {\n        const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend);\n        const inputsValShapes = tensors2D.map(t => {\n            return { vals: backend.readSync(t.dataId), shape: t.shape };\n        });\n        const simplyConcat = tensors2D[0].shape[0] === 1;\n        const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n        const finalOutShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n        const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n        tensors2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n        return outInfo;\n    }\n    if (inputs.length > env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n        const midIndex = Math.floor(inputs.length / 2);\n        const leftSide = concatImpl(inputs.slice(0, midIndex), axis, backend);\n        const rightSide = concatImpl(inputs.slice(midIndex), axis, backend);\n        const result = concatImpl([leftSide, rightSide], axis, backend);\n        backend.disposeIntermediateTensorInfo(leftSide);\n        backend.disposeIntermediateTensorInfo(rightSide);\n        return result;\n    }\n    if (env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') &&\n        inputs[0].shape.length > 1) {\n        const program = new ConcatPackedProgram(inputs.map(t => t.shape), axis);\n        return backend.runWebGLProgram(program, inputs, dtype);\n    }\n    const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend);\n    const program = new ConcatProgram(tensors2D.map(t => t.shape));\n    const result = backend.runWebGLProgram(program, tensors2D, dtype);\n    tensors2D.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    const reshapedResult = reshape({ inputs: { x: result }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(result);\n    return reshapedResult;\n}\nfunction computeTensors2D(inputs, axis, backend) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    const tensors2D = inputs.map(x => reshape({\n        inputs: { x },\n        attrs: { shape: [-1, util.sizeFromShape(x.shape.slice(axis))] },\n        backend\n    }));\n    return { tensors2D, outShape };\n}\n//# sourceMappingURL=Concat_impl.js.map"]},"metadata":{},"sourceType":"module"}