{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Multiply } from '../kernel_names';\nimport { assertAndGetBroadcastShape, getReductionAxes } from '../ops/broadcast_util';\nimport { cast } from '../ops/cast';\nimport { mul } from '../ops/mul';\nimport { reshape } from '../ops/reshape';\nimport { sum } from '../ops/sum';\nexport const multiplyGradConfig = {\n  kernelName: Multiply,\n  inputsToSave: ['a', 'b'],\n  gradFunc: (dy, saved) => {\n    const [a, b] = saved;\n    const outShape = assertAndGetBroadcastShape(a.shape, b.shape);\n    const derA = () => {\n      const res = mul(dy, cast(b, 'float32'));\n      const reduceAxes = getReductionAxes(a.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), a.shape);\n      }\n      return res;\n    };\n    const derB = () => {\n      const res = mul(dy, cast(a, 'float32'));\n      const reduceAxes = getReductionAxes(b.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), b.shape);\n      }\n      return res;\n    };\n    return {\n      a: derA,\n      b: derB\n    };\n  }\n};","map":{"version":3,"sources":["../../../../../../tfjs-core/src/gradients/Multiply_grad.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,QAAQ,QAAO,iBAAiB;AAExC,SAAQ,0BAA0B,EAAE,gBAAgB,QAAO,uBAAuB;AAClF,SAAQ,IAAI,QAAO,aAAa;AAChC,SAAQ,GAAG,QAAO,YAAY;AAC9B,SAAQ,OAAO,QAAO,gBAAgB;AACtC,SAAQ,GAAG,QAAO,YAAY;AAG9B,OAAO,MAAM,kBAAkB,GAAe;EAC5C,UAAU,EAAE,QAAQ;EACpB,YAAY,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;EACxB,QAAQ,EAAE,CAAC,EAAU,EAAE,KAAe,KAAI;IACxC,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,KAAK;IACpB,MAAM,QAAQ,GAAG,0BAA0B,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;IAE7D,MAAM,IAAI,GAAG,MAAK;MAChB,MAAM,GAAG,GAAG,GAAG,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;MACvC,MAAM,UAAU,GAAG,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,CAAC;MACtD,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;QACzB,OAAO,OAAO,CAAC,GAAG,CAAC,GAAG,EAAE,UAAU,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC;MAC9C;MACD,OAAO,GAAG;IACZ,CAAC;IACD,MAAM,IAAI,GAAG,MAAK;MAChB,MAAM,GAAG,GAAG,GAAG,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;MACvC,MAAM,UAAU,GAAG,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,QAAQ,CAAC;MACtD,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;QACzB,OAAO,OAAO,CAAC,GAAG,CAAC,GAAG,EAAE,UAAU,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC;MAC9C;MACD,OAAO,GAAG;IACZ,CAAC;IACD,OAAO;MAAC,CAAC,EAAE,IAAI;MAAE,CAAC,EAAE;IAAI,CAAC;EAC3B;CACD","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Multiply} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport {assertAndGetBroadcastShape, getReductionAxes} from '../ops/broadcast_util';\nimport {cast} from '../ops/cast';\nimport {mul} from '../ops/mul';\nimport {reshape} from '../ops/reshape';\nimport {sum} from '../ops/sum';\nimport {Tensor} from '../tensor';\n\nexport const multiplyGradConfig: GradConfig = {\n  kernelName: Multiply,\n  inputsToSave: ['a', 'b'],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [a, b] = saved;\n    const outShape = assertAndGetBroadcastShape(a.shape, b.shape);\n\n    const derA = () => {\n      const res = mul(dy, cast(b, 'float32'));\n      const reduceAxes = getReductionAxes(a.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), a.shape);\n      }\n      return res;\n    };\n    const derB = () => {\n      const res = mul(dy, cast(a, 'float32'));\n      const reduceAxes = getReductionAxes(b.shape, outShape);\n      if (reduceAxes.length > 0) {\n        return reshape(sum(res, reduceAxes), b.shape);\n      }\n      return res;\n    };\n    return {a: derA, b: derB};\n  }\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}