{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { CumProgram } from '../cum_gpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumImpl(op, x, backend, axis, exclusive, reverse) {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(`WebGL cumprod shader expects an inner-most axis=${x.shape.length - 1} ` + `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({\n    inputs: {\n      x: permutedX\n    },\n    backend\n  });\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n    return reverseTransposedResult;\n  }\n  return result;\n}","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Cum_impl.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,QAAmB,uBAAuB;AAG9D,SAAmB,UAAU,QAAO,YAAY;AAEhD,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,SAAS,QAAO,aAAa;AAErC,OAAM,SAAU,OAAO,CACnB,EAAa,EAAE,CAAa,EAAE,OAAyB,EAAE,IAAY,EACrE,SAAkB,EAAE,OAAgB,EAAA;EACtC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAC5B,MAAM,WAAW,GAAG,YAAY,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,CAAC;EAClE,IAAI,SAAS,GAAG,CAAC;EACjB,IAAI,WAAW,IAAI,IAAI,EAAE;IACvB,SAAS,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAW;IAAC,CAAC,CAAC;EAC1E;EACD,MAAM,YAAY,GAAG,YAAY,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;EAE/D,IAAI,YAAY,KAAK,KAAK,GAAG,CAAC,EAAE;IAC9B,MAAM,IAAI,KAAK,CACX,mDACI,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,GAAG,GACzB,gBAAgB,IAAI,EAAE,CAAC;EAC5B;EACD,MAAM,IAAI,GAAG,SAAS,CAAC,KAAK,CAAC,YAAY,CAAC;EAC1C,IAAI,MAAM,GAAG,QAAQ,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAS,CAAC;IAAE;EAAO,CAAC,CAAC;EACxD;EACA;EACA;EACA;EAEA,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;IACxD,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,SAAS,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;IACnE,MAAM,YAAY,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1B,MAAM,UAAU,GAAG,MAAM;IACzB,MAAM,GACF,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,YAAY,CAAC;IAC1E,OAAO,CAAC,6BAA6B,CAAC,UAAU,CAAC;EAClD;EACD;EACA;EACA,IAAI,SAAS,EAAE;IACb,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,SAAS,CAAC,KAAK,EAAE,SAAS,EAAE,OAAO,CAAC;IACvE,MAAM,UAAU,GAAG,MAAM;IACzB,MAAM,GAAG,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,CAAC;IACjE,OAAO,CAAC,6BAA6B,CAAC,UAAU,CAAC;EAClD;EAED,IAAI,WAAW,IAAI,IAAI,EAAE;IACvB,MAAM,kBAAkB,GAAG,YAAY,CAAC,sBAAsB,CAAC,WAAW,CAAC;IAC3E,MAAM,uBAAuB,GAAG,SAAS,CACrC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAM,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAkB;IAAC,CAAC,CAAC;IAEtE,OAAO,CAAC,6BAA6B,CAAC,MAAM,CAAC;IAC7C,OAAO,CAAC,6BAA6B,CAAC,SAAS,CAAC;IAEhD,OAAO,uBAAuB;EAC/B;EAED,OAAO,MAAM;AACf","sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {CumOpType, CumProgram} from '../cum_gpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: MathBackendWebGL, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGL cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result =\n        backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}