{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ArgMax, backend_util, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { transpose } from './Transpose';\nexport function argMax(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    axis\n  } = attrs;\n  assertNotComplex(x, 'argMax');\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutedAxes\n      }\n    });\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n  const [outShape, reduceShape] = backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const aVals = backend.data.get($x.dataId).values;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    let maxIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n        maxIndex = j;\n      }\n    }\n    vals[i] = maxIndex;\n  }\n  intermediateTensorInfos.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\nexport const argMaxConfig = {\n  kernelName: ArgMax,\n  backendName: 'cpu',\n  kernelFunc: argMax\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/ArgMax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAM,EAA6B,YAAY,EAAoD,IAAI,QAAO,uBAAuB;AAG7I,SAAQ,gBAAgB,QAAO,aAAa;AAC5C,SAAQ,SAAS,QAAO,aAAa;AAErC,OAAM,SAAU,MAAM,CAClB,IAAyE,EAAA;EAE3E,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC;EAAI,CAAC,GAAG,KAAK;EAEpB,gBAAgB,CAAC,CAAC,EAAE,QAAQ,CAAC;EAE7B,IAAI,IAAI,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC;EAC7C,MAAM,YAAY,GAAG,YAAY,CAAC,kBAAkB,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;EAC1E,IAAI,EAAE,GAAG,CAAC;EACV,MAAM,uBAAuB,GAAG,EAAE;EAClC,IAAI,YAAY,IAAI,IAAI,EAAE;IACxB,EAAE,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAY;IAAC,CAAC,CAAC;IACnE,uBAAuB,CAAC,IAAI,CAAC,EAAE,CAAC;IAChC,IAAI,GAAG,YAAY,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC;EACnE;EAED,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;EAChB,YAAY,CAAC,0BAA0B,CAAC,QAAQ,EAAE,IAAI,EAAE,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC;EACxE,MAAM,CAAC,QAAQ,EAAE,WAAW,CAAC,GACzB,YAAY,CAAC,yBAAyB,CAAC,EAAE,CAAC,KAAK,EAAE,IAAI,CAAC;EAE1D,MAAM,OAAO,GAAG,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC;EAC5C,MAAM,IAAI,GAAG,IAAI,CAAC,mBAAmB,CAAC,OAAO,EAAE,OAAO,CAAC;EACvD,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC;EAElD,MAAM,KAAK,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,MAAoB;EAC9D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;IACpC,MAAM,MAAM,GAAG,CAAC,GAAG,UAAU;IAC7B,IAAI,GAAG,GAAG,KAAK,CAAC,MAAM,CAAC;IACvB,IAAI,QAAQ,GAAG,CAAC;IAChB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,EAAE,CAAC,EAAE;MACnC,MAAM,KAAK,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;MAC/B,IAAI,KAAK,GAAG,GAAG,EAAE;QACf,GAAG,GAAG,KAAK;QACX,QAAQ,GAAG,CAAC;MACb;IACF;IACD,IAAI,CAAC,CAAC,CAAC,GAAG,QAAQ;EACnB;EAED,uBAAuB,CAAC,OAAO,CAC3B,CAAC,IAAI,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;EAElD,OAAO,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,OAAO,EAAE,IAAI,CAAC;AACxD;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: MathBackendCPU, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMax');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    let maxIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n        maxIndex = j;\n      }\n    }\n    vals[i] = maxIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'cpu',\n  kernelFunc: argMax as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}